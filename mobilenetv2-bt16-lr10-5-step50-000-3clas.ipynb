{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install roboflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:25.981790Z","iopub.execute_input":"2025-06-20T06:59:25.982073Z","iopub.status.idle":"2025-06-20T06:59:32.048860Z","shell.execute_reply.started":"2025-06-20T06:59:25.982050Z","shell.execute_reply":"2025-06-20T06:59:32.047934Z"}},"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2025.1.31)\nCollecting idna==3.7 (from roboflow)\n  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\nCollecting pillow-heif>=0.18.0 (from roboflow)\n  Downloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.9.0.post0)\nCollecting python-dotenv (from roboflow)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.3.0)\nRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.67.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\nCollecting filetype (from roboflow)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.5->roboflow) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.55.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->roboflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nDownloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: filetype, python-dotenv, pillow-heif, idna, roboflow\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed filetype-1.2.0 idna-3.7 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.66\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"sjY1k7Bc5AwCbbatoIz2\")\nproject = rf.workspace(\"lebeling-sendiri-300\").project(\"-25m-3class\")\nversion = project.version(4)\ndataset = version.download(\"tfrecord\")\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:32.050047Z","iopub.execute_input":"2025-06-20T06:59:32.050382Z","iopub.status.idle":"2025-06-20T06:59:36.063978Z","shell.execute_reply.started":"2025-06-20T06:59:32.050347Z","shell.execute_reply":"2025-06-20T06:59:36.063282Z"}},"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in @25M(3class)-4 to tfrecord:: 100%|██████████| 75101/75101 [00:01<00:00, 60313.00it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to @25M(3class)-4 in tfrecord:: 100%|██████████| 11/11 [00:00<00:00, 71.99it/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Clone the tensorflow models repository from GitHub\n!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n!git clone --depth 1 https://github.com/tensorflow/models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:36.065347Z","iopub.execute_input":"2025-06-20T06:59:36.065591Z","iopub.status.idle":"2025-06-20T06:59:51.711387Z","shell.execute_reply.started":"2025-06-20T06:59:36.065570Z","shell.execute_reply":"2025-06-20T06:59:51.710308Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: Cython 3.0.11\nUninstalling Cython-3.0.11:\n  Successfully uninstalled Cython-3.0.11\nCloning into 'models'...\nremote: Enumerating objects: 4352, done.\u001b[K\nremote: Counting objects: 100% (4352/4352), done.\u001b[K\nremote: Compressing objects: 100% (3160/3160), done.\u001b[K\nremote: Total 4352 (delta 1188), reused 3997 (delta 1119), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (4352/4352), 54.72 MiB | 36.99 MiB/s, done.\nResolving deltas: 100% (1188/1188), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Copy setup files into models/research folder\n!cd /kaggle/working/models/research && protoc object_detection/protos/*.proto --python_out=.\n# !cd models/research/ && protoc object_detection/protos/*.proto --python_out=/kaggle/working/models/research/object_detection\n\n#cp object_detection/packages/tf2/setup.py .\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:51.713409Z","iopub.execute_input":"2025-06-20T06:59:51.713694Z","iopub.status.idle":"2025-06-20T06:59:51.901514Z","shell.execute_reply.started":"2025-06-20T06:59:51.713667Z","shell.execute_reply":"2025-06-20T06:59:51.900458Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\nimport re\nwith open('/kaggle/working/models/research/object_detection/packages/tf2/setup.py') as f:\n    s = f.read()\n\nwith open('/kaggle/working/models/research/setup.py', 'w') as f:\n    # Set fine_tune_checkpoint path\n    s = re.sub('tf-models-official>=2.5.1',\n               'tf-models-official==2.8.0', s)\n    f.write(s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:51.902599Z","iopub.execute_input":"2025-06-20T06:59:51.902912Z","iopub.status.idle":"2025-06-20T06:59:51.908705Z","shell.execute_reply.started":"2025-06-20T06:59:51.902885Z","shell.execute_reply":"2025-06-20T06:59:51.907760Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n\n# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n!pip install pyyaml==5.3\n\n# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n!pip install tensorflow==2.8.0\n# !pip install /kaggle/working/models/research\n\n# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n!pip install tensorflow_io==0.23.1\n!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n!apt-get update && sudo apt-get install -y cuda-toolkit-11-0  # Thêm cờ --yes vào đây\n!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T06:59:51.909790Z","iopub.execute_input":"2025-06-20T06:59:51.910067Z","iopub.status.idle":"2025-06-20T07:04:48.058837Z","shell.execute_reply.started":"2025-06-20T06:59:51.910037Z","shell.execute_reply":"2025-06-20T07:04:48.057684Z"}},"outputs":[{"name":"stdout","text":"Collecting pyyaml==5.3\n  Downloading PyYAML-5.3.tar.gz (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: pyyaml\n  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pyyaml: filename=PyYAML-5.3-cp310-cp310-linux_x86_64.whl size=44244 sha256=f3b9096ac7cb4d6d7b05090708ca49b936a999ec68735da308c98ce7ee517d2d\n  Stored in directory: /root/.cache/pip/wheels/0d/72/68/a263cfc14175636cf26bada99f13b735be1b60a11318e08bfc\nSuccessfully built pyyaml\nInstalling collected packages: pyyaml\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0.2\n    Uninstalling PyYAML-6.0.2:\n      Successfully uninstalled PyYAML-6.0.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\ndask 2024.12.1 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\ndistributed 2024.12.1 requires pyyaml>=5.4.1, but you have pyyaml 5.3 which is incompatible.\nflax 0.8.5 requires PyYAML>=5.4.1, but you have pyyaml 5.3 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\npytorch-lightning 2.5.0.post0 requires PyYAML>=5.4, but you have pyyaml 5.3 which is incompatible.\nroboflow 1.1.66 requires PyYAML>=5.3.1, but you have pyyaml 5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyyaml-5.3\nCollecting tensorflow==2.8.0\n  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\nRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.12.1)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\nRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.17.0)\nCollecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.68.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.45.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.8.0) (2.4.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tensorflow==2.8.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tensorflow==2.8.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->tensorflow==2.8.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->tensorflow==2.8.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->tensorflow==2.8.0) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\nDownloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, google-auth-oauthlib, tensorboard, keras-preprocessing, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.5.0\n    Uninstalling keras-3.5.0:\n      Successfully uninstalled keras-3.5.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.1\n    Uninstalling google-auth-oauthlib-1.2.1:\n      Successfully uninstalled google-auth-oauthlib-1.2.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.8.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\nCollecting tensorflow_io==0.23.1\n  Downloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\nCollecting tensorflow-io-gcs-filesystem==0.23.1 (from tensorflow_io==0.23.1)\n  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\nDownloading tensorflow_io-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.23.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow_io\n  Attempting uninstall: tensorflow-io-gcs-filesystem\n    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n  Attempting uninstall: tensorflow_io\n    Found existing installation: tensorflow-io 0.37.1\n    Uninstalling tensorflow-io-0.37.1:\n      Successfully uninstalled tensorflow-io-0.37.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.8.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-io-gcs-filesystem-0.23.1 tensorflow_io-0.23.1\n--2025-06-20 07:01:07--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\nResolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.195.37.69, 23.195.37.70\nConnecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.195.37.69|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 190 [application/octet-stream]\nSaving to: ‘cuda-ubuntu1804.pin’\n\ncuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n\n2025-06-20 07:01:07 (118 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n\n--2025-06-20 07:01:07--  http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\nResolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.195.37.69, 23.195.37.70\nConnecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.195.37.69|:80... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb [following]\n--2025-06-20 07:01:07--  https://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\nConnecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.195.37.69|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2273753684 (2.1G) [application/x-deb]\nSaving to: ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’\n\ncuda-repo-ubuntu180 100%[===================>]   2.12G   176MB/s    in 13s     \n\n2025-06-20 07:01:20 (170 MB/s) - ‘cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb’ saved [2273753684/2273753684]\n\nSelecting previously unselected package cuda-repo-ubuntu1804-11-0-local.\n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb ...\nUnpacking cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\nSetting up cuda-repo-ubuntu1804-11-0-local (11.0.2-450.51.05-1) ...\n\nThe public CUDA GPG key does not appear to be installed.\nTo install the key, run this command:\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n\nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\nOK\nGet:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\nIgn:1 file:/var/cuda-repo-ubuntu1804-11-0-local  InRelease\nGet:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]\nGet:2 file:/var/cuda-repo-ubuntu1804-11-0-local  Release [564 B]                                    \nGet:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]                                \nGet:3 file:/var/cuda-repo-ubuntu1804-11-0-local  Release.gpg [836 B]                                \nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]                \nHit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:9 file:/var/cuda-repo-ubuntu1804-11-0-local  Packages [23.9 kB]                                 \nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                            \nGet:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,798 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                          \nGet:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]             \nGet:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \nGet:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]              \nGet:16 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [79.8 kB]                \nGet:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,340 kB]\nGet:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,051 kB]    \nGet:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,024 kB]      \nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,703 kB]          \nGet:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]   \nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]           \nGet:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]               \nGet:26 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]           \nGet:27 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.6 kB]\nGet:28 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.1 kB] \nGet:29 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,532 kB]\nGet:30 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\nGet:31 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\nFetched 32.9 MB in 4s (9,396 kB/s)                           \nReading package lists... Done\nW: file:/var/cuda-repo-ubuntu1804-11-0-local/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-tools-11-0\n  cuda-visual-tools-11-0 default-jre default-jre-headless fonts-dejavu-core\n  fonts-dejavu-extra freeglut3 freeglut3-dev libatk-wrapper-java\n  libatk-wrapper-java-jni libcublas-11-0 libcublas-dev-11-0 libcufft-11-0\n  libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0 libcusolver-11-0\n  libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0 libegl-dev\n  libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev\n  libglvnd-core-dev libglvnd-dev libglx-dev libnpp-11-0 libnpp-dev-11-0\n  libnvjpeg-11-0 libnvjpeg-dev-11-0 libopengl-dev libxcb-cursor0 libxcb-icccm4\n  libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxfixes-dev libxi-dev\n  libxkbcommon-x11-0 libxmu-dev libxmu-headers libxtst6 libxxf86dga1\n  nsight-systems-2025.1.3 openjdk-11-jdk-headless openjdk-11-jre\n  openjdk-11-jre-headless x11-utils\nSuggested packages:\n  openjdk-11-demo openjdk-11-source libnss-mdns fonts-ipafont-gothic\n  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n  mesa-utils\nThe following NEW packages will be installed:\n  cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n  cuda-documentation-11-0 cuda-driver-dev-11-0 cuda-gdb-11-0\n  cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n  cuda-nvvp-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n  cuda-tools-11-0 cuda-visual-tools-11-0 default-jre default-jre-headless\n  fonts-dejavu-core fonts-dejavu-extra freeglut3 freeglut3-dev\n  libatk-wrapper-java libatk-wrapper-java-jni libcublas-11-0\n  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n  libcusparse-dev-11-0 libegl-dev libgl-dev libgl1-mesa-dev libgles-dev\n  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n  libglx-dev libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0\n  libopengl-dev libxcb-cursor0 libxcb-icccm4 libxcb-image0 libxcb-keysyms1\n  libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n  libxfixes-dev libxi-dev libxkbcommon-x11-0 libxmu-dev libxmu-headers\n  libxtst6 libxxf86dga1 nsight-systems-2025.1.3 openjdk-11-jre x11-utils\nThe following packages will be upgraded:\n  openjdk-11-jdk-headless openjdk-11-jre-headless\n2 upgraded, 82 newly installed, 0 to remove and 278 not upgraded.\nNeed to get 521 MB/2,103 MB of archives.\nAfter this operation, 4,020 MB of additional disk space will be used.\nGet:1 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-11-0 11.0.194-1 [129 kB]\nGet:2 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-driver-dev-11-0 11.0.194-1 [25.0 kB]\nGet:3 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cudart-dev-11-0 11.0.194-1 [1,662 kB]\nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2025.1.3 2025.1.3.140-251335620677v0 [400 MB]\nGet:5 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvcc-11-0 11.0.194-1 [21.1 MB]\nGet:6 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-11-0 11.0.194-1 [10.5 MB]\nGet:7 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cupti-dev-11-0 11.0.194-1 [2,276 kB]\nGet:8 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvdisasm-11-0 11.0.194-1 [27.3 MB]\nGet:9 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-cuobjdump-11-0 11.0.194-1 [103 kB]\nGet:10 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-gdb-11-0 11.0.194-1 [3,891 kB]\nGet:11 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-memcheck-11-0 11.0.194-1 [144 kB]\nGet:12 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprof-11-0 11.0.194-1 [1,911 kB]\nGet:13 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\nGet:14 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-sanitizer-11-0 11.0.194-1 [7,220 kB]\nGet:15 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-command-line-tools-11-0 11.0.2-1 [2,474 B]\nGet:16 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\nGet:17 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-compiler-11-0 11.0.2-1 [2,416 B]\nGet:18 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-11-0 11.0.194-1 [6,521 kB]\nGet:19 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvrtc-dev-11-0 11.0.194-1 [22.1 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\nGet:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\nGet:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [6,848 B]\nGet:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\nGet:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\nGet:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\nGet:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-headers all 2:1.1.3-3 [54.1 kB]\nGet:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxmu-dev amd64 2:1.1.3-3 [54.6 kB]\nGet:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\nGet:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\nGet:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.27+6~us1-0ubuntu1~22.04 [73.6 MB]\nGet:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.27+6~us1-0ubuntu1~22.04 [42.6 MB]\nGet:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\nGet:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\nGet:41 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.27+6~us1-0ubuntu1~22.04 [214 kB]\nGet:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\nGet:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\nGet:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\nGet:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\nGet:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\nGet:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\nGet:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\nGet:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\nGet:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\nGet:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\nGet:52 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-11-0 10.5.0.218-1 [277 MB]\nGet:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxcb-cursor0 amd64 0.1.1-4ubuntu1 [10.5 kB]\nGet:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\nGet:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\nGet:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\nGet:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\nGet:58 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\nGet:59 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\nGet:60 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusolver-dev-11-0 10.5.0.218-1 [17.6 MB]\nGet:61 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-11-0 11.1.0.229-1 [118 MB]\nGet:62 file:/var/cuda-repo-ubuntu1804-11-0-local  libcublas-dev-11-0 11.1.0.229-1 [120 MB]\nGet:63 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-11-0 10.2.0.218-1 [94.1 MB]\nGet:64 file:/var/cuda-repo-ubuntu1804-11-0-local  libcufft-dev-11-0 10.2.0.218-1 [172 MB]\nGet:65 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-11-0 10.2.1.218-1 [39.2 MB]\nGet:66 file:/var/cuda-repo-ubuntu1804-11-0-local  libcurand-dev-11-0 10.2.1.218-1 [39.2 MB]\nGet:67 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-11-0 11.1.0.218-1 [71.2 MB]\nGet:68 file:/var/cuda-repo-ubuntu1804-11-0-local  libcusparse-dev-11-0 11.1.0.218-1 [71.4 MB]\nGet:69 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-11-0 11.1.0.218-1 [56.6 MB]\nGet:70 file:/var/cuda-repo-ubuntu1804-11-0-local  libnpp-dev-11-0 11.1.0.218-1 [57.4 MB]\nGet:71 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-11-0 11.1.0.218-1 [1,391 kB]\nGet:72 file:/var/cuda-repo-ubuntu1804-11-0-local  libnvjpeg-dev-11-0 11.1.0.218-1 [1,321 kB]\nGet:73 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-samples-11-0 11.0.194-1 [68.1 MB]\nGet:74 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-documentation-11-0 11.0.207-1 [59.6 MB]\nGet:75 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-11-0 11.0.2-1 [2,490 B]\nGet:76 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-libraries-dev-11-0 11.0.2-1 [2,514 B]\nGet:77 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-11-0 11.0.194-1 [119 MB]\nGet:78 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-compute-11-0 11.0.2-1 [3,718 B]\nGet:79 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nsight-systems-11-0 11.0.2-1 [3,280 B]\nGet:80 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\nGet:81 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-nvvp-11-0 11.0.194-1 [115 MB]\nGet:82 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-visual-tools-11-0 11.0.2-1 [2,942 B]\nGet:83 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-tools-11-0 11.0.2-1 [2,380 B]\nGet:84 file:/var/cuda-repo-ubuntu1804-11-0-local  cuda-toolkit-11-0 11.0.2-1 [2,728 B]\nFetched 521 MB in 14s (36.0 MB/s)                                              \ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 84.)\ndebconf: falling back to frontend: Readline\nExtracting templates from packages: 100%\nSelecting previously unselected package cuda-cudart-11-0.\n(Reading database ... 127487 files and directories currently installed.)\nPreparing to unpack .../00-cuda-cudart-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-cudart-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-driver-dev-11-0.\nPreparing to unpack .../01-cuda-driver-dev-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-driver-dev-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-cudart-dev-11-0.\nPreparing to unpack .../02-cuda-cudart-dev-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-cudart-dev-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nvcc-11-0.\nPreparing to unpack .../03-cuda-nvcc-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvcc-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-cupti-11-0.\nPreparing to unpack .../04-cuda-cupti-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-cupti-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-cupti-dev-11-0.\nPreparing to unpack .../05-cuda-cupti-dev-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-cupti-dev-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nvdisasm-11-0.\nPreparing to unpack .../06-cuda-nvdisasm-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvdisasm-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-cuobjdump-11-0.\nPreparing to unpack .../07-cuda-cuobjdump-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-cuobjdump-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-gdb-11-0.\nPreparing to unpack .../08-cuda-gdb-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-gdb-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-memcheck-11-0.\nPreparing to unpack .../09-cuda-memcheck-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-memcheck-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nvprof-11-0.\nPreparing to unpack .../10-cuda-nvprof-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvprof-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nvtx-11-0.\nPreparing to unpack .../11-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\nUnpacking cuda-nvtx-11-0 (11.0.167-1) ...\nSelecting previously unselected package cuda-sanitizer-11-0.\nPreparing to unpack .../12-cuda-sanitizer-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-sanitizer-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-command-line-tools-11-0.\nPreparing to unpack .../13-cuda-command-line-tools-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-command-line-tools-11-0 (11.0.2-1) ...\nSelecting previously unselected package cuda-nvprune-11-0.\nPreparing to unpack .../14-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\nUnpacking cuda-nvprune-11-0 (11.0.167-1) ...\nSelecting previously unselected package cuda-compiler-11-0.\nPreparing to unpack .../15-cuda-compiler-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-compiler-11-0 (11.0.2-1) ...\nSelecting previously unselected package freeglut3:amd64.\nPreparing to unpack .../16-freeglut3_2.8.1-6_amd64.deb ...\nUnpacking freeglut3:amd64 (2.8.1-6) ...\nSelecting previously unselected package libglx-dev:amd64.\nPreparing to unpack .../17-libglx-dev_1.4.0-1_amd64.deb ...\nUnpacking libglx-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libgl-dev:amd64.\nPreparing to unpack .../18-libgl-dev_1.4.0-1_amd64.deb ...\nUnpacking libgl-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libglvnd-core-dev:amd64.\nPreparing to unpack .../19-libglvnd-core-dev_1.4.0-1_amd64.deb ...\nUnpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libegl-dev:amd64.\nPreparing to unpack .../20-libegl-dev_1.4.0-1_amd64.deb ...\nUnpacking libegl-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libgles1:amd64.\nPreparing to unpack .../21-libgles1_1.4.0-1_amd64.deb ...\nUnpacking libgles1:amd64 (1.4.0-1) ...\nSelecting previously unselected package libgles-dev:amd64.\nPreparing to unpack .../22-libgles-dev_1.4.0-1_amd64.deb ...\nUnpacking libgles-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libopengl-dev:amd64.\nPreparing to unpack .../23-libopengl-dev_1.4.0-1_amd64.deb ...\nUnpacking libopengl-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libglvnd-dev:amd64.\nPreparing to unpack .../24-libglvnd-dev_1.4.0-1_amd64.deb ...\nUnpacking libglvnd-dev:amd64 (1.4.0-1) ...\nSelecting previously unselected package libgl1-mesa-dev:amd64.\nPreparing to unpack .../25-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\nUnpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\nSelecting previously unselected package libglu1-mesa:amd64.\nPreparing to unpack .../26-libglu1-mesa_9.0.2-1_amd64.deb ...\nUnpacking libglu1-mesa:amd64 (9.0.2-1) ...\nSelecting previously unselected package libglu1-mesa-dev:amd64.\nPreparing to unpack .../27-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\nUnpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\nSelecting previously unselected package freeglut3-dev:amd64.\nPreparing to unpack .../28-freeglut3-dev_2.8.1-6_amd64.deb ...\nUnpacking freeglut3-dev:amd64 (2.8.1-6) ...\nSelecting previously unselected package libxmu-headers.\nPreparing to unpack .../29-libxmu-headers_2%3a1.1.3-3_all.deb ...\nUnpacking libxmu-headers (2:1.1.3-3) ...\nSelecting previously unselected package libxmu-dev:amd64.\nPreparing to unpack .../30-libxmu-dev_2%3a1.1.3-3_amd64.deb ...\nUnpacking libxmu-dev:amd64 (2:1.1.3-3) ...\nSelecting previously unselected package libxfixes-dev:amd64.\nPreparing to unpack .../31-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\nUnpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\nSelecting previously unselected package libxi-dev:amd64.\nPreparing to unpack .../32-libxi-dev_2%3a1.8-1build1_amd64.deb ...\nUnpacking libxi-dev:amd64 (2:1.8-1build1) ...\nSelecting previously unselected package cuda-nvrtc-11-0.\nPreparing to unpack .../33-cuda-nvrtc-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvrtc-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nvrtc-dev-11-0.\nPreparing to unpack .../34-cuda-nvrtc-dev-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvrtc-dev-11-0 (11.0.194-1) ...\nSelecting previously unselected package libcusolver-11-0.\nPreparing to unpack .../35-libcusolver-11-0_10.5.0.218-1_amd64.deb ...\nUnpacking libcusolver-11-0 (10.5.0.218-1) ...\nSelecting previously unselected package libcusolver-dev-11-0.\nPreparing to unpack .../36-libcusolver-dev-11-0_10.5.0.218-1_amd64.deb ...\nUnpacking libcusolver-dev-11-0 (10.5.0.218-1) ...\nSelecting previously unselected package libcublas-11-0.\nPreparing to unpack .../37-libcublas-11-0_11.1.0.229-1_amd64.deb ...\nUnpacking libcublas-11-0 (11.1.0.229-1) ...\nSelecting previously unselected package libcublas-dev-11-0.\nPreparing to unpack .../38-libcublas-dev-11-0_11.1.0.229-1_amd64.deb ...\nUnpacking libcublas-dev-11-0 (11.1.0.229-1) ...\nSelecting previously unselected package libcufft-11-0.\nPreparing to unpack .../39-libcufft-11-0_10.2.0.218-1_amd64.deb ...\nUnpacking libcufft-11-0 (10.2.0.218-1) ...\nSelecting previously unselected package libcufft-dev-11-0.\nPreparing to unpack .../40-libcufft-dev-11-0_10.2.0.218-1_amd64.deb ...\nUnpacking libcufft-dev-11-0 (10.2.0.218-1) ...\nSelecting previously unselected package libcurand-11-0.\nPreparing to unpack .../41-libcurand-11-0_10.2.1.218-1_amd64.deb ...\nUnpacking libcurand-11-0 (10.2.1.218-1) ...\nSelecting previously unselected package libcurand-dev-11-0.\nPreparing to unpack .../42-libcurand-dev-11-0_10.2.1.218-1_amd64.deb ...\nUnpacking libcurand-dev-11-0 (10.2.1.218-1) ...\nSelecting previously unselected package libcusparse-11-0.\nPreparing to unpack .../43-libcusparse-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libcusparse-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package libcusparse-dev-11-0.\nPreparing to unpack .../44-libcusparse-dev-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libcusparse-dev-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package libnpp-11-0.\nPreparing to unpack .../45-libnpp-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libnpp-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package libnpp-dev-11-0.\nPreparing to unpack .../46-libnpp-dev-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libnpp-dev-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package libnvjpeg-11-0.\nPreparing to unpack .../47-libnvjpeg-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libnvjpeg-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package libnvjpeg-dev-11-0.\nPreparing to unpack .../48-libnvjpeg-dev-11-0_11.1.0.218-1_amd64.deb ...\nUnpacking libnvjpeg-dev-11-0 (11.1.0.218-1) ...\nSelecting previously unselected package cuda-samples-11-0.\nPreparing to unpack .../49-cuda-samples-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-samples-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-documentation-11-0.\nPreparing to unpack .../50-cuda-documentation-11-0_11.0.207-1_amd64.deb ...\nUnpacking cuda-documentation-11-0 (11.0.207-1) ...\nSelecting previously unselected package cuda-libraries-11-0.\nPreparing to unpack .../51-cuda-libraries-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-libraries-11-0 (11.0.2-1) ...\nSelecting previously unselected package cuda-libraries-dev-11-0.\nPreparing to unpack .../52-cuda-libraries-dev-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-libraries-dev-11-0 (11.0.2-1) ...\nPreparing to unpack .../53-openjdk-11-jdk-headless_11.0.27+6~us1-0ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jdk-headless:amd64 (11.0.27+6~us1-0ubuntu1~22.04) over (11.0.25+9-1ubuntu1~22.04) ...\nPreparing to unpack .../54-openjdk-11-jre-headless_11.0.27+6~us1-0ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jre-headless:amd64 (11.0.27+6~us1-0ubuntu1~22.04) over (11.0.25+9-1ubuntu1~22.04) ...\nSelecting previously unselected package default-jre-headless.\nPreparing to unpack .../55-default-jre-headless_2%3a1.11-72build2_amd64.deb ...\nUnpacking default-jre-headless (2:1.11-72build2) ...\nSelecting previously unselected package libxtst6:amd64.\nPreparing to unpack .../56-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\nUnpacking libxtst6:amd64 (2:1.2.3-1build4) ...\nSelecting previously unselected package openjdk-11-jre:amd64.\nPreparing to unpack .../57-openjdk-11-jre_11.0.27+6~us1-0ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jre:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\nSelecting previously unselected package default-jre.\nPreparing to unpack .../58-default-jre_2%3a1.11-72build2_amd64.deb ...\nUnpacking default-jre (2:1.11-72build2) ...\nSelecting previously unselected package cuda-nsight-11-0.\nPreparing to unpack .../59-cuda-nsight-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nsight-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-nsight-compute-11-0.\nPreparing to unpack .../60-cuda-nsight-compute-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-nsight-compute-11-0 (11.0.2-1) ...\nSelecting previously unselected package libxcb-xinerama0:amd64.\nPreparing to unpack .../61-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxcb-icccm4:amd64.\nPreparing to unpack .../62-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\nUnpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\nSelecting previously unselected package libxcb-util1:amd64.\nPreparing to unpack .../63-libxcb-util1_0.4.0-1build2_amd64.deb ...\nUnpacking libxcb-util1:amd64 (0.4.0-1build2) ...\nSelecting previously unselected package libxcb-image0:amd64.\nPreparing to unpack .../64-libxcb-image0_0.4.0-2_amd64.deb ...\nUnpacking libxcb-image0:amd64 (0.4.0-2) ...\nSelecting previously unselected package libxcb-keysyms1:amd64.\nPreparing to unpack .../65-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\nUnpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\nSelecting previously unselected package libxcb-render-util0:amd64.\nPreparing to unpack .../66-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\nUnpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\nSelecting previously unselected package libxcb-xkb1:amd64.\nPreparing to unpack .../67-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxkbcommon-x11-0:amd64.\nPreparing to unpack .../68-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\nUnpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\nSelecting previously unselected package libxcb-xinput0:amd64.\nPreparing to unpack .../69-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxcb-cursor0:amd64.\nPreparing to unpack .../70-libxcb-cursor0_0.1.1-4ubuntu1_amd64.deb ...\nUnpacking libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\nSelecting previously unselected package nsight-systems-2025.1.3.\nPreparing to unpack .../71-nsight-systems-2025.1.3_2025.1.3.140-251335620677v0_amd64.deb ...\nUnpacking nsight-systems-2025.1.3 (2025.1.3.140-251335620677v0) ...\nSelecting previously unselected package cuda-nsight-systems-11-0.\nPreparing to unpack .../72-cuda-nsight-systems-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-nsight-systems-11-0 (11.0.2-1) ...\nSelecting previously unselected package cuda-nvml-dev-11-0.\nPreparing to unpack .../73-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\nUnpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\nSelecting previously unselected package cuda-nvvp-11-0.\nPreparing to unpack .../74-cuda-nvvp-11-0_11.0.194-1_amd64.deb ...\nUnpacking cuda-nvvp-11-0 (11.0.194-1) ...\nSelecting previously unselected package cuda-visual-tools-11-0.\nPreparing to unpack .../75-cuda-visual-tools-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-visual-tools-11-0 (11.0.2-1) ...\nSelecting previously unselected package cuda-tools-11-0.\nPreparing to unpack .../76-cuda-tools-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-tools-11-0 (11.0.2-1) ...\nSelecting previously unselected package cuda-toolkit-11-0.\nPreparing to unpack .../77-cuda-toolkit-11-0_11.0.2-1_amd64.deb ...\nUnpacking cuda-toolkit-11-0 (11.0.2-1) ...\nSelecting previously unselected package fonts-dejavu-core.\nPreparing to unpack .../78-fonts-dejavu-core_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-core (2.37-2build1) ...\nSelecting previously unselected package fonts-dejavu-extra.\nPreparing to unpack .../79-fonts-dejavu-extra_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-extra (2.37-2build1) ...\nSelecting previously unselected package libxxf86dga1:amd64.\nPreparing to unpack .../80-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\nUnpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSelecting previously unselected package x11-utils.\nPreparing to unpack .../81-x11-utils_7.7+5build2_amd64.deb ...\nUnpacking x11-utils (7.7+5build2) ...\nSelecting previously unselected package libatk-wrapper-java.\nPreparing to unpack .../82-libatk-wrapper-java_0.38.0-5build1_all.deb ...\nUnpacking libatk-wrapper-java (0.38.0-5build1) ...\nSelecting previously unselected package libatk-wrapper-java-jni:amd64.\nPreparing to unpack .../83-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\nUnpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nSetting up libcurand-11-0 (10.2.1.218-1) ...\nSetting up libcublas-11-0 (11.1.0.229-1) ...\nSetting up libxmu-headers (2:1.1.3-3) ...\nSetting up cuda-nvtx-11-0 (11.0.167-1) ...\nSetting up freeglut3:amd64 (2.8.1-6) ...\nSetting up libglvnd-core-dev:amd64 (1.4.0-1) ...\nSetting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\nSetting up libcusolver-11-0 (10.5.0.218-1) ...\nSetting up cuda-driver-dev-11-0 (11.0.194-1) ...\nSetting up cuda-nsight-compute-11-0 (11.0.2-1) ...\nSetting up libxtst6:amd64 (2:1.2.3-1build4) ...\nSetting up cuda-memcheck-11-0 (11.0.194-1) ...\nSetting up openjdk-11-jre-headless:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\nInstalling new version of config file /etc/java-11-openjdk/security/java.security ...\nSetting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\nSetting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSetting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\nSetting up openjdk-11-jre:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\nSetting up openjdk-11-jdk-headless:amd64 (11.0.27+6~us1-0ubuntu1~22.04) ...\nSetting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\nSetting up libxmu-dev:amd64 (2:1.1.3-3) ...\nSetting up cuda-nvprune-11-0 (11.0.167-1) ...\nSetting up libnvjpeg-11-0 (11.1.0.218-1) ...\nSetting up libxcb-util1:amd64 (0.4.0-1build2) ...\nSetting up cuda-cudart-11-0 (11.0.194-1) ...\nSetting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\nSetting up libxcb-image0:amd64 (0.4.0-2) ...\nSetting up libxfixes-dev:amd64 (1:6.0.0-1) ...\nSetting up cuda-nvprof-11-0 (11.0.194-1) ...\nSetting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\nSetting up cuda-nvml-dev-11-0 (11.0.167-1) ...\nSetting up libxcb-cursor0:amd64 (0.1.1-4ubuntu1) ...\nSetting up libgles1:amd64 (1.4.0-1) ...\nSetting up libcusparse-11-0 (11.1.0.218-1) ...\nSetting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\nSetting up fonts-dejavu-core (2.37-2build1) ...\nSetting up cuda-cuobjdump-11-0 (11.0.194-1) ...\nSetting up libcufft-11-0 (10.2.0.218-1) ...\nSetting up cuda-cudart-dev-11-0 (11.0.194-1) ...\nSetting up cuda-nvrtc-11-0 (11.0.194-1) ...\nSetting up cuda-sanitizer-11-0 (11.0.194-1) ...\nSetting up fonts-dejavu-extra (2.37-2build1) ...\nSetting up libcufft-dev-11-0 (10.2.0.218-1) ...\nSetting up libnpp-11-0 (11.1.0.218-1) ...\nSetting up libcusolver-dev-11-0 (10.5.0.218-1) ...\nSetting up x11-utils (7.7+5build2) ...\nSetting up libglx-dev:amd64 (1.4.0-1) ...\nSetting up libglu1-mesa:amd64 (9.0.2-1) ...\nSetting up cuda-nvdisasm-11-0 (11.0.194-1) ...\nSetting up libatk-wrapper-java (0.38.0-5build1) ...\nSetting up libopengl-dev:amd64 (1.4.0-1) ...\nSetting up libxi-dev:amd64 (2:1.8-1build1) ...\nSetting up libcublas-dev-11-0 (11.1.0.229-1) ...\nSetting up libgl-dev:amd64 (1.4.0-1) ...\nSetting up libcusparse-dev-11-0 (11.1.0.218-1) ...\nSetting up libcurand-dev-11-0 (10.2.1.218-1) ...\nSetting up libnpp-dev-11-0 (11.1.0.218-1) ...\nSetting up cuda-libraries-11-0 (11.0.2-1) ...\nSetting up cuda-gdb-11-0 (11.0.194-1) ...\nSetting up cuda-nvrtc-dev-11-0 (11.0.194-1) ...\nSetting up default-jre-headless (2:1.11-72build2) ...\nSetting up libegl-dev:amd64 (1.4.0-1) ...\nSetting up nsight-systems-2025.1.3 (2025.1.3.140-251335620677v0) ...\nupdate-alternatives: using /opt/nvidia/nsight-systems/2025.1.3/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\nupdate-alternatives: using /opt/nvidia/nsight-systems/2025.1.3/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\nSetting up default-jre (2:1.11-72build2) ...\nSetting up libnvjpeg-dev-11-0 (11.1.0.218-1) ...\nSetting up cuda-nvcc-11-0 (11.0.194-1) ...\nSetting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nSetting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\nSetting up cuda-libraries-dev-11-0 (11.0.2-1) ...\nSetting up cuda-cupti-11-0 (11.0.194-1) ...\nSetting up libgles-dev:amd64 (1.4.0-1) ...\nSetting up cuda-nsight-systems-11-0 (11.0.2-1) ...\nSetting up cuda-nvvp-11-0 (11.0.194-1) ...\nSetting up cuda-compiler-11-0 (11.0.2-1) ...\nSetting up cuda-nsight-11-0 (11.0.194-1) ...\nSetting up libglvnd-dev:amd64 (1.4.0-1) ...\nSetting up cuda-cupti-dev-11-0 (11.0.194-1) ...\nSetting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\nSetting up cuda-command-line-tools-11-0 (11.0.2-1) ...\nSetting up cuda-visual-tools-11-0 (11.0.2-1) ...\nSetting up freeglut3-dev:amd64 (2.8.1-6) ...\nSetting up cuda-tools-11-0 (11.0.2-1) ...\nSetting up cuda-samples-11-0 (11.0.194-1) ...\nSetting up cuda-documentation-11-0 (11.0.207-1) ...\nSetting up cuda-toolkit-11-0 (11.0.2-1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Run Model Bulider Test file, just to verify everything's working properly\n!pip install /kaggle/working/models/research\n\n!python /kaggle/working/models/research/object_detection/builders/model_builder_tf2_test.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:04:48.060155Z","iopub.execute_input":"2025-06-20T07:04:48.060512Z","iopub.status.idle":"2025-06-20T07:06:17.153644Z","shell.execute_reply.started":"2025-06-20T07:04:48.060484Z","shell.execute_reply":"2025-06-20T07:06:17.152573Z"}},"outputs":[{"name":"stdout","text":"Processing ./models/research\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting avro-python3 (from object_detection==0.1)\n  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting apache-beam (from object_detection==0.1)\n  Downloading apache_beam-2.65.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.7.5)\nCollecting Cython (from object_detection==0.1)\n  Downloading cython-3.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\nCollecting contextlib2 (from object_detection==0.1)\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.17.0)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\nCollecting lvis (from object_detection==0.1)\n  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.3)\nCollecting tf-models-official==2.8.0 (from object_detection==0.1)\n  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.23.1)\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.8.0)\nCollecting pyparsing==2.4.7 (from object_detection==0.1)\n  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\nCollecting sacrebleu<=2.2.0 (from object_detection==0.1)\n  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.5.0)\nRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.155.0)\nRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.6.17)\nRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.26.4)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.1.3)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.10.0.84)\nRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.9.5)\nRequirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (9.0.0)\nRequirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.3)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\nCollecting seqeval (from tf-models-official==2.8.0->object_detection==0.1)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting tensorflow-addons (from tf-models-official==2.8.0->object_detection==0.1)\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (4.9.7)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (0.16.1)\nCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.8.0->object_detection==0.1)\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nCollecting tensorflow-text~=2.8.0 (from tf-models-official==2.8.0->object_detection==0.1)\n  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.8.0->object_detection==0.1) (2.8.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\nCollecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\nRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\nCollecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n  Downloading crcmod-1.7.tar.gz (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.12)\nCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n  Downloading fastavro-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\nCollecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n  Downloading hdfs-2.7.3.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\nCollecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\nCollecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\nRequirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.11.1)\nRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\nRequirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.20.3)\nCollecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\nCollecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n  Downloading redis-5.3.0-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\nCollecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\nRequirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.23.1)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (2.27.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (4.1.1)\nCollecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2025.1.31)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (4.67.1)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (2.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (6.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2.4.1)\nRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\nCollecting PyJWT~=2.9.0 (from redis<6,>=5.0.0->apache-beam->object_detection==0.1)\n  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (5.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.7)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (24.3.25)\nRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.12.1)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.1.2)\nRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.4.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (75.1.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.17.0)\nRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.8.0)\nRequirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (2.8.0.dev2021122109)\nRequirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1) (2.17.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.8.0->object_detection==0.1) (0.1.8)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (0.4.1)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.8.0->object_detection==0.1) (4.9)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.2.2)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->tf-models-official==2.8.0->object_detection==0.1)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (8.1.7)\nRequirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (4.2.1)\nRequirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2.3)\nRequirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.1.6)\nRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.13.1)\nRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.10.2)\nRequirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\nRequirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (1.11.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.45.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (2024.12.0)\nRequirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (5.13.0)\nRequirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (3.21.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (1.66.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.8.0->object_detection==0.1) (5.5.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.8.0->object_detection==0.1) (3.5.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.8.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.1.3)\nINFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\nCollecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official==2.8.0->object_detection==0.1)\n  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (0.5.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.8.0->object_detection==0.1) (1.3)\nRequirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.8.0->object_detection==0.1) (0.16)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (1.3.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.15.4->tf-models-official==2.8.0->object_detection==0.1) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.0.2)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official==2.8.0->object_detection==0.1) (3.2.2)\nDownloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading apache_beam-2.65.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nDownloading cython-3.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\nDownloading fastavro-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\nDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\nDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\nDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\nDownloading redis-5.3.0-py3-none-any.whl (272 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\nDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=21920520 sha256=68ce99efe9c3a9d6cc32871a8073885508cf39de0c64889409897fdf3425e4b8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-fq1ww2_t/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\n  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=95b5863521b083bed4c847c40b87b8eba91f13b3b17fd6a9f6d44aca5833d42d\n  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=99c440fcb4d1bdcd07b6202be062698c98fbde9247a6332ce452d959e0299b99\n  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=4f43f7c0b31866bc0bb0817376eac248754980ed54e0ee6a49f9a756866f0fb7\n  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=093d53b720c7ac1bdb6de4a8db167dc69d1bd600a841a35d9afb325b489c6346\n  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=1c13d315866f24a5bb6a90d29a53959f2a8f327e69bd138aa24e1519ceef1075\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=586d495907c1a6682694c272d3d09744585561c8a337a06a16289efae8178744\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\nSuccessfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\nInstalling collected packages: docopt, crcmod, zstandard, typeguard, tf-keras, pyparsing, PyJWT, pyarrow-hotfix, portalocker, objsize, jsonpickle, grpcio, fasteners, fastavro, dill, Cython, contextlib2, avro-python3, tensorflow-addons, redis, pydot, hdfs, pyarrow, tensorflow-text, tensorflow-model-optimization, seqeval, sacrebleu, tf-models-official, lvis, apache-beam, object_detection\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.1\n    Uninstalling typeguard-4.4.1:\n      Successfully uninstalled typeguard-4.4.1\n  Attempting uninstall: tf-keras\n    Found existing installation: tf_keras 2.17.0\n    Uninstalling tf_keras-2.17.0:\n      Successfully uninstalled tf_keras-2.17.0\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.2.0\n    Uninstalling pyparsing-3.2.0:\n      Successfully uninstalled pyparsing-3.2.0\n  Attempting uninstall: PyJWT\n    Found existing installation: PyJWT 2.10.1\n    Uninstalling PyJWT-2.10.1:\n      Successfully uninstalled PyJWT-2.10.1\n  Attempting uninstall: jsonpickle\n    Found existing installation: jsonpickle 4.0.1\n    Uninstalling jsonpickle-4.0.1:\n      Successfully uninstalled jsonpickle-4.0.1\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.68.1\n    Uninstalling grpcio-1.68.1:\n      Successfully uninstalled grpcio-1.68.1\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: pydot\n    Found existing installation: pydot 3.0.3\n    Uninstalling pydot-3.0.3:\n      Successfully uninstalled pydot-3.0.3\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: tensorflow-text\n    Found existing installation: tensorflow-text 2.17.0\n    Uninstalling tensorflow-text-2.17.0:\n      Successfully uninstalled tensorflow-text-2.17.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ninflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nmultiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nroboflow 1.1.66 requires PyYAML>=5.3.1, but you have pyyaml 5.3 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tf-keras~=2.17, but you have tf-keras 2.15.0 which is incompatible.\nydata-profiling 4.12.2 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Cython-3.1.2 PyJWT-2.9.0 apache-beam-2.65.0 avro-python3-1.10.2 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.11.1 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 lvis-0.5.3 object_detection-0.1 objsize-0.7.1 portalocker-3.2.0 pyarrow-16.1.0 pyarrow-hotfix-0.7 pydot-1.4.2 pyparsing-2.4.7 redis-5.3.0 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-addons-0.23.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.8.2 tf-keras-2.15.0 tf-models-official-2.8.0 typeguard-2.13.3 zstandard-0.23.0\nRunning tests under Python 3.10.12: /usr/bin/python3\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n  logging.warn(('Building experimental DeepMAC meta-arch.'\nW0620 07:05:49.401274 132929902691456 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\nI0620 07:05:49.654911 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.23s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\nI0620 07:05:50.256695 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.6s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\nI0620 07:05:50.651131 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.39s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\nI0620 07:05:50.890740 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\nI0620 07:05:52.601584 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.71s\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\nI0620 07:05:52.602845 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\nI0620 07:05:52.627582 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\nI0620 07:05:52.641819 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\nI0620 07:05:52.656310 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\nI0620 07:05:52.753606 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\nI0620 07:05:52.841708 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\nI0620 07:05:52.934462 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\nI0620 07:05:53.030630 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\nI0620 07:05:53.120140 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\nI0620 07:05:53.147721 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\nI0620 07:05:53.496563 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\nI0620 07:05:53.496770 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\nI0620 07:05:53.496848 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\nI0620 07:05:53.499585 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:53.516576 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:53.516727 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:53.576051 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:53.576242 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:53.729881 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:53.730057 132929902691456 efficientnet_model.py:144] round_filter input=40 output=40\nI0620 07:05:53.882934 132929902691456 efficientnet_model.py:144] round_filter input=40 output=40\nI0620 07:05:53.883101 132929902691456 efficientnet_model.py:144] round_filter input=80 output=80\nI0620 07:05:54.108719 132929902691456 efficientnet_model.py:144] round_filter input=80 output=80\nI0620 07:05:54.108892 132929902691456 efficientnet_model.py:144] round_filter input=112 output=112\nI0620 07:05:54.337668 132929902691456 efficientnet_model.py:144] round_filter input=112 output=112\nI0620 07:05:54.337845 132929902691456 efficientnet_model.py:144] round_filter input=192 output=192\nI0620 07:05:54.652547 132929902691456 efficientnet_model.py:144] round_filter input=192 output=192\nI0620 07:05:54.652719 132929902691456 efficientnet_model.py:144] round_filter input=320 output=320\nI0620 07:05:54.730367 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=1280\nI0620 07:05:54.765088 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:05:54.815904 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\nI0620 07:05:54.816069 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\nI0620 07:05:54.816217 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\nI0620 07:05:54.817897 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:54.832779 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:54.832910 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:54.960108 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:54.960320 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:55.187399 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:55.187628 132929902691456 efficientnet_model.py:144] round_filter input=40 output=40\nI0620 07:05:55.429902 132929902691456 efficientnet_model.py:144] round_filter input=40 output=40\nI0620 07:05:55.430130 132929902691456 efficientnet_model.py:144] round_filter input=80 output=80\nI0620 07:05:55.771920 132929902691456 efficientnet_model.py:144] round_filter input=80 output=80\nI0620 07:05:55.772170 132929902691456 efficientnet_model.py:144] round_filter input=112 output=112\nI0620 07:05:56.087142 132929902691456 efficientnet_model.py:144] round_filter input=112 output=112\nI0620 07:05:56.087355 132929902691456 efficientnet_model.py:144] round_filter input=192 output=192\nI0620 07:05:56.472633 132929902691456 efficientnet_model.py:144] round_filter input=192 output=192\nI0620 07:05:56.472865 132929902691456 efficientnet_model.py:144] round_filter input=320 output=320\nI0620 07:05:56.622487 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=1280\nI0620 07:05:56.654767 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:05:56.715334 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\nI0620 07:05:56.715510 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\nI0620 07:05:56.715642 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\nI0620 07:05:56.717251 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:56.732079 132929902691456 efficientnet_model.py:144] round_filter input=32 output=32\nI0620 07:05:56.732266 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:56.853927 132929902691456 efficientnet_model.py:144] round_filter input=16 output=16\nI0620 07:05:56.854094 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:57.087726 132929902691456 efficientnet_model.py:144] round_filter input=24 output=24\nI0620 07:05:57.087950 132929902691456 efficientnet_model.py:144] round_filter input=40 output=48\nI0620 07:05:57.322660 132929902691456 efficientnet_model.py:144] round_filter input=40 output=48\nI0620 07:05:57.322861 132929902691456 efficientnet_model.py:144] round_filter input=80 output=88\nI0620 07:05:57.634937 132929902691456 efficientnet_model.py:144] round_filter input=80 output=88\nI0620 07:05:57.635143 132929902691456 efficientnet_model.py:144] round_filter input=112 output=120\nI0620 07:05:57.950740 132929902691456 efficientnet_model.py:144] round_filter input=112 output=120\nI0620 07:05:57.950974 132929902691456 efficientnet_model.py:144] round_filter input=192 output=208\nI0620 07:05:58.555098 132929902691456 efficientnet_model.py:144] round_filter input=192 output=208\nI0620 07:05:58.555380 132929902691456 efficientnet_model.py:144] round_filter input=320 output=352\nI0620 07:05:58.717593 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=1408\nI0620 07:05:58.748375 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:05:58.811407 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\nI0620 07:05:58.811583 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\nI0620 07:05:58.811721 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\nI0620 07:05:58.813171 132929902691456 efficientnet_model.py:144] round_filter input=32 output=40\nI0620 07:05:58.828769 132929902691456 efficientnet_model.py:144] round_filter input=32 output=40\nI0620 07:05:58.828927 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:05:58.950678 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:05:58.950852 132929902691456 efficientnet_model.py:144] round_filter input=24 output=32\nI0620 07:05:59.181065 132929902691456 efficientnet_model.py:144] round_filter input=24 output=32\nI0620 07:05:59.181298 132929902691456 efficientnet_model.py:144] round_filter input=40 output=48\nI0620 07:05:59.406995 132929902691456 efficientnet_model.py:144] round_filter input=40 output=48\nI0620 07:05:59.407215 132929902691456 efficientnet_model.py:144] round_filter input=80 output=96\nI0620 07:05:59.803113 132929902691456 efficientnet_model.py:144] round_filter input=80 output=96\nI0620 07:05:59.803350 132929902691456 efficientnet_model.py:144] round_filter input=112 output=136\nI0620 07:06:00.198848 132929902691456 efficientnet_model.py:144] round_filter input=112 output=136\nI0620 07:06:00.199072 132929902691456 efficientnet_model.py:144] round_filter input=192 output=232\nI0620 07:06:00.644318 132929902691456 efficientnet_model.py:144] round_filter input=192 output=232\nI0620 07:06:00.644542 132929902691456 efficientnet_model.py:144] round_filter input=320 output=384\nI0620 07:06:00.800154 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=1536\nI0620 07:06:00.835762 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:06:00.899761 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\nI0620 07:06:00.899924 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\nI0620 07:06:00.900025 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI0620 07:06:00.901497 132929902691456 efficientnet_model.py:144] round_filter input=32 output=48\nI0620 07:06:00.917671 132929902691456 efficientnet_model.py:144] round_filter input=32 output=48\nI0620 07:06:00.917796 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:06:01.046707 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:06:01.046949 132929902691456 efficientnet_model.py:144] round_filter input=24 output=32\nI0620 07:06:01.397776 132929902691456 efficientnet_model.py:144] round_filter input=24 output=32\nI0620 07:06:01.397975 132929902691456 efficientnet_model.py:144] round_filter input=40 output=56\nI0620 07:06:01.713078 132929902691456 efficientnet_model.py:144] round_filter input=40 output=56\nI0620 07:06:01.713299 132929902691456 efficientnet_model.py:144] round_filter input=80 output=112\nI0620 07:06:02.169926 132929902691456 efficientnet_model.py:144] round_filter input=80 output=112\nI0620 07:06:02.170156 132929902691456 efficientnet_model.py:144] round_filter input=112 output=160\nI0620 07:06:02.627740 132929902691456 efficientnet_model.py:144] round_filter input=112 output=160\nI0620 07:06:02.627959 132929902691456 efficientnet_model.py:144] round_filter input=192 output=272\nI0620 07:06:03.260746 132929902691456 efficientnet_model.py:144] round_filter input=192 output=272\nI0620 07:06:03.260957 132929902691456 efficientnet_model.py:144] round_filter input=320 output=448\nI0620 07:06:03.418675 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=1792\nI0620 07:06:03.449945 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:06:03.524863 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\nI0620 07:06:03.525015 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\nI0620 07:06:03.525079 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\nI0620 07:06:03.526769 132929902691456 efficientnet_model.py:144] round_filter input=32 output=48\nI0620 07:06:03.830107 132929902691456 efficientnet_model.py:144] round_filter input=32 output=48\nI0620 07:06:03.830333 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:06:04.015251 132929902691456 efficientnet_model.py:144] round_filter input=16 output=24\nI0620 07:06:04.015476 132929902691456 efficientnet_model.py:144] round_filter input=24 output=40\nI0620 07:06:04.387303 132929902691456 efficientnet_model.py:144] round_filter input=24 output=40\nI0620 07:06:04.387532 132929902691456 efficientnet_model.py:144] round_filter input=40 output=64\nI0620 07:06:04.764484 132929902691456 efficientnet_model.py:144] round_filter input=40 output=64\nI0620 07:06:04.764711 132929902691456 efficientnet_model.py:144] round_filter input=80 output=128\nI0620 07:06:05.313571 132929902691456 efficientnet_model.py:144] round_filter input=80 output=128\nI0620 07:06:05.313781 132929902691456 efficientnet_model.py:144] round_filter input=112 output=176\nI0620 07:06:05.922979 132929902691456 efficientnet_model.py:144] round_filter input=112 output=176\nI0620 07:06:05.923188 132929902691456 efficientnet_model.py:144] round_filter input=192 output=304\nI0620 07:06:06.715862 132929902691456 efficientnet_model.py:144] round_filter input=192 output=304\nI0620 07:06:06.716134 132929902691456 efficientnet_model.py:144] round_filter input=320 output=512\nI0620 07:06:07.060428 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=2048\nI0620 07:06:07.095306 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:06:07.186002 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\nI0620 07:06:07.186185 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI0620 07:06:07.186346 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI0620 07:06:07.188149 132929902691456 efficientnet_model.py:144] round_filter input=32 output=56\nI0620 07:06:07.204131 132929902691456 efficientnet_model.py:144] round_filter input=32 output=56\nI0620 07:06:07.204319 132929902691456 efficientnet_model.py:144] round_filter input=16 output=32\nI0620 07:06:07.398442 132929902691456 efficientnet_model.py:144] round_filter input=16 output=32\nI0620 07:06:07.398603 132929902691456 efficientnet_model.py:144] round_filter input=24 output=40\nI0620 07:06:07.861460 132929902691456 efficientnet_model.py:144] round_filter input=24 output=40\nI0620 07:06:07.861667 132929902691456 efficientnet_model.py:144] round_filter input=40 output=72\nI0620 07:06:08.313403 132929902691456 efficientnet_model.py:144] round_filter input=40 output=72\nI0620 07:06:08.313610 132929902691456 efficientnet_model.py:144] round_filter input=80 output=144\nI0620 07:06:08.905780 132929902691456 efficientnet_model.py:144] round_filter input=80 output=144\nI0620 07:06:08.906009 132929902691456 efficientnet_model.py:144] round_filter input=112 output=200\nI0620 07:06:09.503334 132929902691456 efficientnet_model.py:144] round_filter input=112 output=200\nI0620 07:06:09.503582 132929902691456 efficientnet_model.py:144] round_filter input=192 output=344\nI0620 07:06:10.638675 132929902691456 efficientnet_model.py:144] round_filter input=192 output=344\nI0620 07:06:10.638927 132929902691456 efficientnet_model.py:144] round_filter input=320 output=576\nI0620 07:06:10.895107 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=2304\nI0620 07:06:10.927594 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:06:11.031691 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\nI0620 07:06:11.031877 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\nI0620 07:06:11.031948 132929902691456 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\nI0620 07:06:11.033696 132929902691456 efficientnet_model.py:144] round_filter input=32 output=64\nI0620 07:06:11.049681 132929902691456 efficientnet_model.py:144] round_filter input=32 output=64\nI0620 07:06:11.049827 132929902691456 efficientnet_model.py:144] round_filter input=16 output=32\nI0620 07:06:11.320107 132929902691456 efficientnet_model.py:144] round_filter input=16 output=32\nI0620 07:06:11.320368 132929902691456 efficientnet_model.py:144] round_filter input=24 output=48\nI0620 07:06:11.879839 132929902691456 efficientnet_model.py:144] round_filter input=24 output=48\nI0620 07:06:11.880044 132929902691456 efficientnet_model.py:144] round_filter input=40 output=80\nI0620 07:06:12.457528 132929902691456 efficientnet_model.py:144] round_filter input=40 output=80\nI0620 07:06:12.457746 132929902691456 efficientnet_model.py:144] round_filter input=80 output=160\nI0620 07:06:13.225209 132929902691456 efficientnet_model.py:144] round_filter input=80 output=160\nI0620 07:06:13.225466 132929902691456 efficientnet_model.py:144] round_filter input=112 output=224\nI0620 07:06:14.000155 132929902691456 efficientnet_model.py:144] round_filter input=112 output=224\nI0620 07:06:14.000382 132929902691456 efficientnet_model.py:144] round_filter input=192 output=384\nI0620 07:06:14.982841 132929902691456 efficientnet_model.py:144] round_filter input=192 output=384\nI0620 07:06:14.983090 132929902691456 efficientnet_model.py:144] round_filter input=320 output=640\nI0620 07:06:15.303500 132929902691456 efficientnet_model.py:144] round_filter input=1280 output=2560\nI0620 07:06:15.332589 132929902691456 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\nI0620 07:06:15.453879 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.31s\n[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\nI0620 07:06:15.465879 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\nI0620 07:06:15.467686 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\nI0620 07:06:15.468266 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\nI0620 07:06:15.469874 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n[ RUN      ] ModelBuilderTF2Test.test_session\n[  SKIPPED ] ModelBuilderTF2Test.test_session\n[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\nI0620 07:06:15.471193 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\nI0620 07:06:15.471724 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\nI0620 07:06:15.472823 132929902691456 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n----------------------------------------------------------------------\nRan 24 tests in 28.053s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\nchosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n\nMODELS_CONFIG = {\n    'ssd-mobilenet-v2': {\n        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n    },\n    'efficientdet-d0': {\n        'model_name': 'efficientdet_d0_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n    },\n    'ssd-mobilenet-v2-fpnlite-320': {\n        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n    },\n    # The centernet model isn't working as of 9/10/22\n    #'centernet-mobilenet-v2': {\n    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n    #    'base_pipeline_file': 'pipeline.config',\n    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n    #}\n}\n\nmodel_name = MODELS_CONFIG[chosen_model]['model_name']\npretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\nbase_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:17.156113Z","iopub.execute_input":"2025-06-20T07:06:17.156375Z","iopub.status.idle":"2025-06-20T07:06:17.161704Z","shell.execute_reply.started":"2025-06-20T07:06:17.156352Z","shell.execute_reply":"2025-06-20T07:06:17.160946Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n%mkdir /kaggle/working/models/mymodel/\n%cd /kaggle/working/models/mymodel/\n\n# Download pre-trained model weights\nimport tarfile\ndownload_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n!wget {download_tar}\ntar = tarfile.open(pretrained_checkpoint)\ntar.extractall()\ntar.close()\n\n# Download training configuration file for model\ndownload_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n!wget {download_config}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:17.163664Z","iopub.execute_input":"2025-06-20T07:06:17.163914Z","iopub.status.idle":"2025-06-20T07:06:18.390721Z","shell.execute_reply.started":"2025-06-20T07:06:17.163893Z","shell.execute_reply":"2025-06-20T07:06:18.389586Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/models/mymodel\n--2025-06-20 07:06:17--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\nResolving download.tensorflow.org (download.tensorflow.org)... 108.177.12.207, 74.125.26.207, 172.217.204.207, ...\nConnecting to download.tensorflow.org (download.tensorflow.org)|108.177.12.207|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20515344 (20M) [application/x-tar]\nSaving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n\nssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n\n2025-06-20 07:06:17 (165 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n\n--2025-06-20 07:06:18--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4684 (4.6K) [text/plain]\nSaving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config’\n\nssd_mobilenet_v2_fp 100%[===================>]   4.57K  --.-KB/s    in 0s      \n\n2025-06-20 07:06:18 (43.1 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config’ saved [4684/4684]\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Set training parameters for the model\nnum_steps =1000\nbatch_size = 16\n\n# print(batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:18.391843Z","iopub.execute_input":"2025-06-20T07:06:18.392069Z","iopub.status.idle":"2025-06-20T07:06:18.396159Z","shell.execute_reply.started":"2025-06-20T07:06:18.392049Z","shell.execute_reply":"2025-06-20T07:06:18.395243Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import os\n\ndef get_file_by_extension(folder, extension):\n    \"\"\"Mencari file dengan ekstensi tertentu di dalam folder.\"\"\"\n    for file in os.listdir(folder):\n        if file.endswith(extension):\n            return os.path.join(folder, file)\n    return None  # Jika tidak ditemukan\n\n# Dataset di Kaggle biasanya ada di folder \ndataset_location = dataset.location\n\n# Folder train dan test\ntrain_folder = os.path.join(dataset_location, 'train')\nval_folder = os.path.join(dataset_location, 'valid')\ntest_folder = os.path.join(dataset_location, 'test')\n\n# Cari file .tfrecord dan .pbtxt secara otomatis\ntest_record_fname = get_file_by_extension(test_folder, \".tfrecord\")\nval_record_fname = get_file_by_extension(val_folder, \".tfrecord\")\ntrain_record_fname = get_file_by_extension(train_folder, \".tfrecord\")\nlabel_map_pbtxt_fname = get_file_by_extension(train_folder, \".pbtxt\")\n# Set file locations and get number of classes for config file\npipeline_fname = '/kaggle/working/models/mymodel/' + base_pipeline_file\nfine_tune_checkpoint = '/kaggle/working/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n# Cetak hasil\nprint(\"Test Record:\", test_record_fname)\nprint(\"Val Record:\", val_record_fname)\nprint(\"Train Record:\", train_record_fname)\nprint(\"Label Map:\", label_map_pbtxt_fname)\n\ndef get_num_classes(pbtxt_fname):\n    from object_detection.utils import label_map_util\n    label_map = label_map_util.load_labelmap(pbtxt_fname)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=90, use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n    return len(category_index.keys())\nnum_classes = get_num_classes(label_map_pbtxt_fname)\nprint('Total classes:', num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:18.397263Z","iopub.execute_input":"2025-06-20T07:06:18.397647Z","iopub.status.idle":"2025-06-20T07:06:21.239799Z","shell.execute_reply.started":"2025-06-20T07:06:18.397611Z","shell.execute_reply":"2025-06-20T07:06:21.239054Z"}},"outputs":[{"name":"stdout","text":"Test Record: /kaggle/working/@25M(3class)-4/test/1-QDa5-FSKD.tfrecord\nVal Record: /kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord\nTrain Record: /kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord\nLabel Map: /kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD_label_map.pbtxt\nTotal classes: 3\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\nimport re\n\n#train_record_fname = '/kaggle/working/vehicle-detection-1/train/vehicles.tfrecord'\n#val_record_fname = '/kaggle/working/vehicle-detection-1/valid/vehicles.tfrecord'\n\n%cd /kaggle/working/models/mymodel\nprint('writing custom configuration file')\n\nwith open(pipeline_fname) as f:\n    s = f.read()\nwith open('pipeline_file.config', 'w') as f:\n\n    # Set fine_tune_checkpoint path\n    s = re.sub('fine_tune_checkpoint: \".*?\"',\n               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n\n    # Set tfrecord files for train and test datasets\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n\n    # Set label_map_path\n    s = re.sub(\n        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n\n    # Set batch_size\n    s = re.sub('batch_size: [0-9]+',\n               'batch_size: {}'.format(16), s)\n\n    # Set training steps, num_steps\n    s = re.sub('num_steps: [0-9]+',\n               'num_steps: {}'.format(num_steps), s)\n\n    # Set number of classes num_classes\n    s = re.sub('num_classes: [0-9]+',\n               'num_classes: {}'.format(num_classes), s)\n\n    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n    s = re.sub(\n        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n\n    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n    if chosen_model == 'ssd-mobilenet-v2-fpnlite-320':\n      s = re.sub('learning_rate_base: 0.001',\n                 'learning_rate_base: 0.0001', s)\n\n      s = re.sub('warmup_learning_rate: 0.001',\n                 'warmup_learning_rate: 0.001', s)\n\n    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n    if chosen_model == 'ssd-mobilenet-v2-fpnlite-320':\n      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n      s = re.sub('pad_to_max_dimension: true', '', s)\n      s = re.sub('min_dimension', 'height', s)\n      s = re.sub('max_dimension', 'width', s)\n   \n\n    f.write(s)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.240633Z","iopub.execute_input":"2025-06-20T07:06:21.241152Z","iopub.status.idle":"2025-06-20T07:06:21.254316Z","shell.execute_reply.started":"2025-06-20T07:06:21.241129Z","shell.execute_reply":"2025-06-20T07:06:21.253617Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/models/mymodel\nwriting custom configuration file\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Set the path to the custom config file and the directory to store training checkpoints in\n# %mkdir /content/training\npipeline_file = '/kaggle/working/models/mymodel/pipeline_file.config'\nmodel_dir = '/kaggle/working/training/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.255130Z","iopub.execute_input":"2025-06-20T07:06:21.255380Z","iopub.status.idle":"2025-06-20T07:06:21.270490Z","shell.execute_reply.started":"2025-06-20T07:06:21.255359Z","shell.execute_reply":"2025-06-20T07:06:21.269746Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n%%writefile /kaggle/working/models/mymodel/pipeline_file.config\n# SSD with Mobilenet v2 FPN-lite (go/fpn-lite) feature extractor, shared box\n# predictor and focal loss (a mobile version of Retinanet).\n# Retinanet: see Lin et al, https://arxiv.org/abs/1708.02002\n# Trained on COCO, initialized from Imagenet classification checkpoint\n# Train on TPU-8\n#\n# Achieves 22.2 mAP on COCO17 Val\n\nmodel {\n  ssd {\n    inplace_batchnorm_update: true\n    freeze_batchnorm: false\n    num_classes: 3\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n        use_matmul_gather: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    encode_background_as_zeros: true\n    anchor_generator {\n      multiscale_anchor_generator {\n        min_level: 3\n        max_level: 7\n        anchor_scale: 1.0\n        aspect_ratios: [0.5, 0.75, 1.0, 1.5]\n        scales_per_octave: 2\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 512\n        width: 512\n      }\n    }\n    box_predictor {\n      weight_shared_convolutional_box_predictor {\n        depth: 128\n        class_prediction_bias_init: -4.6\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            random_normal_initializer {\n              stddev: 0.01\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            scale: true,\n            decay: 0.997,\n            epsilon: 0.001,\n          }\n        }\n        num_layers_before_predictor: 4\n        share_prediction_tower: true\n        use_depthwise: true\n        kernel_size: 3\n      }\n    }\n    feature_extractor {\n      type: 'ssd_mobilenet_v2_fpn_keras'\n      use_depthwise: true\n      fpn {\n        min_level: 3\n        max_level: 7\n        additional_layer_depth: 128\n      }\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          random_normal_initializer {\n            stddev: 0.01\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          scale: true,\n          decay: 0.997,\n          epsilon: 0.001,\n        }\n      }\n      override_base_feature_extractor_hyperparams: true\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid_focal {\n          alpha: 0.35\n          gamma: 2.0\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      classification_weight: 2.0\n      localization_weight: 2.0\n    }\n    normalize_loss_by_num_matches: true\n    normalize_loc_loss_by_codesize: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config {\n  fine_tune_checkpoint_version: V2\n  fine_tune_checkpoint: \"/kaggle/working/models/mymodel/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n  fine_tune_checkpoint_type: \"detection\"\n  batch_size: 16\n  sync_replicas: true\n  startup_delay_steps: 0\n  replicas_to_aggregate: 8\n  num_steps: 80000\n  \n\n\n  data_augmentation_options {\n    random_horizontal_flip {}\n  }\n  data_augmentation_options {\n    random_crop_image {\n      min_object_covered: 0.0\n      min_aspect_ratio: 0.5\n      max_aspect_ratio: 1.7\n      min_area: 0.75\n      max_area: 1.0\n      overlap_thresh: 0.0\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_hue {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_contrast {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_saturation {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_brightness {\n    }\n  }\n\n  data_augmentation_options {\n   random_vertical_flip {\n   }\n }\n  data_augmentation_options {\n   random_rotation90 {\n   }\n }\n\n  optimizer {\n    adam_optimizer {\n      learning_rate {\n        cosine_decay_learning_rate {\n          learning_rate_base: 0.00002\n          total_steps: 80000\n          warmup_learning_rate: 0.00002\n          warmup_steps: 1000\n        }\n      }\n     \n      epsilon: 1e-8\n    }\n    use_moving_average: false\n  }\n\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n}\n\n\n \n\ntrain_input_reader: {\n  label_map_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD_label_map.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n}\n\neval_input_reader: {\n  label_map_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD_label_map.pbtxt\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord\"\n  }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.271403Z","iopub.execute_input":"2025-06-20T07:06:21.271708Z","iopub.status.idle":"2025-06-20T07:06:21.284223Z","shell.execute_reply.started":"2025-06-20T07:06:21.271661Z","shell.execute_reply":"2025-06-20T07:06:21.283462Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/models/mymodel/pipeline_file.config\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# (Optional) Display the custom configuration file's contents\n!cat /kaggle/working/models/mymodel/pipeline_file.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.285154Z","iopub.execute_input":"2025-06-20T07:06:21.285452Z","iopub.status.idle":"2025-06-20T07:06:21.425670Z","shell.execute_reply.started":"2025-06-20T07:06:21.285431Z","shell.execute_reply":"2025-06-20T07:06:21.424644Z"}},"outputs":[{"name":"stdout","text":"# SSD with Mobilenet v2 FPN-lite (go/fpn-lite) feature extractor, shared box\n# predictor and focal loss (a mobile version of Retinanet).\n# Retinanet: see Lin et al, https://arxiv.org/abs/1708.02002\n# Trained on COCO, initialized from Imagenet classification checkpoint\n# Train on TPU-8\n#\n# Achieves 22.2 mAP on COCO17 Val\n\nmodel {\n  ssd {\n    inplace_batchnorm_update: true\n    freeze_batchnorm: false\n    num_classes: 3\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n        use_matmul_gather: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    encode_background_as_zeros: true\n    anchor_generator {\n      multiscale_anchor_generator {\n        min_level: 3\n        max_level: 7\n        anchor_scale: 1.0\n        aspect_ratios: [0.5, 0.75, 1.0, 1.5]\n        scales_per_octave: 2\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 512\n        width: 512\n      }\n    }\n    box_predictor {\n      weight_shared_convolutional_box_predictor {\n        depth: 128\n        class_prediction_bias_init: -4.6\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            random_normal_initializer {\n              stddev: 0.01\n              mean: 0.0\n            }\n          }\n          batch_norm {\n            scale: true,\n            decay: 0.997,\n            epsilon: 0.001,\n          }\n        }\n        num_layers_before_predictor: 4\n        share_prediction_tower: true\n        use_depthwise: true\n        kernel_size: 3\n      }\n    }\n    feature_extractor {\n      type: 'ssd_mobilenet_v2_fpn_keras'\n      use_depthwise: true\n      fpn {\n        min_level: 3\n        max_level: 7\n        additional_layer_depth: 128\n      }\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          random_normal_initializer {\n            stddev: 0.01\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          scale: true,\n          decay: 0.997,\n          epsilon: 0.001,\n        }\n      }\n      override_base_feature_extractor_hyperparams: true\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid_focal {\n          alpha: 0.35\n          gamma: 2.0\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      classification_weight: 2.0\n      localization_weight: 2.0\n    }\n    normalize_loss_by_num_matches: true\n    normalize_loc_loss_by_codesize: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config {\n  fine_tune_checkpoint_version: V2\n  fine_tune_checkpoint: \"/kaggle/working/models/mymodel/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n  fine_tune_checkpoint_type: \"detection\"\n  batch_size: 16\n  sync_replicas: true\n  startup_delay_steps: 0\n  replicas_to_aggregate: 8\n  num_steps: 80000\n  \n\n\n  data_augmentation_options {\n    random_horizontal_flip {}\n  }\n  data_augmentation_options {\n    random_crop_image {\n      min_object_covered: 0.0\n      min_aspect_ratio: 0.5\n      max_aspect_ratio: 1.7\n      min_area: 0.75\n      max_area: 1.0\n      overlap_thresh: 0.0\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_hue {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_contrast {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_saturation {\n    }\n  }\n\n  data_augmentation_options {\n    random_adjust_brightness {\n    }\n  }\n\n  data_augmentation_options {\n   random_vertical_flip {\n   }\n }\n  data_augmentation_options {\n   random_rotation90 {\n   }\n }\n\n  optimizer {\n    adam_optimizer {\n      learning_rate {\n        cosine_decay_learning_rate {\n          learning_rate_base: 0.00002\n          total_steps: 80000\n          warmup_learning_rate: 0.00002\n          warmup_steps: 1000\n        }\n      }\n     \n      epsilon: 1e-8\n    }\n    use_moving_average: false\n  }\n\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n}\n\n\n \n\ntrain_input_reader: {\n  label_map_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD_label_map.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n}\n\neval_input_reader: {\n  label_map_path: \"/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD_label_map.pbtxt\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord\"\n  }\n}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":" #%load_ext tensorboard\n #%reload_ext tensorboard\n #%tensorboard --logdir '/kaggle/working/training/train' --port 6009\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.426933Z","iopub.execute_input":"2025-06-20T07:06:21.427315Z","iopub.status.idle":"2025-06-20T07:06:21.431173Z","shell.execute_reply.started":"2025-06-20T07:06:21.427278Z","shell.execute_reply":"2025-06-20T07:06:21.430292Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# # Run training!\n# !python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n#     --pipeline_config_path={pipeline_file} \\\n#     --model_dir={model_dir} \\\n#     --alsologtostderr \\\n#     --num_train_steps={num_steps} \\\n#     --sample_1_of_n_eval_examples=1\n\npipeline_file = \"/kaggle/working/models/mymodel/pipeline_file.config\"\nmodel_dir = \"/kaggle/working/training\"\nnum_iterations = 4          # berapa kali train+eval akan diulang\nsteps_per_iter = 12500        # jumlah step setiap loop\n\nfor i in range(num_iterations):\n    print(f\"\\n🟢 Training iterasi ke-{i+1} ({(i)*steps_per_iter} -> {(i+1)*steps_per_iter} steps)\")\n    !python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n        --pipeline_config_path={pipeline_file} \\\n        --model_dir={model_dir} \\\n        --alsologtostderr \\\n        --num_train_steps={(i+1)*steps_per_iter}\n\n    print(f\"\\n🔵 Evaluasi setelah iterasi ke-{i+1}\")\n    !python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n        --pipeline_config_path={pipeline_file} \\\n        --model_dir={model_dir} \\\n        --checkpoint_dir={model_dir} \\\n        --alsologtostderr \\\n        --sample_1_of_n_eval_examples=1\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T07:06:21.432179Z","iopub.execute_input":"2025-06-20T07:06:21.432453Z","iopub.status.idle":"2025-06-20T14:07:30.691354Z","shell.execute_reply.started":"2025-06-20T07:06:21.432432Z","shell.execute_reply":"2025-06-20T14:07:30.690355Z"}},"outputs":[{"name":"stdout","text":"\n🟢 Training iterasi ke-1 (0 -> 12500 steps)\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nI0620 07:06:27.197373 132867512947840 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI0620 07:06:27.202103 132867512947840 config_util.py:552] Maybe overwriting train_steps: 12500\nI0620 07:06:27.202305 132867512947840 config_util.py:552] Maybe overwriting use_bfloat16: False\nW0620 07:06:27.371285 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI0620 07:06:27.376741 132867512947840 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 07:06:27.377094 132867512947840 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 07:06:27.377264 132867512947840 dataset_builder.py:80] Number of filenames to read: 1\nW0620 07:06:27.377378 132867512947840 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 07:06:27.382618 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 07:06:27.414804 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 07:06:33.824102 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 07:06:36.536914 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nW0620 07:06:39.057810 132867512947840 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 07:06:48.456056 132860182787648 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:06:58.039299 132860266649152 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:03.389399 132860266649152 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:06.901479 132860182787648 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:19.491176 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.493053 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.495296 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.496398 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.498486 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.499450 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.501732 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.502839 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.505046 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 07:07:19.506108 132867512947840 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nW0620 07:07:20.276731 132861608851008 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\nI0620 07:07:21.249900 132861608851008 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:27.186533 132860140836416 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:31.589166 132867512947840 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 07:07:37.758607 132860140836416 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:42.752543 132861608851008 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:46.969653 132867512947840 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 07:07:52.342597 132861608851008 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:07:57.440133 132860140836416 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:08:01.583976 132867512947840 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 07:08:07.020141 132860140836416 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:08:12.047226 132861608851008 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 07:08:16.391119 132867512947840 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 07:09:25.737540 132867512947840 model_lib_v2.py:705] Step 100 per-step time 1.260s\nI0620 07:09:25.737927 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 3.1639977,\n 'Loss/localization_loss': 1.7191021,\n 'Loss/regularization_loss': 0.15290557,\n 'Loss/total_loss': 5.036005,\n 'learning_rate': 2e-05}\nI0620 07:10:10.025070 132867512947840 model_lib_v2.py:705] Step 200 per-step time 0.443s\nI0620 07:10:10.025525 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 3.1493523,\n 'Loss/localization_loss': 1.8669136,\n 'Loss/regularization_loss': 0.1524224,\n 'Loss/total_loss': 5.1686883,\n 'learning_rate': 2e-05}\nI0620 07:10:54.415351 132867512947840 model_lib_v2.py:705] Step 300 per-step time 0.444s\nI0620 07:10:54.415760 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 3.097643,\n 'Loss/localization_loss': 1.8798339,\n 'Loss/regularization_loss': 0.15216014,\n 'Loss/total_loss': 5.129637,\n 'learning_rate': 2e-05}\nI0620 07:11:39.157620 132867512947840 model_lib_v2.py:705] Step 400 per-step time 0.447s\nI0620 07:11:39.157993 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 3.0102448,\n 'Loss/localization_loss': 1.7259898,\n 'Loss/regularization_loss': 0.1520166,\n 'Loss/total_loss': 4.8882513,\n 'learning_rate': 2e-05}\nI0620 07:12:23.746408 132867512947840 model_lib_v2.py:705] Step 500 per-step time 0.446s\nI0620 07:12:23.746822 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.9275446,\n 'Loss/localization_loss': 1.7801385,\n 'Loss/regularization_loss': 0.15193388,\n 'Loss/total_loss': 4.8596168,\n 'learning_rate': 2e-05}\nI0620 07:13:08.082526 132867512947840 model_lib_v2.py:705] Step 600 per-step time 0.443s\nI0620 07:13:08.082961 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.7545934,\n 'Loss/localization_loss': 1.7231505,\n 'Loss/regularization_loss': 0.1518782,\n 'Loss/total_loss': 4.629622,\n 'learning_rate': 2e-05}\nI0620 07:13:52.483870 132867512947840 model_lib_v2.py:705] Step 700 per-step time 0.444s\nI0620 07:13:52.484339 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.7228746,\n 'Loss/localization_loss': 1.6842142,\n 'Loss/regularization_loss': 0.15183415,\n 'Loss/total_loss': 4.558923,\n 'learning_rate': 2e-05}\nI0620 07:14:36.902070 132867512947840 model_lib_v2.py:705] Step 800 per-step time 0.444s\nI0620 07:14:36.902469 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.4957967,\n 'Loss/localization_loss': 1.6625156,\n 'Loss/regularization_loss': 0.15179646,\n 'Loss/total_loss': 4.3101087,\n 'learning_rate': 2e-05}\nI0620 07:15:21.300893 132867512947840 model_lib_v2.py:705] Step 900 per-step time 0.444s\nI0620 07:15:21.301326 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.5073252,\n 'Loss/localization_loss': 1.6475077,\n 'Loss/regularization_loss': 0.15176512,\n 'Loss/total_loss': 4.3065987,\n 'learning_rate': 2e-05}\nI0620 07:16:05.889172 132867512947840 model_lib_v2.py:705] Step 1000 per-step time 0.446s\nI0620 07:16:05.889633 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.3935165,\n 'Loss/localization_loss': 1.754314,\n 'Loss/regularization_loss': 0.1517373,\n 'Loss/total_loss': 4.299568,\n 'learning_rate': 2e-05}\nI0620 07:16:50.998825 132867512947840 model_lib_v2.py:705] Step 1100 per-step time 0.451s\nI0620 07:16:50.999396 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.4562411,\n 'Loss/localization_loss': 1.8180016,\n 'Loss/regularization_loss': 0.15171267,\n 'Loss/total_loss': 4.425956,\n 'learning_rate': 1.9999921e-05}\nI0620 07:17:35.516771 132867512947840 model_lib_v2.py:705] Step 1200 per-step time 0.445s\nI0620 07:17:35.517208 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.5489907,\n 'Loss/localization_loss': 1.9955192,\n 'Loss/regularization_loss': 0.15168972,\n 'Loss/total_loss': 4.6961994,\n 'learning_rate': 1.9999683e-05}\nI0620 07:18:19.644412 132867512947840 model_lib_v2.py:705] Step 1300 per-step time 0.441s\nI0620 07:18:19.644938 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.171338,\n 'Loss/localization_loss': 1.6945884,\n 'Loss/regularization_loss': 0.1516687,\n 'Loss/total_loss': 4.0175953,\n 'learning_rate': 1.9999288e-05}\nI0620 07:19:04.191100 132867512947840 model_lib_v2.py:705] Step 1400 per-step time 0.445s\nI0620 07:19:04.191576 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.0086417,\n 'Loss/localization_loss': 1.6607362,\n 'Loss/regularization_loss': 0.15164796,\n 'Loss/total_loss': 3.8210258,\n 'learning_rate': 1.9998735e-05}\nI0620 07:19:48.807593 132867512947840 model_lib_v2.py:705] Step 1500 per-step time 0.446s\nI0620 07:19:48.808012 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 2.0782099,\n 'Loss/localization_loss': 1.6383781,\n 'Loss/regularization_loss': 0.15162928,\n 'Loss/total_loss': 3.868217,\n 'learning_rate': 1.9998022e-05}\nI0620 07:20:33.044159 132867512947840 model_lib_v2.py:705] Step 1600 per-step time 0.442s\nI0620 07:20:33.044565 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.7944727,\n 'Loss/localization_loss': 1.7292328,\n 'Loss/regularization_loss': 0.15161052,\n 'Loss/total_loss': 3.6753159,\n 'learning_rate': 1.9997153e-05}\nI0620 07:21:17.260294 132867512947840 model_lib_v2.py:705] Step 1700 per-step time 0.442s\nI0620 07:21:17.260788 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.8948617,\n 'Loss/localization_loss': 1.6462419,\n 'Loss/regularization_loss': 0.1515924,\n 'Loss/total_loss': 3.6926963,\n 'learning_rate': 1.9996125e-05}\nI0620 07:22:01.886590 132867512947840 model_lib_v2.py:705] Step 1800 per-step time 0.446s\nI0620 07:22:01.887003 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.7872342,\n 'Loss/localization_loss': 1.6310313,\n 'Loss/regularization_loss': 0.15157528,\n 'Loss/total_loss': 3.5698407,\n 'learning_rate': 1.999494e-05}\nI0620 07:22:46.508285 132867512947840 model_lib_v2.py:705] Step 1900 per-step time 0.446s\nI0620 07:22:46.508705 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.6051381,\n 'Loss/localization_loss': 1.4158726,\n 'Loss/regularization_loss': 0.15155786,\n 'Loss/total_loss': 3.1725683,\n 'learning_rate': 1.9993595e-05}\nI0620 07:23:31.107690 132867512947840 model_lib_v2.py:705] Step 2000 per-step time 0.446s\nI0620 07:23:31.108101 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.9722763,\n 'Loss/localization_loss': 1.6443279,\n 'Loss/regularization_loss': 0.15154047,\n 'Loss/total_loss': 3.7681446,\n 'learning_rate': 1.9992094e-05}\nI0620 07:24:16.213735 132867512947840 model_lib_v2.py:705] Step 2100 per-step time 0.451s\nI0620 07:24:16.214138 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.4962285,\n 'Loss/localization_loss': 1.7025334,\n 'Loss/regularization_loss': 0.15152381,\n 'Loss/total_loss': 3.3502855,\n 'learning_rate': 1.9990433e-05}\nI0620 07:25:00.605167 132867512947840 model_lib_v2.py:705] Step 2200 per-step time 0.444s\nI0620 07:25:00.605613 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.7353609,\n 'Loss/localization_loss': 1.5070566,\n 'Loss/regularization_loss': 0.151508,\n 'Loss/total_loss': 3.3939257,\n 'learning_rate': 1.9988614e-05}\nI0620 07:25:44.849920 132867512947840 model_lib_v2.py:705] Step 2300 per-step time 0.442s\nI0620 07:25:44.850339 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.7169445,\n 'Loss/localization_loss': 1.6541137,\n 'Loss/regularization_loss': 0.15149206,\n 'Loss/total_loss': 3.52255,\n 'learning_rate': 1.9986639e-05}\nI0620 07:26:29.219885 132867512947840 model_lib_v2.py:705] Step 2400 per-step time 0.444s\nI0620 07:26:29.220332 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.6434534,\n 'Loss/localization_loss': 1.597447,\n 'Loss/regularization_loss': 0.15147582,\n 'Loss/total_loss': 3.3923764,\n 'learning_rate': 1.9984505e-05}\nI0620 07:27:13.579344 132867512947840 model_lib_v2.py:705] Step 2500 per-step time 0.444s\nI0620 07:27:13.579732 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.4591539,\n 'Loss/localization_loss': 1.4761269,\n 'Loss/regularization_loss': 0.15145998,\n 'Loss/total_loss': 3.0867407,\n 'learning_rate': 1.9982213e-05}\nI0620 07:27:58.120980 132867512947840 model_lib_v2.py:705] Step 2600 per-step time 0.445s\nI0620 07:27:58.121388 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.7175729,\n 'Loss/localization_loss': 1.5585265,\n 'Loss/regularization_loss': 0.15144409,\n 'Loss/total_loss': 3.4275439,\n 'learning_rate': 1.9979765e-05}\nI0620 07:28:42.536792 132867512947840 model_lib_v2.py:705] Step 2700 per-step time 0.444s\nI0620 07:28:42.537221 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.27936,\n 'Loss/localization_loss': 1.4742718,\n 'Loss/regularization_loss': 0.15142794,\n 'Loss/total_loss': 2.9050598,\n 'learning_rate': 1.9977157e-05}\nI0620 07:29:26.956977 132867512947840 model_lib_v2.py:705] Step 2800 per-step time 0.444s\nI0620 07:29:26.957441 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.4948475,\n 'Loss/localization_loss': 1.5207543,\n 'Loss/regularization_loss': 0.15141158,\n 'Loss/total_loss': 3.1670134,\n 'learning_rate': 1.9974392e-05}\nI0620 07:30:11.546617 132867512947840 model_lib_v2.py:705] Step 2900 per-step time 0.446s\nI0620 07:30:11.546984 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.581259,\n 'Loss/localization_loss': 1.4938587,\n 'Loss/regularization_loss': 0.1513956,\n 'Loss/total_loss': 3.2265134,\n 'learning_rate': 1.9971469e-05}\nI0620 07:30:55.900331 132867512947840 model_lib_v2.py:705] Step 3000 per-step time 0.444s\nI0620 07:30:55.900876 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.4445181,\n 'Loss/localization_loss': 1.6574771,\n 'Loss/regularization_loss': 0.15137997,\n 'Loss/total_loss': 3.2533753,\n 'learning_rate': 1.9968387e-05}\nI0620 07:31:41.063332 132867512947840 model_lib_v2.py:705] Step 3100 per-step time 0.452s\nI0620 07:31:41.063726 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.4263672,\n 'Loss/localization_loss': 1.5945411,\n 'Loss/regularization_loss': 0.15136409,\n 'Loss/total_loss': 3.1722722,\n 'learning_rate': 1.996515e-05}\nI0620 07:32:25.579121 132867512947840 model_lib_v2.py:705] Step 3200 per-step time 0.445s\nI0620 07:32:25.579550 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.328192,\n 'Loss/localization_loss': 1.4739094,\n 'Loss/regularization_loss': 0.15134795,\n 'Loss/total_loss': 2.9534492,\n 'learning_rate': 1.9961753e-05}\nI0620 07:33:10.069755 132867512947840 model_lib_v2.py:705] Step 3300 per-step time 0.445s\nI0620 07:33:10.070132 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.2612269,\n 'Loss/localization_loss': 1.557589,\n 'Loss/regularization_loss': 0.15133181,\n 'Loss/total_loss': 2.9701476,\n 'learning_rate': 1.99582e-05}\nI0620 07:33:54.685871 132867512947840 model_lib_v2.py:705] Step 3400 per-step time 0.446s\nI0620 07:33:54.686315 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.2934854,\n 'Loss/localization_loss': 1.6425533,\n 'Loss/regularization_loss': 0.15131582,\n 'Loss/total_loss': 3.0873547,\n 'learning_rate': 1.995449e-05}\nI0620 07:34:39.114621 132867512947840 model_lib_v2.py:705] Step 3500 per-step time 0.444s\nI0620 07:34:39.115064 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.3961625,\n 'Loss/localization_loss': 1.5278244,\n 'Loss/regularization_loss': 0.15129924,\n 'Loss/total_loss': 3.0752861,\n 'learning_rate': 1.9950621e-05}\nI0620 07:35:23.278555 132867512947840 model_lib_v2.py:705] Step 3600 per-step time 0.442s\nI0620 07:35:23.279237 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.126133,\n 'Loss/localization_loss': 1.4885906,\n 'Loss/regularization_loss': 0.15128292,\n 'Loss/total_loss': 2.7660067,\n 'learning_rate': 1.9946596e-05}\nI0620 07:36:07.842648 132867512947840 model_lib_v2.py:705] Step 3700 per-step time 0.446s\nI0620 07:36:07.843063 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1324459,\n 'Loss/localization_loss': 1.4783454,\n 'Loss/regularization_loss': 0.15126617,\n 'Loss/total_loss': 2.7620575,\n 'learning_rate': 1.9942412e-05}\nI0620 07:36:52.389792 132867512947840 model_lib_v2.py:705] Step 3800 per-step time 0.445s\nI0620 07:36:52.390120 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1984634,\n 'Loss/localization_loss': 1.4003475,\n 'Loss/regularization_loss': 0.1512494,\n 'Loss/total_loss': 2.7500606,\n 'learning_rate': 1.9938072e-05}\nI0620 07:37:36.766660 132867512947840 model_lib_v2.py:705] Step 3900 per-step time 0.444s\nI0620 07:37:36.767050 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1707327,\n 'Loss/localization_loss': 1.5310118,\n 'Loss/regularization_loss': 0.15123247,\n 'Loss/total_loss': 2.852977,\n 'learning_rate': 1.9933575e-05}\nI0620 07:38:21.471849 132867512947840 model_lib_v2.py:705] Step 4000 per-step time 0.447s\nI0620 07:38:21.472282 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.2341069,\n 'Loss/localization_loss': 1.5658724,\n 'Loss/regularization_loss': 0.15121485,\n 'Loss/total_loss': 2.9511943,\n 'learning_rate': 1.992892e-05}\nI0620 07:39:07.189909 132867512947840 model_lib_v2.py:705] Step 4100 per-step time 0.457s\nI0620 07:39:07.190357 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1452594,\n 'Loss/localization_loss': 1.5467365,\n 'Loss/regularization_loss': 0.15119714,\n 'Loss/total_loss': 2.843193,\n 'learning_rate': 1.9924108e-05}\nI0620 07:39:51.526529 132867512947840 model_lib_v2.py:705] Step 4200 per-step time 0.443s\nI0620 07:39:51.526964 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.2959602,\n 'Loss/localization_loss': 1.5739541,\n 'Loss/regularization_loss': 0.15117972,\n 'Loss/total_loss': 3.021094,\n 'learning_rate': 1.991914e-05}\nI0620 07:40:35.891568 132867512947840 model_lib_v2.py:705] Step 4300 per-step time 0.444s\nI0620 07:40:35.891956 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1862144,\n 'Loss/localization_loss': 1.5534674,\n 'Loss/regularization_loss': 0.15116179,\n 'Loss/total_loss': 2.8908434,\n 'learning_rate': 1.9914016e-05}\nI0620 07:41:20.355749 132867512947840 model_lib_v2.py:705] Step 4400 per-step time 0.445s\nI0620 07:41:20.356157 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0190668,\n 'Loss/localization_loss': 1.4039438,\n 'Loss/regularization_loss': 0.15114374,\n 'Loss/total_loss': 2.5741544,\n 'learning_rate': 1.9908734e-05}\nI0620 07:42:04.820487 132867512947840 model_lib_v2.py:705] Step 4500 per-step time 0.445s\nI0620 07:42:04.820889 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0502714,\n 'Loss/localization_loss': 1.5729471,\n 'Loss/regularization_loss': 0.15112619,\n 'Loss/total_loss': 2.7743447,\n 'learning_rate': 1.9903295e-05}\nI0620 07:42:49.015833 132867512947840 model_lib_v2.py:705] Step 4600 per-step time 0.442s\nI0620 07:42:49.016223 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0763408,\n 'Loss/localization_loss': 1.4212767,\n 'Loss/regularization_loss': 0.15110782,\n 'Loss/total_loss': 2.6487253,\n 'learning_rate': 1.98977e-05}\nI0620 07:43:33.503971 132867512947840 model_lib_v2.py:705] Step 4700 per-step time 0.445s\nI0620 07:43:33.504414 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1346685,\n 'Loss/localization_loss': 1.3925018,\n 'Loss/regularization_loss': 0.15108934,\n 'Loss/total_loss': 2.6782596,\n 'learning_rate': 1.9891948e-05}\nI0620 07:44:17.949447 132867512947840 model_lib_v2.py:705] Step 4800 per-step time 0.444s\nI0620 07:44:17.949886 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0400982,\n 'Loss/localization_loss': 1.366395,\n 'Loss/regularization_loss': 0.15107086,\n 'Loss/total_loss': 2.5575643,\n 'learning_rate': 1.9886038e-05}\nI0620 07:45:02.333598 132867512947840 model_lib_v2.py:705] Step 4900 per-step time 0.444s\nI0620 07:45:02.334027 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1514125,\n 'Loss/localization_loss': 1.5503266,\n 'Loss/regularization_loss': 0.15105195,\n 'Loss/total_loss': 2.8527908,\n 'learning_rate': 1.9879973e-05}\nI0620 07:45:46.657529 132867512947840 model_lib_v2.py:705] Step 5000 per-step time 0.443s\nI0620 07:45:46.657926 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0411175,\n 'Loss/localization_loss': 1.3356025,\n 'Loss/regularization_loss': 0.1510333,\n 'Loss/total_loss': 2.5277536,\n 'learning_rate': 1.9873753e-05}\nI0620 07:46:31.896402 132867512947840 model_lib_v2.py:705] Step 5100 per-step time 0.452s\nI0620 07:46:31.896879 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1473885,\n 'Loss/localization_loss': 1.3355854,\n 'Loss/regularization_loss': 0.15101433,\n 'Loss/total_loss': 2.6339884,\n 'learning_rate': 1.9867375e-05}\nI0620 07:47:16.447550 132867512947840 model_lib_v2.py:705] Step 5200 per-step time 0.446s\nI0620 07:47:16.448086 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.043241,\n 'Loss/localization_loss': 1.475893,\n 'Loss/regularization_loss': 0.15099527,\n 'Loss/total_loss': 2.6701293,\n 'learning_rate': 1.9860843e-05}\nI0620 07:48:00.810858 132867512947840 model_lib_v2.py:705] Step 5300 per-step time 0.444s\nI0620 07:48:00.811316 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0821354,\n 'Loss/localization_loss': 1.5008435,\n 'Loss/regularization_loss': 0.15097585,\n 'Loss/total_loss': 2.733955,\n 'learning_rate': 1.9854155e-05}\nI0620 07:48:45.384742 132867512947840 model_lib_v2.py:705] Step 5400 per-step time 0.446s\nI0620 07:48:45.385158 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9939431,\n 'Loss/localization_loss': 1.5291778,\n 'Loss/regularization_loss': 0.15095659,\n 'Loss/total_loss': 2.6740775,\n 'learning_rate': 1.984731e-05}\nI0620 07:49:29.749626 132867512947840 model_lib_v2.py:705] Step 5500 per-step time 0.444s\nI0620 07:49:29.750036 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1101689,\n 'Loss/localization_loss': 1.439891,\n 'Loss/regularization_loss': 0.15093705,\n 'Loss/total_loss': 2.7009969,\n 'learning_rate': 1.9840309e-05}\nI0620 07:50:14.127689 132867512947840 model_lib_v2.py:705] Step 5600 per-step time 0.444s\nI0620 07:50:14.128115 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0680807,\n 'Loss/localization_loss': 1.48539,\n 'Loss/regularization_loss': 0.15091729,\n 'Loss/total_loss': 2.704388,\n 'learning_rate': 1.9833153e-05}\nI0620 07:50:58.510384 132867512947840 model_lib_v2.py:705] Step 5700 per-step time 0.444s\nI0620 07:50:58.510807 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1130093,\n 'Loss/localization_loss': 1.5166914,\n 'Loss/regularization_loss': 0.15089732,\n 'Loss/total_loss': 2.7805982,\n 'learning_rate': 1.982584e-05}\nI0620 07:51:42.926336 132867512947840 model_lib_v2.py:705] Step 5800 per-step time 0.444s\nI0620 07:51:42.926708 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0816274,\n 'Loss/localization_loss': 1.461344,\n 'Loss/regularization_loss': 0.15087742,\n 'Loss/total_loss': 2.6938488,\n 'learning_rate': 1.9818372e-05}\nI0620 07:52:27.328834 132867512947840 model_lib_v2.py:705] Step 5900 per-step time 0.444s\nI0620 07:52:27.329366 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9789221,\n 'Loss/localization_loss': 1.4886518,\n 'Loss/regularization_loss': 0.15085718,\n 'Loss/total_loss': 2.618431,\n 'learning_rate': 1.981075e-05}\nI0620 07:53:11.811134 132867512947840 model_lib_v2.py:705] Step 6000 per-step time 0.445s\nI0620 07:53:11.811559 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0079186,\n 'Loss/localization_loss': 1.3932846,\n 'Loss/regularization_loss': 0.15083657,\n 'Loss/total_loss': 2.5520396,\n 'learning_rate': 1.9802972e-05}\nI0620 07:53:56.894498 132867512947840 model_lib_v2.py:705] Step 6100 per-step time 0.451s\nI0620 07:53:56.894912 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.008117,\n 'Loss/localization_loss': 1.5720193,\n 'Loss/regularization_loss': 0.15081586,\n 'Loss/total_loss': 2.7309523,\n 'learning_rate': 1.9795041e-05}\nI0620 07:54:41.499161 132867512947840 model_lib_v2.py:705] Step 6200 per-step time 0.446s\nI0620 07:54:41.499566 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0414228,\n 'Loss/localization_loss': 1.5069466,\n 'Loss/regularization_loss': 0.15079533,\n 'Loss/total_loss': 2.6991646,\n 'learning_rate': 1.9786954e-05}\nI0620 07:55:25.849368 132867512947840 model_lib_v2.py:705] Step 6300 per-step time 0.444s\nI0620 07:55:25.849794 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1310365,\n 'Loss/localization_loss': 1.5032942,\n 'Loss/regularization_loss': 0.15077424,\n 'Loss/total_loss': 2.7851052,\n 'learning_rate': 1.9778712e-05}\nI0620 07:56:10.302272 132867512947840 model_lib_v2.py:705] Step 6400 per-step time 0.445s\nI0620 07:56:10.302599 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1199956,\n 'Loss/localization_loss': 1.4445786,\n 'Loss/regularization_loss': 0.15075293,\n 'Loss/total_loss': 2.7153273,\n 'learning_rate': 1.9770314e-05}\nI0620 07:56:54.706074 132867512947840 model_lib_v2.py:705] Step 6500 per-step time 0.444s\nI0620 07:56:54.706504 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1718469,\n 'Loss/localization_loss': 1.506083,\n 'Loss/regularization_loss': 0.15073188,\n 'Loss/total_loss': 2.8286617,\n 'learning_rate': 1.9761763e-05}\nI0620 07:57:38.941574 132867512947840 model_lib_v2.py:705] Step 6600 per-step time 0.442s\nI0620 07:57:38.941980 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0901479,\n 'Loss/localization_loss': 1.4595859,\n 'Loss/regularization_loss': 0.15071075,\n 'Loss/total_loss': 2.7004447,\n 'learning_rate': 1.9753057e-05}\nI0620 07:58:23.428967 132867512947840 model_lib_v2.py:705] Step 6700 per-step time 0.445s\nI0620 07:58:23.429484 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.94005966,\n 'Loss/localization_loss': 1.4937613,\n 'Loss/regularization_loss': 0.15068936,\n 'Loss/total_loss': 2.5845103,\n 'learning_rate': 1.9744197e-05}\nI0620 07:59:07.667176 132867512947840 model_lib_v2.py:705] Step 6800 per-step time 0.442s\nI0620 07:59:07.667615 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0637822,\n 'Loss/localization_loss': 1.4659916,\n 'Loss/regularization_loss': 0.15066837,\n 'Loss/total_loss': 2.6804423,\n 'learning_rate': 1.9735184e-05}\nI0620 07:59:51.989679 132867512947840 model_lib_v2.py:705] Step 6900 per-step time 0.443s\nI0620 07:59:51.990077 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9211042,\n 'Loss/localization_loss': 1.3957946,\n 'Loss/regularization_loss': 0.15064716,\n 'Loss/total_loss': 2.467546,\n 'learning_rate': 1.9726014e-05}\nI0620 08:00:36.465524 132867512947840 model_lib_v2.py:705] Step 7000 per-step time 0.445s\nI0620 08:00:36.465905 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9946215,\n 'Loss/localization_loss': 1.5685333,\n 'Loss/regularization_loss': 0.15062629,\n 'Loss/total_loss': 2.7137809,\n 'learning_rate': 1.9716692e-05}\nI0620 08:01:21.297601 132867512947840 model_lib_v2.py:705] Step 7100 per-step time 0.448s\nI0620 08:01:21.297975 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9368775,\n 'Loss/localization_loss': 1.3378007,\n 'Loss/regularization_loss': 0.1506049,\n 'Loss/total_loss': 2.4252834,\n 'learning_rate': 1.9707217e-05}\nI0620 08:02:05.661103 132867512947840 model_lib_v2.py:705] Step 7200 per-step time 0.444s\nI0620 08:02:05.661475 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9884974,\n 'Loss/localization_loss': 1.4900284,\n 'Loss/regularization_loss': 0.15058324,\n 'Loss/total_loss': 2.6291091,\n 'learning_rate': 1.9697589e-05}\nI0620 08:02:50.104166 132867512947840 model_lib_v2.py:705] Step 7300 per-step time 0.444s\nI0620 08:02:50.104552 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.99606967,\n 'Loss/localization_loss': 1.3760605,\n 'Loss/regularization_loss': 0.15056168,\n 'Loss/total_loss': 2.5226917,\n 'learning_rate': 1.9687806e-05}\nI0620 08:03:34.390816 132867512947840 model_lib_v2.py:705] Step 7400 per-step time 0.443s\nI0620 08:03:34.391258 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.1855149,\n 'Loss/localization_loss': 1.5711246,\n 'Loss/regularization_loss': 0.15054013,\n 'Loss/total_loss': 2.9071794,\n 'learning_rate': 1.967787e-05}\nI0620 08:04:18.721603 132867512947840 model_lib_v2.py:705] Step 7500 per-step time 0.443s\nI0620 08:04:18.722033 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9392754,\n 'Loss/localization_loss': 1.4344339,\n 'Loss/regularization_loss': 0.1505187,\n 'Loss/total_loss': 2.524228,\n 'learning_rate': 1.9667783e-05}\nI0620 08:05:03.281030 132867512947840 model_lib_v2.py:705] Step 7600 per-step time 0.446s\nI0620 08:05:03.281458 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9025787,\n 'Loss/localization_loss': 1.3864634,\n 'Loss/regularization_loss': 0.15049712,\n 'Loss/total_loss': 2.4395392,\n 'learning_rate': 1.965754e-05}\nI0620 08:05:47.550736 132867512947840 model_lib_v2.py:705] Step 7700 per-step time 0.443s\nI0620 08:05:47.551151 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9355315,\n 'Loss/localization_loss': 1.4337997,\n 'Loss/regularization_loss': 0.15047596,\n 'Loss/total_loss': 2.519807,\n 'learning_rate': 1.9647146e-05}\nI0620 08:06:32.055705 132867512947840 model_lib_v2.py:705] Step 7800 per-step time 0.445s\nI0620 08:06:32.056082 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.7950498,\n 'Loss/localization_loss': 1.3823242,\n 'Loss/regularization_loss': 0.15045415,\n 'Loss/total_loss': 2.327828,\n 'learning_rate': 1.96366e-05}\nI0620 08:07:16.526484 132867512947840 model_lib_v2.py:705] Step 7900 per-step time 0.445s\nI0620 08:07:16.526859 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.933126,\n 'Loss/localization_loss': 1.4666418,\n 'Loss/regularization_loss': 0.1504325,\n 'Loss/total_loss': 2.5502005,\n 'learning_rate': 1.9625899e-05}\nI0620 08:08:00.910590 132867512947840 model_lib_v2.py:705] Step 8000 per-step time 0.444s\nI0620 08:08:00.910967 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.93607676,\n 'Loss/localization_loss': 1.3890429,\n 'Loss/regularization_loss': 0.15041086,\n 'Loss/total_loss': 2.4755306,\n 'learning_rate': 1.9615049e-05}\nI0620 08:08:45.905661 132867512947840 model_lib_v2.py:705] Step 8100 per-step time 0.450s\nI0620 08:08:45.906098 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8780856,\n 'Loss/localization_loss': 1.4699354,\n 'Loss/regularization_loss': 0.15038915,\n 'Loss/total_loss': 2.4984102,\n 'learning_rate': 1.9604046e-05}\nI0620 08:09:30.410117 132867512947840 model_lib_v2.py:705] Step 8200 per-step time 0.445s\nI0620 08:09:30.410529 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8972783,\n 'Loss/localization_loss': 1.4636264,\n 'Loss/regularization_loss': 0.15036756,\n 'Loss/total_loss': 2.511272,\n 'learning_rate': 1.959289e-05}\nI0620 08:10:14.939940 132867512947840 model_lib_v2.py:705] Step 8300 per-step time 0.445s\nI0620 08:10:14.940357 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.93869376,\n 'Loss/localization_loss': 1.4908328,\n 'Loss/regularization_loss': 0.15034565,\n 'Loss/total_loss': 2.5798721,\n 'learning_rate': 1.9581583e-05}\nI0620 08:10:59.684394 132867512947840 model_lib_v2.py:705] Step 8400 per-step time 0.447s\nI0620 08:10:59.684771 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.93122435,\n 'Loss/localization_loss': 1.4371535,\n 'Loss/regularization_loss': 0.15032388,\n 'Loss/total_loss': 2.5187018,\n 'learning_rate': 1.9570123e-05}\nI0620 08:11:44.137549 132867512947840 model_lib_v2.py:705] Step 8500 per-step time 0.445s\nI0620 08:11:44.137980 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9539275,\n 'Loss/localization_loss': 1.5953779,\n 'Loss/regularization_loss': 0.15030216,\n 'Loss/total_loss': 2.6996076,\n 'learning_rate': 1.9558514e-05}\nI0620 08:12:28.425884 132867512947840 model_lib_v2.py:705] Step 8600 per-step time 0.443s\nI0620 08:12:28.426297 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9780571,\n 'Loss/localization_loss': 1.3596115,\n 'Loss/regularization_loss': 0.15028076,\n 'Loss/total_loss': 2.4879494,\n 'learning_rate': 1.9546755e-05}\nI0620 08:13:12.794944 132867512947840 model_lib_v2.py:705] Step 8700 per-step time 0.444s\nI0620 08:13:12.795352 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8461231,\n 'Loss/localization_loss': 1.2847347,\n 'Loss/regularization_loss': 0.15025951,\n 'Loss/total_loss': 2.2811174,\n 'learning_rate': 1.9534842e-05}\nI0620 08:13:57.170017 132867512947840 model_lib_v2.py:705] Step 8800 per-step time 0.444s\nI0620 08:13:57.170401 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8726906,\n 'Loss/localization_loss': 1.3362677,\n 'Loss/regularization_loss': 0.15023777,\n 'Loss/total_loss': 2.3591962,\n 'learning_rate': 1.9522779e-05}\nI0620 08:14:41.784679 132867512947840 model_lib_v2.py:705] Step 8900 per-step time 0.446s\nI0620 08:14:41.785087 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9745949,\n 'Loss/localization_loss': 1.4503155,\n 'Loss/regularization_loss': 0.1502162,\n 'Loss/total_loss': 2.5751266,\n 'learning_rate': 1.9510564e-05}\nI0620 08:15:26.184546 132867512947840 model_lib_v2.py:705] Step 9000 per-step time 0.444s\nI0620 08:15:26.184983 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0682039,\n 'Loss/localization_loss': 1.3584752,\n 'Loss/regularization_loss': 0.15019447,\n 'Loss/total_loss': 2.5768733,\n 'learning_rate': 1.94982e-05}\nI0620 08:16:11.046308 132867512947840 model_lib_v2.py:705] Step 9100 per-step time 0.449s\nI0620 08:16:11.046717 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.90980107,\n 'Loss/localization_loss': 1.2835882,\n 'Loss/regularization_loss': 0.15017357,\n 'Loss/total_loss': 2.3435628,\n 'learning_rate': 1.9485688e-05}\nI0620 08:16:55.611439 132867512947840 model_lib_v2.py:705] Step 9200 per-step time 0.446s\nI0620 08:16:55.611940 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0086932,\n 'Loss/localization_loss': 1.4548659,\n 'Loss/regularization_loss': 0.15015207,\n 'Loss/total_loss': 2.6137114,\n 'learning_rate': 1.9473024e-05}\nI0620 08:17:39.879962 132867512947840 model_lib_v2.py:705] Step 9300 per-step time 0.443s\nI0620 08:17:39.880366 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.91774035,\n 'Loss/localization_loss': 1.4467268,\n 'Loss/regularization_loss': 0.1501306,\n 'Loss/total_loss': 2.5145977,\n 'learning_rate': 1.9460207e-05}\nI0620 08:18:24.371461 132867512947840 model_lib_v2.py:705] Step 9400 per-step time 0.445s\nI0620 08:18:24.371809 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9354805,\n 'Loss/localization_loss': 1.4644928,\n 'Loss/regularization_loss': 0.15010984,\n 'Loss/total_loss': 2.5500832,\n 'learning_rate': 1.9447245e-05}\nI0620 08:19:08.553599 132867512947840 model_lib_v2.py:705] Step 9500 per-step time 0.442s\nI0620 08:19:08.553977 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.88535756,\n 'Loss/localization_loss': 1.2524385,\n 'Loss/regularization_loss': 0.15008874,\n 'Loss/total_loss': 2.2878847,\n 'learning_rate': 1.9434132e-05}\nI0620 08:19:53.032728 132867512947840 model_lib_v2.py:705] Step 9600 per-step time 0.445s\nI0620 08:19:53.033101 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9048948,\n 'Loss/localization_loss': 1.3631194,\n 'Loss/regularization_loss': 0.15006769,\n 'Loss/total_loss': 2.418082,\n 'learning_rate': 1.9420871e-05}\nI0620 08:20:37.519683 132867512947840 model_lib_v2.py:705] Step 9700 per-step time 0.445s\nI0620 08:20:37.520062 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.7997243,\n 'Loss/localization_loss': 1.3075354,\n 'Loss/regularization_loss': 0.15004686,\n 'Loss/total_loss': 2.2573066,\n 'learning_rate': 1.940746e-05}\nI0620 08:21:22.114120 132867512947840 model_lib_v2.py:705] Step 9800 per-step time 0.446s\nI0620 08:21:22.114565 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.88808715,\n 'Loss/localization_loss': 1.4021215,\n 'Loss/regularization_loss': 0.15002567,\n 'Loss/total_loss': 2.4402344,\n 'learning_rate': 1.93939e-05}\nI0620 08:22:06.632441 132867512947840 model_lib_v2.py:705] Step 9900 per-step time 0.445s\nI0620 08:22:06.632815 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9964722,\n 'Loss/localization_loss': 1.4031645,\n 'Loss/regularization_loss': 0.1500046,\n 'Loss/total_loss': 2.5496411,\n 'learning_rate': 1.9380192e-05}\nI0620 08:22:50.869558 132867512947840 model_lib_v2.py:705] Step 10000 per-step time 0.442s\nI0620 08:22:50.869991 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.81648135,\n 'Loss/localization_loss': 1.3510087,\n 'Loss/regularization_loss': 0.14998403,\n 'Loss/total_loss': 2.3174741,\n 'learning_rate': 1.9366335e-05}\nI0620 08:23:35.739600 132867512947840 model_lib_v2.py:705] Step 10100 per-step time 0.449s\nI0620 08:23:35.740024 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.96081007,\n 'Loss/localization_loss': 1.4338421,\n 'Loss/regularization_loss': 0.14996356,\n 'Loss/total_loss': 2.5446157,\n 'learning_rate': 1.935233e-05}\nI0620 08:24:20.210877 132867512947840 model_lib_v2.py:705] Step 10200 per-step time 0.445s\nI0620 08:24:20.211254 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9331121,\n 'Loss/localization_loss': 1.3852925,\n 'Loss/regularization_loss': 0.14994304,\n 'Loss/total_loss': 2.4683475,\n 'learning_rate': 1.9338177e-05}\nI0620 08:25:04.651556 132867512947840 model_lib_v2.py:705] Step 10300 per-step time 0.444s\nI0620 08:25:04.651999 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.84671104,\n 'Loss/localization_loss': 1.2621343,\n 'Loss/regularization_loss': 0.14992219,\n 'Loss/total_loss': 2.2587676,\n 'learning_rate': 1.9323877e-05}\nI0620 08:25:49.097321 132867512947840 model_lib_v2.py:705] Step 10400 per-step time 0.444s\nI0620 08:25:49.097657 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8152091,\n 'Loss/localization_loss': 1.3512309,\n 'Loss/regularization_loss': 0.14990172,\n 'Loss/total_loss': 2.3163414,\n 'learning_rate': 1.930943e-05}\nI0620 08:26:33.440498 132867512947840 model_lib_v2.py:705] Step 10500 per-step time 0.443s\nI0620 08:26:33.440855 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8895703,\n 'Loss/localization_loss': 1.3136625,\n 'Loss/regularization_loss': 0.1498814,\n 'Loss/total_loss': 2.3531141,\n 'learning_rate': 1.9294834e-05}\nI0620 08:27:17.844877 132867512947840 model_lib_v2.py:705] Step 10600 per-step time 0.444s\nI0620 08:27:17.845266 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.820571,\n 'Loss/localization_loss': 1.3840175,\n 'Loss/regularization_loss': 0.14986093,\n 'Loss/total_loss': 2.3544493,\n 'learning_rate': 1.9280093e-05}\nI0620 08:28:02.295713 132867512947840 model_lib_v2.py:705] Step 10700 per-step time 0.445s\nI0620 08:28:02.296094 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8591007,\n 'Loss/localization_loss': 1.3856969,\n 'Loss/regularization_loss': 0.1498407,\n 'Loss/total_loss': 2.394638,\n 'learning_rate': 1.9265202e-05}\nI0620 08:28:46.719130 132867512947840 model_lib_v2.py:705] Step 10800 per-step time 0.444s\nI0620 08:28:46.719533 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9025858,\n 'Loss/localization_loss': 1.4795294,\n 'Loss/regularization_loss': 0.14982057,\n 'Loss/total_loss': 2.5319357,\n 'learning_rate': 1.9250167e-05}\nI0620 08:29:30.936172 132867512947840 model_lib_v2.py:705] Step 10900 per-step time 0.442s\nI0620 08:29:30.936575 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9092549,\n 'Loss/localization_loss': 1.3682458,\n 'Loss/regularization_loss': 0.1498003,\n 'Loss/total_loss': 2.427301,\n 'learning_rate': 1.9234985e-05}\nI0620 08:30:15.538956 132867512947840 model_lib_v2.py:705] Step 11000 per-step time 0.446s\nI0620 08:30:15.539340 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0756783,\n 'Loss/localization_loss': 1.4267509,\n 'Loss/regularization_loss': 0.14977995,\n 'Loss/total_loss': 2.6522093,\n 'learning_rate': 1.9219658e-05}\nI0620 08:31:00.379547 132867512947840 model_lib_v2.py:705] Step 11100 per-step time 0.448s\nI0620 08:31:00.379906 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.91446376,\n 'Loss/localization_loss': 1.3106503,\n 'Loss/regularization_loss': 0.14975986,\n 'Loss/total_loss': 2.3748739,\n 'learning_rate': 1.9204184e-05}\nI0620 08:31:44.844138 132867512947840 model_lib_v2.py:705] Step 11200 per-step time 0.445s\nI0620 08:31:44.844565 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.92116433,\n 'Loss/localization_loss': 1.3252987,\n 'Loss/regularization_loss': 0.14973977,\n 'Loss/total_loss': 2.3962026,\n 'learning_rate': 1.9188567e-05}\nI0620 08:32:29.259794 132867512947840 model_lib_v2.py:705] Step 11300 per-step time 0.444s\nI0620 08:32:29.260163 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.96612084,\n 'Loss/localization_loss': 1.4919858,\n 'Loss/regularization_loss': 0.14971966,\n 'Loss/total_loss': 2.6078262,\n 'learning_rate': 1.9172801e-05}\nI0620 08:33:13.712944 132867512947840 model_lib_v2.py:705] Step 11400 per-step time 0.445s\nI0620 08:33:13.713355 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8592198,\n 'Loss/localization_loss': 1.2359525,\n 'Loss/regularization_loss': 0.14969933,\n 'Loss/total_loss': 2.2448716,\n 'learning_rate': 1.9156892e-05}\nI0620 08:33:58.179265 132867512947840 model_lib_v2.py:705] Step 11500 per-step time 0.445s\nI0620 08:33:58.179653 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8256166,\n 'Loss/localization_loss': 1.3196126,\n 'Loss/regularization_loss': 0.14967968,\n 'Loss/total_loss': 2.294909,\n 'learning_rate': 1.9140838e-05}\nI0620 08:34:42.230672 132867512947840 model_lib_v2.py:705] Step 11600 per-step time 0.441s\nI0620 08:34:42.231002 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.9569417,\n 'Loss/localization_loss': 1.3850298,\n 'Loss/regularization_loss': 0.14965932,\n 'Loss/total_loss': 2.4916308,\n 'learning_rate': 1.9124638e-05}\nI0620 08:35:26.697268 132867512947840 model_lib_v2.py:705] Step 11700 per-step time 0.445s\nI0620 08:35:26.697661 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.84269464,\n 'Loss/localization_loss': 1.392763,\n 'Loss/regularization_loss': 0.14963943,\n 'Loss/total_loss': 2.385097,\n 'learning_rate': 1.9108296e-05}\nI0620 08:36:10.926244 132867512947840 model_lib_v2.py:705] Step 11800 per-step time 0.442s\nI0620 08:36:10.926655 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8903942,\n 'Loss/localization_loss': 1.3531123,\n 'Loss/regularization_loss': 0.14961962,\n 'Loss/total_loss': 2.393126,\n 'learning_rate': 1.9091809e-05}\nI0620 08:36:55.305901 132867512947840 model_lib_v2.py:705] Step 11900 per-step time 0.444s\nI0620 08:36:55.306283 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8758811,\n 'Loss/localization_loss': 1.2895267,\n 'Loss/regularization_loss': 0.14960004,\n 'Loss/total_loss': 2.3150077,\n 'learning_rate': 1.9075178e-05}\nI0620 08:37:39.505253 132867512947840 model_lib_v2.py:705] Step 12000 per-step time 0.442s\nI0620 08:37:39.505662 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 1.0011538,\n 'Loss/localization_loss': 1.4071991,\n 'Loss/regularization_loss': 0.14958031,\n 'Loss/total_loss': 2.5579333,\n 'learning_rate': 1.9058403e-05}\nI0620 08:38:24.649966 132867512947840 model_lib_v2.py:705] Step 12100 per-step time 0.451s\nI0620 08:38:24.650374 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8303526,\n 'Loss/localization_loss': 1.3206073,\n 'Loss/regularization_loss': 0.14956072,\n 'Loss/total_loss': 2.3005204,\n 'learning_rate': 1.9041485e-05}\nI0620 08:39:09.008362 132867512947840 model_lib_v2.py:705] Step 12200 per-step time 0.444s\nI0620 08:39:09.008766 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.95896477,\n 'Loss/localization_loss': 1.2923982,\n 'Loss/regularization_loss': 0.14954145,\n 'Loss/total_loss': 2.4009042,\n 'learning_rate': 1.9024425e-05}\nI0620 08:39:53.331593 132867512947840 model_lib_v2.py:705] Step 12300 per-step time 0.443s\nI0620 08:39:53.332007 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8828285,\n 'Loss/localization_loss': 1.4149306,\n 'Loss/regularization_loss': 0.14952178,\n 'Loss/total_loss': 2.447281,\n 'learning_rate': 1.9007222e-05}\nI0620 08:40:37.683096 132867512947840 model_lib_v2.py:705] Step 12400 per-step time 0.444s\nI0620 08:40:37.683517 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.91305506,\n 'Loss/localization_loss': 1.3567252,\n 'Loss/regularization_loss': 0.1495022,\n 'Loss/total_loss': 2.4192824,\n 'learning_rate': 1.8989876e-05}\nI0620 08:41:22.239027 132867512947840 model_lib_v2.py:705] Step 12500 per-step time 0.446s\nI0620 08:41:22.239436 132867512947840 model_lib_v2.py:708] {'Loss/classification_loss': 0.8862358,\n 'Loss/localization_loss': 1.3152943,\n 'Loss/regularization_loss': 0.14948297,\n 'Loss/total_loss': 2.351013,\n 'learning_rate': 1.8972389e-05}\n\n🔵 Evaluasi setelah iterasi ke-1\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nW0620 08:41:31.235547 135002165085312 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\nI0620 08:41:31.235788 135002165085312 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\nI0620 08:41:31.235899 135002165085312 config_util.py:552] Maybe overwriting use_bfloat16: False\nI0620 08:41:31.235982 135002165085312 config_util.py:552] Maybe overwriting eval_num_epochs: 1\nW0620 08:41:31.236076 135002165085312 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\nI0620 08:41:32.903832 135002165085312 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 08:41:32.904149 135002165085312 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 08:41:32.904295 135002165085312 dataset_builder.py:80] Number of filenames to read: 1\nW0620 08:41:32.904386 135002165085312 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 08:41:32.906719 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 08:41:32.940315 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 08:41:36.679937 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 08:41:37.569080 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 08:41:39.902156 135002165085312 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\nI0620 08:41:39.903617 135002165085312 checkpoint_utils.py:145] Found new checkpoint at /kaggle/working/training/ckpt-13\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 08:41:45.577319 135002165085312 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:41:58.615083 135002165085312 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 08:42:04.342808 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 08:42:04.356780 135002165085312 model_lib_v2.py:966] Finished eval step 0\nW0620 08:42:04.476006 135002165085312 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nI0620 08:42:08.000151 135002165085312 coco_evaluation.py:293] Performing evaluation on 39 images.\ncreating index...\nindex created!\nI0620 08:42:08.003122 135002165085312 coco_tools.py:116] Loading and preparing annotation results...\nI0620 08:42:08.007704 135002165085312 coco_tools.py:138] DONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.80s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.054\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.031\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\nI0620 08:42:08.888560 135002165085312 model_lib_v2.py:1015] Eval metrics at step 12000\nI0620 08:42:08.896730 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.011374\nI0620 08:42:08.898173 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.053884\nI0620 08:42:08.899547 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000879\nI0620 08:42:08.900972 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\nI0620 08:42:08.902667 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.007192\nI0620 08:42:08.903923 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.022250\nI0620 08:42:08.905267 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.004272\nI0620 08:42:08.906664 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.030635\nI0620 08:42:08.908038 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.085635\nI0620 08:42:08.909286 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\nI0620 08:42:08.910604 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.063877\nI0620 08:42:08.911887 135002165085312 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.130379\nI0620 08:42:08.912936 135002165085312 model_lib_v2.py:1018] \t+ Loss/localization_loss: 1.157592\nI0620 08:42:08.913982 135002165085312 model_lib_v2.py:1018] \t+ Loss/classification_loss: 1.092371\nI0620 08:42:08.915051 135002165085312 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.149580\nI0620 08:42:08.916208 135002165085312 model_lib_v2.py:1018] \t+ Loss/total_loss: 2.399543\nI0620 08:46:40.003911 135002165085312 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n    tf.compat.v1.app.run()\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 81, in main\n    model_lib_v2.eval_continuously(\n  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n    for latest_checkpoint in tf.train.checkpoints_iterator(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 194, in checkpoints_iterator\n    new_checkpoint_path = wait_for_new_checkpoint(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n    time.sleep(seconds_to_sleep)\nKeyboardInterrupt\n\n🟢 Training iterasi ke-2 (12500 -> 25000 steps)\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nI0620 08:53:08.654842 138935039562880 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI0620 08:53:08.659030 138935039562880 config_util.py:552] Maybe overwriting train_steps: 25000\nI0620 08:53:08.659230 138935039562880 config_util.py:552] Maybe overwriting use_bfloat16: False\nW0620 08:53:08.829761 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI0620 08:53:08.833768 138935039562880 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 08:53:08.833991 138935039562880 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 08:53:08.834101 138935039562880 dataset_builder.py:80] Number of filenames to read: 1\nW0620 08:53:08.834180 138935039562880 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 08:53:08.836621 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 08:53:08.862239 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 08:53:15.262436 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 08:53:18.008258 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nW0620 08:53:20.436666 138935039562880 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 08:53:29.528696 138927721653824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:53:39.177511 138927730046528 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:53:44.574134 138927730046528 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:53:48.436372 138927721653824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 08:54:02.415351 138928266933824 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\nI0620 08:54:03.401782 138928266933824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:08.789839 138928258541120 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:13.065256 138935039562880 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 08:54:16.362372 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:16.364724 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:16.366539 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:16.368225 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:19.171057 138928258541120 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:24.524407 138928266933824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:28.803079 138935039562880 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 08:54:31.528795 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:31.531063 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:31.532715 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:31.534555 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:33.784340 138928266933824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:39.539315 138928258541120 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:43.840049 138935039562880 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 08:54:46.976694 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:46.979161 138935039562880 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 08:54:49.877071 138928258541120 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:54.996254 138928266933824 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 08:54:59.840775 138935039562880 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 08:56:11.899158 138935039562880 model_lib_v2.py:705] Step 12100 per-step time 1.298s\nI0620 08:56:11.899604 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.9275834,\n 'Loss/localization_loss': 1.4293265,\n 'Loss/regularization_loss': 0.14956096,\n 'Loss/total_loss': 2.506471,\n 'learning_rate': 1.9041485e-05}\nI0620 08:56:55.905972 138935039562880 model_lib_v2.py:705] Step 12200 per-step time 0.440s\nI0620 08:56:55.906399 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.84527946,\n 'Loss/localization_loss': 1.4313004,\n 'Loss/regularization_loss': 0.14954148,\n 'Loss/total_loss': 2.4261212,\n 'learning_rate': 1.9024425e-05}\nI0620 08:57:40.193597 138935039562880 model_lib_v2.py:705] Step 12300 per-step time 0.443s\nI0620 08:57:40.193979 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.86482155,\n 'Loss/localization_loss': 1.2891661,\n 'Loss/regularization_loss': 0.14952151,\n 'Loss/total_loss': 2.3035092,\n 'learning_rate': 1.9007222e-05}\nI0620 08:58:24.463115 138935039562880 model_lib_v2.py:705] Step 12400 per-step time 0.443s\nI0620 08:58:24.463590 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8246459,\n 'Loss/localization_loss': 1.2305291,\n 'Loss/regularization_loss': 0.14950196,\n 'Loss/total_loss': 2.2046769,\n 'learning_rate': 1.8989876e-05}\nI0620 08:59:08.965701 138935039562880 model_lib_v2.py:705] Step 12500 per-step time 0.445s\nI0620 08:59:08.966093 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.95020413,\n 'Loss/localization_loss': 1.3920727,\n 'Loss/regularization_loss': 0.1494828,\n 'Loss/total_loss': 2.4917595,\n 'learning_rate': 1.8972389e-05}\nI0620 08:59:53.156919 138935039562880 model_lib_v2.py:705] Step 12600 per-step time 0.442s\nI0620 08:59:53.157317 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.919616,\n 'Loss/localization_loss': 1.413595,\n 'Loss/regularization_loss': 0.14946339,\n 'Loss/total_loss': 2.4826741,\n 'learning_rate': 1.8954759e-05}\nI0620 09:00:37.228776 138935039562880 model_lib_v2.py:705] Step 12700 per-step time 0.441s\nI0620 09:00:37.229275 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8146537,\n 'Loss/localization_loss': 1.2877123,\n 'Loss/regularization_loss': 0.14944404,\n 'Loss/total_loss': 2.25181,\n 'learning_rate': 1.8936986e-05}\nI0620 09:01:21.332964 138935039562880 model_lib_v2.py:705] Step 12800 per-step time 0.441s\nI0620 09:01:21.333425 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.99023813,\n 'Loss/localization_loss': 1.2505174,\n 'Loss/regularization_loss': 0.1494247,\n 'Loss/total_loss': 2.3901803,\n 'learning_rate': 1.8919074e-05}\nI0620 09:02:05.568887 138935039562880 model_lib_v2.py:705] Step 12900 per-step time 0.442s\nI0620 09:02:05.569432 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 1.0059114,\n 'Loss/localization_loss': 1.376767,\n 'Loss/regularization_loss': 0.14940561,\n 'Loss/total_loss': 2.532084,\n 'learning_rate': 1.890102e-05}\nI0620 09:02:49.722056 138935039562880 model_lib_v2.py:705] Step 13000 per-step time 0.442s\nI0620 09:02:49.722458 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.97354126,\n 'Loss/localization_loss': 1.3751068,\n 'Loss/regularization_loss': 0.1493868,\n 'Loss/total_loss': 2.498035,\n 'learning_rate': 1.8882825e-05}\nI0620 09:03:34.570012 138935039562880 model_lib_v2.py:705] Step 13100 per-step time 0.449s\nI0620 09:03:34.570468 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8817831,\n 'Loss/localization_loss': 1.309607,\n 'Loss/regularization_loss': 0.14936754,\n 'Loss/total_loss': 2.3407576,\n 'learning_rate': 1.886449e-05}\nI0620 09:04:18.640270 138935039562880 model_lib_v2.py:705] Step 13200 per-step time 0.441s\nI0620 09:04:18.640627 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8821266,\n 'Loss/localization_loss': 1.3221447,\n 'Loss/regularization_loss': 0.14934844,\n 'Loss/total_loss': 2.3536198,\n 'learning_rate': 1.8846016e-05}\nI0620 09:05:02.938583 138935039562880 model_lib_v2.py:705] Step 13300 per-step time 0.443s\nI0620 09:05:02.938965 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.84375787,\n 'Loss/localization_loss': 1.391645,\n 'Loss/regularization_loss': 0.14932978,\n 'Loss/total_loss': 2.3847325,\n 'learning_rate': 1.8827399e-05}\nI0620 09:05:47.051939 138935039562880 model_lib_v2.py:705] Step 13400 per-step time 0.441s\nI0620 09:05:47.052363 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.85539585,\n 'Loss/localization_loss': 1.3028772,\n 'Loss/regularization_loss': 0.1493107,\n 'Loss/total_loss': 2.3075838,\n 'learning_rate': 1.8808645e-05}\nI0620 09:06:31.303259 138935039562880 model_lib_v2.py:705] Step 13500 per-step time 0.442s\nI0620 09:06:31.303617 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 1.0355413,\n 'Loss/localization_loss': 1.473271,\n 'Loss/regularization_loss': 0.1492919,\n 'Loss/total_loss': 2.6581044,\n 'learning_rate': 1.8789751e-05}\nI0620 09:07:15.523780 138935039562880 model_lib_v2.py:705] Step 13600 per-step time 0.442s\nI0620 09:07:15.524179 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.86296535,\n 'Loss/localization_loss': 1.4078159,\n 'Loss/regularization_loss': 0.14927313,\n 'Loss/total_loss': 2.4200544,\n 'learning_rate': 1.8770717e-05}\nI0620 09:07:59.803943 138935039562880 model_lib_v2.py:705] Step 13700 per-step time 0.443s\nI0620 09:07:59.804320 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.9583031,\n 'Loss/localization_loss': 1.4162331,\n 'Loss/regularization_loss': 0.1492543,\n 'Loss/total_loss': 2.5237904,\n 'learning_rate': 1.8751547e-05}\nI0620 09:08:44.099917 138935039562880 model_lib_v2.py:705] Step 13800 per-step time 0.443s\nI0620 09:08:44.100419 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8522533,\n 'Loss/localization_loss': 1.268681,\n 'Loss/regularization_loss': 0.14923564,\n 'Loss/total_loss': 2.27017,\n 'learning_rate': 1.8732237e-05}\nI0620 09:09:28.230672 138935039562880 model_lib_v2.py:705] Step 13900 per-step time 0.441s\nI0620 09:09:28.231100 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80423945,\n 'Loss/localization_loss': 1.3184648,\n 'Loss/regularization_loss': 0.14921694,\n 'Loss/total_loss': 2.2719212,\n 'learning_rate': 1.8712788e-05}\nI0620 09:10:12.490424 138935039562880 model_lib_v2.py:705] Step 14000 per-step time 0.443s\nI0620 09:10:12.490845 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.9520546,\n 'Loss/localization_loss': 1.3801141,\n 'Loss/regularization_loss': 0.14919864,\n 'Loss/total_loss': 2.481367,\n 'learning_rate': 1.8693203e-05}\nI0620 09:10:57.559369 138935039562880 model_lib_v2.py:705] Step 14100 per-step time 0.451s\nI0620 09:10:57.560019 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80980206,\n 'Loss/localization_loss': 1.2728901,\n 'Loss/regularization_loss': 0.14918007,\n 'Loss/total_loss': 2.231872,\n 'learning_rate': 1.867348e-05}\nI0620 09:11:41.740465 138935039562880 model_lib_v2.py:705] Step 14200 per-step time 0.442s\nI0620 09:11:41.740903 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.987509,\n 'Loss/localization_loss': 1.3090112,\n 'Loss/regularization_loss': 0.14916162,\n 'Loss/total_loss': 2.4456818,\n 'learning_rate': 1.8653618e-05}\nI0620 09:12:25.918882 138935039562880 model_lib_v2.py:705] Step 14300 per-step time 0.442s\nI0620 09:12:25.919307 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8376856,\n 'Loss/localization_loss': 1.3003004,\n 'Loss/regularization_loss': 0.1491434,\n 'Loss/total_loss': 2.2871294,\n 'learning_rate': 1.863362e-05}\nI0620 09:13:10.025798 138935039562880 model_lib_v2.py:705] Step 14400 per-step time 0.441s\nI0620 09:13:10.026294 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.9533602,\n 'Loss/localization_loss': 1.3114159,\n 'Loss/regularization_loss': 0.1491254,\n 'Loss/total_loss': 2.4139013,\n 'learning_rate': 1.8613486e-05}\nI0620 09:13:54.125380 138935039562880 model_lib_v2.py:705] Step 14500 per-step time 0.441s\nI0620 09:13:54.125760 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.81999576,\n 'Loss/localization_loss': 1.2412617,\n 'Loss/regularization_loss': 0.14910728,\n 'Loss/total_loss': 2.2103648,\n 'learning_rate': 1.8593215e-05}\nI0620 09:14:38.412014 138935039562880 model_lib_v2.py:705] Step 14600 per-step time 0.443s\nI0620 09:14:38.412429 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8373627,\n 'Loss/localization_loss': 1.2671411,\n 'Loss/regularization_loss': 0.14908884,\n 'Loss/total_loss': 2.2535927,\n 'learning_rate': 1.8572811e-05}\nI0620 09:15:22.831613 138935039562880 model_lib_v2.py:705] Step 14700 per-step time 0.444s\nI0620 09:15:22.832021 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8241761,\n 'Loss/localization_loss': 1.262006,\n 'Loss/regularization_loss': 0.14907125,\n 'Loss/total_loss': 2.2352533,\n 'learning_rate': 1.8552268e-05}\nI0620 09:16:06.973849 138935039562880 model_lib_v2.py:705] Step 14800 per-step time 0.441s\nI0620 09:16:06.974229 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8524912,\n 'Loss/localization_loss': 1.3180327,\n 'Loss/regularization_loss': 0.14905332,\n 'Loss/total_loss': 2.3195772,\n 'learning_rate': 1.8531591e-05}\nI0620 09:16:51.277174 138935039562880 model_lib_v2.py:705] Step 14900 per-step time 0.443s\nI0620 09:16:51.277604 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.893423,\n 'Loss/localization_loss': 1.2832258,\n 'Loss/regularization_loss': 0.14903554,\n 'Loss/total_loss': 2.325684,\n 'learning_rate': 1.851078e-05}\nI0620 09:17:35.352440 138935039562880 model_lib_v2.py:705] Step 15000 per-step time 0.441s\nI0620 09:17:35.352922 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7984807,\n 'Loss/localization_loss': 1.2671163,\n 'Loss/regularization_loss': 0.14901774,\n 'Loss/total_loss': 2.2146149,\n 'learning_rate': 1.8489833e-05}\nI0620 09:18:20.145094 138935039562880 model_lib_v2.py:705] Step 15100 per-step time 0.448s\nI0620 09:18:20.145467 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8400692,\n 'Loss/localization_loss': 1.154836,\n 'Loss/regularization_loss': 0.14900012,\n 'Loss/total_loss': 2.1439052,\n 'learning_rate': 1.8468752e-05}\nI0620 09:19:04.225856 138935039562880 model_lib_v2.py:705] Step 15200 per-step time 0.441s\nI0620 09:19:04.226305 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8658072,\n 'Loss/localization_loss': 1.2936403,\n 'Loss/regularization_loss': 0.1489824,\n 'Loss/total_loss': 2.30843,\n 'learning_rate': 1.8447538e-05}\nI0620 09:19:48.322774 138935039562880 model_lib_v2.py:705] Step 15300 per-step time 0.441s\nI0620 09:19:48.323258 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8526595,\n 'Loss/localization_loss': 1.2902243,\n 'Loss/regularization_loss': 0.14896479,\n 'Loss/total_loss': 2.2918487,\n 'learning_rate': 1.842619e-05}\nI0620 09:20:32.336485 138935039562880 model_lib_v2.py:705] Step 15400 per-step time 0.440s\nI0620 09:20:32.336967 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7568347,\n 'Loss/localization_loss': 1.2573252,\n 'Loss/regularization_loss': 0.14894721,\n 'Loss/total_loss': 2.163107,\n 'learning_rate': 1.840471e-05}\nI0620 09:21:16.516322 138935039562880 model_lib_v2.py:705] Step 15500 per-step time 0.442s\nI0620 09:21:16.516728 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7990293,\n 'Loss/localization_loss': 1.2631544,\n 'Loss/regularization_loss': 0.14892948,\n 'Loss/total_loss': 2.2111132,\n 'learning_rate': 1.8383094e-05}\nI0620 09:22:00.678377 138935039562880 model_lib_v2.py:705] Step 15600 per-step time 0.442s\nI0620 09:22:00.678777 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.69920796,\n 'Loss/localization_loss': 1.2702398,\n 'Loss/regularization_loss': 0.14891204,\n 'Loss/total_loss': 2.1183598,\n 'learning_rate': 1.8361347e-05}\nI0620 09:22:44.846760 138935039562880 model_lib_v2.py:705] Step 15700 per-step time 0.442s\nI0620 09:22:44.847126 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8662723,\n 'Loss/localization_loss': 1.2911749,\n 'Loss/regularization_loss': 0.14889468,\n 'Loss/total_loss': 2.306342,\n 'learning_rate': 1.8339466e-05}\nI0620 09:23:28.975045 138935039562880 model_lib_v2.py:705] Step 15800 per-step time 0.441s\nI0620 09:23:28.975421 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8920234,\n 'Loss/localization_loss': 1.3016346,\n 'Loss/regularization_loss': 0.14887743,\n 'Loss/total_loss': 2.3425355,\n 'learning_rate': 1.8317456e-05}\nI0620 09:24:13.054866 138935039562880 model_lib_v2.py:705] Step 15900 per-step time 0.441s\nI0620 09:24:13.055277 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.79200774,\n 'Loss/localization_loss': 1.2840412,\n 'Loss/regularization_loss': 0.14886019,\n 'Loss/total_loss': 2.2249093,\n 'learning_rate': 1.8295314e-05}\nI0620 09:24:57.029864 138935039562880 model_lib_v2.py:705] Step 16000 per-step time 0.440s\nI0620 09:24:57.030276 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8054186,\n 'Loss/localization_loss': 1.3159089,\n 'Loss/regularization_loss': 0.14884275,\n 'Loss/total_loss': 2.2701705,\n 'learning_rate': 1.827304e-05}\nI0620 09:25:41.883667 138935039562880 model_lib_v2.py:705] Step 16100 per-step time 0.449s\nI0620 09:25:41.884088 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.777558,\n 'Loss/localization_loss': 1.2671565,\n 'Loss/regularization_loss': 0.14882554,\n 'Loss/total_loss': 2.19354,\n 'learning_rate': 1.8250636e-05}\nI0620 09:26:26.126570 138935039562880 model_lib_v2.py:705] Step 16200 per-step time 0.442s\nI0620 09:26:26.126956 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7950482,\n 'Loss/localization_loss': 1.3073757,\n 'Loss/regularization_loss': 0.14880857,\n 'Loss/total_loss': 2.2512321,\n 'learning_rate': 1.82281e-05}\nI0620 09:27:10.307408 138935039562880 model_lib_v2.py:705] Step 16300 per-step time 0.442s\nI0620 09:27:10.307853 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8493868,\n 'Loss/localization_loss': 1.3579648,\n 'Loss/regularization_loss': 0.14879155,\n 'Loss/total_loss': 2.356143,\n 'learning_rate': 1.8205435e-05}\nI0620 09:27:54.419825 138935039562880 model_lib_v2.py:705] Step 16400 per-step time 0.441s\nI0620 09:27:54.420212 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8530207,\n 'Loss/localization_loss': 1.3031802,\n 'Loss/regularization_loss': 0.14877446,\n 'Loss/total_loss': 2.3049755,\n 'learning_rate': 1.818264e-05}\nI0620 09:28:38.548271 138935039562880 model_lib_v2.py:705] Step 16500 per-step time 0.441s\nI0620 09:28:38.548708 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8149871,\n 'Loss/localization_loss': 1.272466,\n 'Loss/regularization_loss': 0.14875758,\n 'Loss/total_loss': 2.2362108,\n 'learning_rate': 1.8159715e-05}\nI0620 09:29:22.621351 138935039562880 model_lib_v2.py:705] Step 16600 per-step time 0.441s\nI0620 09:29:22.621740 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.86203307,\n 'Loss/localization_loss': 1.2498813,\n 'Loss/regularization_loss': 0.14874102,\n 'Loss/total_loss': 2.2606554,\n 'learning_rate': 1.8136663e-05}\nI0620 09:30:06.981542 138935039562880 model_lib_v2.py:705] Step 16700 per-step time 0.444s\nI0620 09:30:06.981962 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.776387,\n 'Loss/localization_loss': 1.2909825,\n 'Loss/regularization_loss': 0.14872424,\n 'Loss/total_loss': 2.2160938,\n 'learning_rate': 1.8113478e-05}\nI0620 09:30:51.152061 138935039562880 model_lib_v2.py:705] Step 16800 per-step time 0.442s\nI0620 09:30:51.152487 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.83244765,\n 'Loss/localization_loss': 1.2014735,\n 'Loss/regularization_loss': 0.14870737,\n 'Loss/total_loss': 2.1826284,\n 'learning_rate': 1.809017e-05}\nI0620 09:31:35.137780 138935039562880 model_lib_v2.py:705] Step 16900 per-step time 0.440s\nI0620 09:31:35.138138 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.9381403,\n 'Loss/localization_loss': 1.3210166,\n 'Loss/regularization_loss': 0.1486904,\n 'Loss/total_loss': 2.4078472,\n 'learning_rate': 1.8066732e-05}\nI0620 09:32:19.436826 138935039562880 model_lib_v2.py:705] Step 17000 per-step time 0.443s\nI0620 09:32:19.437219 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7451621,\n 'Loss/localization_loss': 1.2892618,\n 'Loss/regularization_loss': 0.14867377,\n 'Loss/total_loss': 2.1830976,\n 'learning_rate': 1.8043165e-05}\nI0620 09:33:04.043108 138935039562880 model_lib_v2.py:705] Step 17100 per-step time 0.446s\nI0620 09:33:04.043570 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.84243834,\n 'Loss/localization_loss': 1.3975606,\n 'Loss/regularization_loss': 0.1486569,\n 'Loss/total_loss': 2.3886557,\n 'learning_rate': 1.8019471e-05}\nI0620 09:33:48.159140 138935039562880 model_lib_v2.py:705] Step 17200 per-step time 0.441s\nI0620 09:33:48.159489 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.79055285,\n 'Loss/localization_loss': 1.3605955,\n 'Loss/regularization_loss': 0.14864044,\n 'Loss/total_loss': 2.2997887,\n 'learning_rate': 1.7995653e-05}\nI0620 09:34:32.284121 138935039562880 model_lib_v2.py:705] Step 17300 per-step time 0.441s\nI0620 09:34:32.284569 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8306674,\n 'Loss/localization_loss': 1.1816957,\n 'Loss/regularization_loss': 0.14862373,\n 'Loss/total_loss': 2.160987,\n 'learning_rate': 1.7971706e-05}\nI0620 09:35:16.335562 138935039562880 model_lib_v2.py:705] Step 17400 per-step time 0.440s\nI0620 09:35:16.335911 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8011681,\n 'Loss/localization_loss': 1.3317771,\n 'Loss/regularization_loss': 0.1486071,\n 'Loss/total_loss': 2.2815523,\n 'learning_rate': 1.7947632e-05}\nI0620 09:36:00.530655 138935039562880 model_lib_v2.py:705] Step 17500 per-step time 0.442s\nI0620 09:36:00.530972 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.79680705,\n 'Loss/localization_loss': 1.2970994,\n 'Loss/regularization_loss': 0.14859053,\n 'Loss/total_loss': 2.242497,\n 'learning_rate': 1.7923436e-05}\nI0620 09:36:44.804228 138935039562880 model_lib_v2.py:705] Step 17600 per-step time 0.443s\nI0620 09:36:44.804577 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80912256,\n 'Loss/localization_loss': 1.2310266,\n 'Loss/regularization_loss': 0.14857401,\n 'Loss/total_loss': 2.1887233,\n 'learning_rate': 1.7899112e-05}\nI0620 09:37:28.936866 138935039562880 model_lib_v2.py:705] Step 17700 per-step time 0.441s\nI0620 09:37:28.937211 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8708384,\n 'Loss/localization_loss': 1.3675542,\n 'Loss/regularization_loss': 0.14855789,\n 'Loss/total_loss': 2.3869505,\n 'learning_rate': 1.7874663e-05}\nI0620 09:38:13.047920 138935039562880 model_lib_v2.py:705] Step 17800 per-step time 0.441s\nI0620 09:38:13.048302 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7756709,\n 'Loss/localization_loss': 1.2292532,\n 'Loss/regularization_loss': 0.14854185,\n 'Loss/total_loss': 2.153466,\n 'learning_rate': 1.785009e-05}\nI0620 09:38:57.207464 138935039562880 model_lib_v2.py:705] Step 17900 per-step time 0.442s\nI0620 09:38:57.207830 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.76682055,\n 'Loss/localization_loss': 1.1922593,\n 'Loss/regularization_loss': 0.1485258,\n 'Loss/total_loss': 2.1076057,\n 'learning_rate': 1.7825394e-05}\nI0620 09:39:41.551132 138935039562880 model_lib_v2.py:705] Step 18000 per-step time 0.443s\nI0620 09:39:41.551548 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7390679,\n 'Loss/localization_loss': 1.1686691,\n 'Loss/regularization_loss': 0.14851002,\n 'Loss/total_loss': 2.056247,\n 'learning_rate': 1.7800572e-05}\nI0620 09:40:26.265606 138935039562880 model_lib_v2.py:705] Step 18100 per-step time 0.447s\nI0620 09:40:26.266031 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.75037706,\n 'Loss/localization_loss': 1.2077373,\n 'Loss/regularization_loss': 0.14849392,\n 'Loss/total_loss': 2.1066084,\n 'learning_rate': 1.7775628e-05}\nI0620 09:41:10.520562 138935039562880 model_lib_v2.py:705] Step 18200 per-step time 0.443s\nI0620 09:41:10.520955 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80362654,\n 'Loss/localization_loss': 1.1840304,\n 'Loss/regularization_loss': 0.14847796,\n 'Loss/total_loss': 2.136135,\n 'learning_rate': 1.775056e-05}\nI0620 09:41:54.908336 138935039562880 model_lib_v2.py:705] Step 18300 per-step time 0.444s\nI0620 09:41:54.908771 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7278193,\n 'Loss/localization_loss': 1.212096,\n 'Loss/regularization_loss': 0.14846204,\n 'Loss/total_loss': 2.0883772,\n 'learning_rate': 1.7725371e-05}\nI0620 09:42:39.039794 138935039562880 model_lib_v2.py:705] Step 18400 per-step time 0.441s\nI0620 09:42:39.040265 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.81228316,\n 'Loss/localization_loss': 1.373699,\n 'Loss/regularization_loss': 0.14844613,\n 'Loss/total_loss': 2.334428,\n 'learning_rate': 1.770006e-05}\nI0620 09:43:23.090139 138935039562880 model_lib_v2.py:705] Step 18500 per-step time 0.441s\nI0620 09:43:23.090558 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7644725,\n 'Loss/localization_loss': 1.2962817,\n 'Loss/regularization_loss': 0.14843033,\n 'Loss/total_loss': 2.2091846,\n 'learning_rate': 1.7674627e-05}\nI0620 09:44:07.289289 138935039562880 model_lib_v2.py:705] Step 18600 per-step time 0.442s\nI0620 09:44:07.289709 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.88283026,\n 'Loss/localization_loss': 1.3131293,\n 'Loss/regularization_loss': 0.14841461,\n 'Loss/total_loss': 2.3443742,\n 'learning_rate': 1.764907e-05}\nI0620 09:44:51.228665 138935039562880 model_lib_v2.py:705] Step 18700 per-step time 0.439s\nI0620 09:44:51.229047 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8739064,\n 'Loss/localization_loss': 1.2294619,\n 'Loss/regularization_loss': 0.14839919,\n 'Loss/total_loss': 2.2517676,\n 'learning_rate': 1.7623395e-05}\nI0620 09:45:35.314466 138935039562880 model_lib_v2.py:705] Step 18800 per-step time 0.441s\nI0620 09:45:35.314996 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.82798463,\n 'Loss/localization_loss': 1.2823234,\n 'Loss/regularization_loss': 0.14838368,\n 'Loss/total_loss': 2.2586918,\n 'learning_rate': 1.7597598e-05}\nI0620 09:46:19.391684 138935039562880 model_lib_v2.py:705] Step 18900 per-step time 0.441s\nI0620 09:46:19.392078 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.85664177,\n 'Loss/localization_loss': 1.32795,\n 'Loss/regularization_loss': 0.1483678,\n 'Loss/total_loss': 2.3329597,\n 'learning_rate': 1.7571683e-05}\nI0620 09:47:03.539769 138935039562880 model_lib_v2.py:705] Step 19000 per-step time 0.441s\nI0620 09:47:03.540152 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7630097,\n 'Loss/localization_loss': 1.249795,\n 'Loss/regularization_loss': 0.14835234,\n 'Loss/total_loss': 2.1611571,\n 'learning_rate': 1.7545646e-05}\nI0620 09:47:48.276173 138935039562880 model_lib_v2.py:705] Step 19100 per-step time 0.447s\nI0620 09:47:48.276605 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7892996,\n 'Loss/localization_loss': 1.2870519,\n 'Loss/regularization_loss': 0.14833681,\n 'Loss/total_loss': 2.2246885,\n 'learning_rate': 1.7519491e-05}\nI0620 09:48:32.331546 138935039562880 model_lib_v2.py:705] Step 19200 per-step time 0.441s\nI0620 09:48:32.331947 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.83965003,\n 'Loss/localization_loss': 1.2384255,\n 'Loss/regularization_loss': 0.14832182,\n 'Loss/total_loss': 2.2263973,\n 'learning_rate': 1.7493216e-05}\nI0620 09:49:16.471674 138935039562880 model_lib_v2.py:705] Step 19300 per-step time 0.441s\nI0620 09:49:16.472052 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.76281065,\n 'Loss/localization_loss': 1.2817005,\n 'Loss/regularization_loss': 0.14830677,\n 'Loss/total_loss': 2.1928182,\n 'learning_rate': 1.7466822e-05}\nI0620 09:50:00.580148 138935039562880 model_lib_v2.py:705] Step 19400 per-step time 0.441s\nI0620 09:50:00.580555 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7824675,\n 'Loss/localization_loss': 1.2135072,\n 'Loss/regularization_loss': 0.14829151,\n 'Loss/total_loss': 2.1442661,\n 'learning_rate': 1.7440312e-05}\nI0620 09:50:44.616056 138935039562880 model_lib_v2.py:705] Step 19500 per-step time 0.440s\nI0620 09:50:44.616505 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.77637,\n 'Loss/localization_loss': 1.2108005,\n 'Loss/regularization_loss': 0.14827646,\n 'Loss/total_loss': 2.135447,\n 'learning_rate': 1.7413682e-05}\nI0620 09:51:28.752566 138935039562880 model_lib_v2.py:705] Step 19600 per-step time 0.441s\nI0620 09:51:28.752929 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7418159,\n 'Loss/localization_loss': 1.2651049,\n 'Loss/regularization_loss': 0.14826097,\n 'Loss/total_loss': 2.155182,\n 'learning_rate': 1.7386938e-05}\nI0620 09:52:12.749599 138935039562880 model_lib_v2.py:705] Step 19700 per-step time 0.440s\nI0620 09:52:12.749992 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8498162,\n 'Loss/localization_loss': 1.1766741,\n 'Loss/regularization_loss': 0.14824587,\n 'Loss/total_loss': 2.174736,\n 'learning_rate': 1.7360073e-05}\nI0620 09:52:56.844583 138935039562880 model_lib_v2.py:705] Step 19800 per-step time 0.441s\nI0620 09:52:56.844966 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7944039,\n 'Loss/localization_loss': 1.2250445,\n 'Loss/regularization_loss': 0.14823098,\n 'Loss/total_loss': 2.1676793,\n 'learning_rate': 1.7333094e-05}\nI0620 09:53:40.936376 138935039562880 model_lib_v2.py:705] Step 19900 per-step time 0.441s\nI0620 09:53:40.936791 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8272357,\n 'Loss/localization_loss': 1.3296789,\n 'Loss/regularization_loss': 0.14821608,\n 'Loss/total_loss': 2.3051305,\n 'learning_rate': 1.7305998e-05}\nI0620 09:54:25.025450 138935039562880 model_lib_v2.py:705] Step 20000 per-step time 0.441s\nI0620 09:54:25.025834 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.745306,\n 'Loss/localization_loss': 1.1835392,\n 'Loss/regularization_loss': 0.14820136,\n 'Loss/total_loss': 2.0770466,\n 'learning_rate': 1.7278788e-05}\nI0620 09:55:09.548130 138935039562880 model_lib_v2.py:705] Step 20100 per-step time 0.445s\nI0620 09:55:09.548610 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7543188,\n 'Loss/localization_loss': 1.2910094,\n 'Loss/regularization_loss': 0.14818648,\n 'Loss/total_loss': 2.1935148,\n 'learning_rate': 1.7251463e-05}\nI0620 09:55:53.833117 138935039562880 model_lib_v2.py:705] Step 20200 per-step time 0.443s\nI0620 09:55:53.833559 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.78205013,\n 'Loss/localization_loss': 1.1811975,\n 'Loss/regularization_loss': 0.14817154,\n 'Loss/total_loss': 2.1114192,\n 'learning_rate': 1.722402e-05}\nI0620 09:56:37.874220 138935039562880 model_lib_v2.py:705] Step 20300 per-step time 0.440s\nI0620 09:56:37.874626 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7890376,\n 'Loss/localization_loss': 1.2754511,\n 'Loss/regularization_loss': 0.14815685,\n 'Loss/total_loss': 2.2126455,\n 'learning_rate': 1.7196466e-05}\nI0620 09:57:21.984363 138935039562880 model_lib_v2.py:705] Step 20400 per-step time 0.441s\nI0620 09:57:21.984731 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.77151716,\n 'Loss/localization_loss': 1.1694789,\n 'Loss/regularization_loss': 0.1481426,\n 'Loss/total_loss': 2.0891387,\n 'learning_rate': 1.7168799e-05}\nI0620 09:58:06.233326 138935039562880 model_lib_v2.py:705] Step 20500 per-step time 0.443s\nI0620 09:58:06.233869 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.72944474,\n 'Loss/localization_loss': 1.1516683,\n 'Loss/regularization_loss': 0.14812812,\n 'Loss/total_loss': 2.029241,\n 'learning_rate': 1.7141016e-05}\nI0620 09:58:50.208638 138935039562880 model_lib_v2.py:705] Step 20600 per-step time 0.440s\nI0620 09:58:50.209063 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.76864535,\n 'Loss/localization_loss': 1.2952132,\n 'Loss/regularization_loss': 0.14811377,\n 'Loss/total_loss': 2.2119722,\n 'learning_rate': 1.711312e-05}\nI0620 09:59:34.244391 138935039562880 model_lib_v2.py:705] Step 20700 per-step time 0.440s\nI0620 09:59:34.244739 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.815668,\n 'Loss/localization_loss': 1.1998019,\n 'Loss/regularization_loss': 0.14809962,\n 'Loss/total_loss': 2.1635695,\n 'learning_rate': 1.7085113e-05}\nI0620 10:00:18.371556 138935039562880 model_lib_v2.py:705] Step 20800 per-step time 0.441s\nI0620 10:00:18.371979 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8043135,\n 'Loss/localization_loss': 1.2804849,\n 'Loss/regularization_loss': 0.14808539,\n 'Loss/total_loss': 2.2328837,\n 'learning_rate': 1.7056995e-05}\nI0620 10:01:02.512919 138935039562880 model_lib_v2.py:705] Step 20900 per-step time 0.441s\nI0620 10:01:02.513308 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.768751,\n 'Loss/localization_loss': 1.0979661,\n 'Loss/regularization_loss': 0.14807108,\n 'Loss/total_loss': 2.0147882,\n 'learning_rate': 1.7028762e-05}\nI0620 10:01:46.660496 138935039562880 model_lib_v2.py:705] Step 21000 per-step time 0.441s\nI0620 10:01:46.660856 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7227694,\n 'Loss/localization_loss': 1.1877207,\n 'Loss/regularization_loss': 0.14805697,\n 'Loss/total_loss': 2.058547,\n 'learning_rate': 1.700042e-05}\nI0620 10:02:31.614896 138935039562880 model_lib_v2.py:705] Step 21100 per-step time 0.450s\nI0620 10:02:31.615263 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.854615,\n 'Loss/localization_loss': 1.2528398,\n 'Loss/regularization_loss': 0.14804305,\n 'Loss/total_loss': 2.255498,\n 'learning_rate': 1.6971966e-05}\nI0620 10:03:15.635844 138935039562880 model_lib_v2.py:705] Step 21200 per-step time 0.440s\nI0620 10:03:15.636402 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.754501,\n 'Loss/localization_loss': 1.1632875,\n 'Loss/regularization_loss': 0.14802912,\n 'Loss/total_loss': 2.0658176,\n 'learning_rate': 1.6943404e-05}\nI0620 10:03:59.867715 138935039562880 model_lib_v2.py:705] Step 21300 per-step time 0.442s\nI0620 10:03:59.868128 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7792114,\n 'Loss/localization_loss': 1.2749883,\n 'Loss/regularization_loss': 0.14801514,\n 'Loss/total_loss': 2.202215,\n 'learning_rate': 1.6914732e-05}\nI0620 10:04:43.665023 138935039562880 model_lib_v2.py:705] Step 21400 per-step time 0.438s\nI0620 10:04:43.665423 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.77200574,\n 'Loss/localization_loss': 1.2327907,\n 'Loss/regularization_loss': 0.14800115,\n 'Loss/total_loss': 2.1527977,\n 'learning_rate': 1.6885948e-05}\nI0620 10:05:27.724791 138935039562880 model_lib_v2.py:705] Step 21500 per-step time 0.441s\nI0620 10:05:27.725184 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8102483,\n 'Loss/localization_loss': 1.29175,\n 'Loss/regularization_loss': 0.1479874,\n 'Loss/total_loss': 2.2499857,\n 'learning_rate': 1.6857057e-05}\nI0620 10:06:11.887495 138935039562880 model_lib_v2.py:705] Step 21600 per-step time 0.442s\nI0620 10:06:11.887858 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8296201,\n 'Loss/localization_loss': 1.2951634,\n 'Loss/regularization_loss': 0.14797363,\n 'Loss/total_loss': 2.272757,\n 'learning_rate': 1.6828057e-05}\nI0620 10:06:55.926620 138935039562880 model_lib_v2.py:705] Step 21700 per-step time 0.440s\nI0620 10:06:55.927020 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.77719194,\n 'Loss/localization_loss': 1.1538439,\n 'Loss/regularization_loss': 0.14795996,\n 'Loss/total_loss': 2.0789957,\n 'learning_rate': 1.679895e-05}\nI0620 10:07:40.328088 138935039562880 model_lib_v2.py:705] Step 21800 per-step time 0.444s\nI0620 10:07:40.328503 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8079058,\n 'Loss/localization_loss': 1.2205126,\n 'Loss/regularization_loss': 0.14794615,\n 'Loss/total_loss': 2.1763644,\n 'learning_rate': 1.6769736e-05}\nI0620 10:08:24.387937 138935039562880 model_lib_v2.py:705] Step 21900 per-step time 0.441s\nI0620 10:08:24.388333 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.6588973,\n 'Loss/localization_loss': 1.1220586,\n 'Loss/regularization_loss': 0.14793263,\n 'Loss/total_loss': 1.9288886,\n 'learning_rate': 1.6740412e-05}\nI0620 10:09:08.507392 138935039562880 model_lib_v2.py:705] Step 22000 per-step time 0.441s\nI0620 10:09:08.507754 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.72227985,\n 'Loss/localization_loss': 1.1596274,\n 'Loss/regularization_loss': 0.14791907,\n 'Loss/total_loss': 2.0298264,\n 'learning_rate': 1.6710985e-05}\nI0620 10:09:53.250114 138935039562880 model_lib_v2.py:705] Step 22100 per-step time 0.447s\nI0620 10:09:53.250562 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.76249504,\n 'Loss/localization_loss': 1.189942,\n 'Loss/regularization_loss': 0.14790554,\n 'Loss/total_loss': 2.1003425,\n 'learning_rate': 1.668145e-05}\nI0620 10:10:37.336843 138935039562880 model_lib_v2.py:705] Step 22200 per-step time 0.441s\nI0620 10:10:37.337314 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.6986486,\n 'Loss/localization_loss': 1.2139428,\n 'Loss/regularization_loss': 0.14789207,\n 'Loss/total_loss': 2.0604835,\n 'learning_rate': 1.665181e-05}\nI0620 10:11:21.524651 138935039562880 model_lib_v2.py:705] Step 22300 per-step time 0.442s\nI0620 10:11:21.524982 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.785348,\n 'Loss/localization_loss': 1.2976611,\n 'Loss/regularization_loss': 0.14787883,\n 'Loss/total_loss': 2.230888,\n 'learning_rate': 1.6622063e-05}\nI0620 10:12:05.600287 138935039562880 model_lib_v2.py:705] Step 22400 per-step time 0.441s\nI0620 10:12:05.600795 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.6852888,\n 'Loss/localization_loss': 1.1711828,\n 'Loss/regularization_loss': 0.14786558,\n 'Loss/total_loss': 2.004337,\n 'learning_rate': 1.6592212e-05}\nI0620 10:12:49.649934 138935039562880 model_lib_v2.py:705] Step 22500 per-step time 0.441s\nI0620 10:12:49.650274 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.6622355,\n 'Loss/localization_loss': 1.1948289,\n 'Loss/regularization_loss': 0.14785247,\n 'Loss/total_loss': 2.004917,\n 'learning_rate': 1.6562257e-05}\nI0620 10:13:33.792440 138935039562880 model_lib_v2.py:705] Step 22600 per-step time 0.441s\nI0620 10:13:33.792839 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7513434,\n 'Loss/localization_loss': 1.1779712,\n 'Loss/regularization_loss': 0.1478392,\n 'Loss/total_loss': 2.077154,\n 'learning_rate': 1.6532198e-05}\nI0620 10:14:18.037688 138935039562880 model_lib_v2.py:705] Step 22700 per-step time 0.442s\nI0620 10:14:18.038100 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8133918,\n 'Loss/localization_loss': 1.1511955,\n 'Loss/regularization_loss': 0.14782593,\n 'Loss/total_loss': 2.1124134,\n 'learning_rate': 1.6502037e-05}\nI0620 10:15:02.160004 138935039562880 model_lib_v2.py:705] Step 22800 per-step time 0.441s\nI0620 10:15:02.160346 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7575666,\n 'Loss/localization_loss': 1.2416282,\n 'Loss/regularization_loss': 0.1478129,\n 'Loss/total_loss': 2.1470077,\n 'learning_rate': 1.6471771e-05}\nI0620 10:15:46.125240 138935039562880 model_lib_v2.py:705] Step 22900 per-step time 0.440s\nI0620 10:15:46.125613 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7209861,\n 'Loss/localization_loss': 1.1300592,\n 'Loss/regularization_loss': 0.1477998,\n 'Loss/total_loss': 1.9988451,\n 'learning_rate': 1.6441405e-05}\nI0620 10:16:30.119515 138935039562880 model_lib_v2.py:705] Step 23000 per-step time 0.440s\nI0620 10:16:30.119911 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7405775,\n 'Loss/localization_loss': 1.1794921,\n 'Loss/regularization_loss': 0.14778684,\n 'Loss/total_loss': 2.0678563,\n 'learning_rate': 1.6410935e-05}\nI0620 10:17:15.362614 138935039562880 model_lib_v2.py:705] Step 23100 per-step time 0.452s\nI0620 10:17:15.363000 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8577424,\n 'Loss/localization_loss': 1.28391,\n 'Loss/regularization_loss': 0.14777404,\n 'Loss/total_loss': 2.2894263,\n 'learning_rate': 1.6380365e-05}\nI0620 10:17:59.610899 138935039562880 model_lib_v2.py:705] Step 23200 per-step time 0.442s\nI0620 10:17:59.611307 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.74520266,\n 'Loss/localization_loss': 1.1164397,\n 'Loss/regularization_loss': 0.14776112,\n 'Loss/total_loss': 2.0094035,\n 'learning_rate': 1.6349695e-05}\nI0620 10:18:43.535943 138935039562880 model_lib_v2.py:705] Step 23300 per-step time 0.439s\nI0620 10:18:43.536349 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80891085,\n 'Loss/localization_loss': 1.2253568,\n 'Loss/regularization_loss': 0.14774846,\n 'Loss/total_loss': 2.1820164,\n 'learning_rate': 1.6318923e-05}\nI0620 10:19:27.516058 138935039562880 model_lib_v2.py:705] Step 23400 per-step time 0.440s\nI0620 10:19:27.516500 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.70851886,\n 'Loss/localization_loss': 1.1469815,\n 'Loss/regularization_loss': 0.1477358,\n 'Loss/total_loss': 2.0032363,\n 'learning_rate': 1.6288051e-05}\nI0620 10:20:11.599949 138935039562880 model_lib_v2.py:705] Step 23500 per-step time 0.441s\nI0620 10:20:11.600350 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.6976913,\n 'Loss/localization_loss': 1.13971,\n 'Loss/regularization_loss': 0.14772302,\n 'Loss/total_loss': 1.9851243,\n 'learning_rate': 1.6257081e-05}\nI0620 10:20:55.729096 138935039562880 model_lib_v2.py:705] Step 23600 per-step time 0.441s\nI0620 10:20:55.729511 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.79057646,\n 'Loss/localization_loss': 1.1666707,\n 'Loss/regularization_loss': 0.14771056,\n 'Loss/total_loss': 2.1049576,\n 'learning_rate': 1.622601e-05}\nI0620 10:21:39.837991 138935039562880 model_lib_v2.py:705] Step 23700 per-step time 0.441s\nI0620 10:21:39.838435 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7108526,\n 'Loss/localization_loss': 1.1712785,\n 'Loss/regularization_loss': 0.14769793,\n 'Loss/total_loss': 2.029829,\n 'learning_rate': 1.6194841e-05}\nI0620 10:22:23.947399 138935039562880 model_lib_v2.py:705] Step 23800 per-step time 0.441s\nI0620 10:22:23.947805 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8145607,\n 'Loss/localization_loss': 1.171659,\n 'Loss/regularization_loss': 0.14768533,\n 'Loss/total_loss': 2.133905,\n 'learning_rate': 1.6163574e-05}\nI0620 10:23:07.945332 138935039562880 model_lib_v2.py:705] Step 23900 per-step time 0.440s\nI0620 10:23:07.945753 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.76613617,\n 'Loss/localization_loss': 1.1041102,\n 'Loss/regularization_loss': 0.14767286,\n 'Loss/total_loss': 2.0179193,\n 'learning_rate': 1.6132211e-05}\nI0620 10:23:51.946129 138935039562880 model_lib_v2.py:705] Step 24000 per-step time 0.440s\nI0620 10:23:51.946527 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.74137056,\n 'Loss/localization_loss': 1.1665208,\n 'Loss/regularization_loss': 0.14766032,\n 'Loss/total_loss': 2.0555515,\n 'learning_rate': 1.610075e-05}\nI0620 10:24:36.762295 138935039562880 model_lib_v2.py:705] Step 24100 per-step time 0.448s\nI0620 10:24:36.762673 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.67789775,\n 'Loss/localization_loss': 1.001642,\n 'Loss/regularization_loss': 0.147648,\n 'Loss/total_loss': 1.8271878,\n 'learning_rate': 1.6069194e-05}\nI0620 10:25:20.840450 138935039562880 model_lib_v2.py:705] Step 24200 per-step time 0.441s\nI0620 10:25:20.840818 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80416596,\n 'Loss/localization_loss': 1.1709244,\n 'Loss/regularization_loss': 0.14763568,\n 'Loss/total_loss': 2.122726,\n 'learning_rate': 1.603754e-05}\nI0620 10:26:05.011565 138935039562880 model_lib_v2.py:705] Step 24300 per-step time 0.442s\nI0620 10:26:05.011945 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7140579,\n 'Loss/localization_loss': 1.1665089,\n 'Loss/regularization_loss': 0.14762324,\n 'Loss/total_loss': 2.0281901,\n 'learning_rate': 1.6005792e-05}\nI0620 10:26:49.315017 138935039562880 model_lib_v2.py:705] Step 24400 per-step time 0.443s\nI0620 10:26:49.315383 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.71716565,\n 'Loss/localization_loss': 1.1329696,\n 'Loss/regularization_loss': 0.14761087,\n 'Loss/total_loss': 1.9977462,\n 'learning_rate': 1.5973947e-05}\nI0620 10:27:33.641423 138935039562880 model_lib_v2.py:705] Step 24500 per-step time 0.443s\nI0620 10:27:33.641832 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.80776477,\n 'Loss/localization_loss': 1.2858493,\n 'Loss/regularization_loss': 0.1475986,\n 'Loss/total_loss': 2.2412126,\n 'learning_rate': 1.594201e-05}\nI0620 10:28:17.722003 138935039562880 model_lib_v2.py:705] Step 24600 per-step time 0.441s\nI0620 10:28:17.722399 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.69436353,\n 'Loss/localization_loss': 1.1141292,\n 'Loss/regularization_loss': 0.1475864,\n 'Loss/total_loss': 1.9560791,\n 'learning_rate': 1.5909978e-05}\nI0620 10:29:01.908931 138935039562880 model_lib_v2.py:705] Step 24700 per-step time 0.442s\nI0620 10:29:01.909353 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.8702779,\n 'Loss/localization_loss': 1.1927006,\n 'Loss/regularization_loss': 0.14757441,\n 'Loss/total_loss': 2.210553,\n 'learning_rate': 1.5877851e-05}\nI0620 10:29:46.198687 138935039562880 model_lib_v2.py:705] Step 24800 per-step time 0.443s\nI0620 10:29:46.199064 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.69928336,\n 'Loss/localization_loss': 1.0956057,\n 'Loss/regularization_loss': 0.14756243,\n 'Loss/total_loss': 1.9424515,\n 'learning_rate': 1.5845633e-05}\nI0620 10:30:30.307210 138935039562880 model_lib_v2.py:705] Step 24900 per-step time 0.441s\nI0620 10:30:30.307608 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7170856,\n 'Loss/localization_loss': 1.2095802,\n 'Loss/regularization_loss': 0.14755043,\n 'Loss/total_loss': 2.0742161,\n 'learning_rate': 1.5813323e-05}\nI0620 10:31:14.238877 138935039562880 model_lib_v2.py:705] Step 25000 per-step time 0.439s\nI0620 10:31:14.239285 138935039562880 model_lib_v2.py:708] {'Loss/classification_loss': 0.7545384,\n 'Loss/localization_loss': 1.2335978,\n 'Loss/regularization_loss': 0.14753832,\n 'Loss/total_loss': 2.1356745,\n 'learning_rate': 1.5780919e-05}\n\n🔵 Evaluasi setelah iterasi ke-2\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nW0620 10:31:23.783338 136737144763520 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\nI0620 10:31:23.783571 136737144763520 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\nI0620 10:31:23.783668 136737144763520 config_util.py:552] Maybe overwriting use_bfloat16: False\nI0620 10:31:23.783746 136737144763520 config_util.py:552] Maybe overwriting eval_num_epochs: 1\nW0620 10:31:23.783838 136737144763520 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\nI0620 10:31:25.410540 136737144763520 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 10:31:25.410806 136737144763520 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 10:31:25.410932 136737144763520 dataset_builder.py:80] Number of filenames to read: 1\nW0620 10:31:25.411006 136737144763520 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 10:31:25.413064 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 10:31:25.442963 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 10:31:29.102312 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 10:31:30.000368 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 10:31:32.285960 136737144763520 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\nI0620 10:31:32.287066 136737144763520 checkpoint_utils.py:145] Found new checkpoint at /kaggle/working/training/ckpt-26\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 10:31:37.779170 136737144763520 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:31:50.921706 136737144763520 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 10:31:56.554980 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 10:31:56.565581 136737144763520 model_lib_v2.py:966] Finished eval step 0\nW0620 10:31:56.681473 136737144763520 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nI0620 10:32:00.292383 136737144763520 coco_evaluation.py:293] Performing evaluation on 39 images.\ncreating index...\nindex created!\nI0620 10:32:00.293525 136737144763520 coco_tools.py:116] Loading and preparing annotation results...\nI0620 10:32:00.297116 136737144763520 coco_tools.py:138] DONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.80s).\nAccumulating evaluation results...\nDONE (t=0.06s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.076\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\nI0620 10:32:01.157235 136737144763520 model_lib_v2.py:1015] Eval metrics at step 25000\nI0620 10:32:01.165753 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.022255\nI0620 10:32:01.167073 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.084978\nI0620 10:32:01.168510 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.005610\nI0620 10:32:01.169915 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\nI0620 10:32:01.171302 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.015537\nI0620 10:32:01.172751 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.033051\nI0620 10:32:01.173985 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.013592\nI0620 10:32:01.175550 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.054976\nI0620 10:32:01.177135 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.109257\nI0620 10:32:01.178159 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\nI0620 10:32:01.179362 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.075878\nI0620 10:32:01.180975 136737144763520 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.168913\nI0620 10:32:01.182250 136737144763520 model_lib_v2.py:1018] \t+ Loss/localization_loss: 1.115828\nI0620 10:32:01.183257 136737144763520 model_lib_v2.py:1018] \t+ Loss/classification_loss: 1.019407\nI0620 10:32:01.184262 136737144763520 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.147538\nI0620 10:32:01.185228 136737144763520 model_lib_v2.py:1018] \t+ Loss/total_loss: 2.282772\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n    tf.compat.v1.app.run()\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 81, in main\n    model_lib_v2.eval_continuously(\n  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n    for latest_checkpoint in tf.train.checkpoints_iterator(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n    time.sleep(time_to_next_eval)\nKeyboardInterrupt\n\n🟢 Training iterasi ke-3 (25000 -> 37500 steps)\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nI0620 10:35:24.210869 132745443468416 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI0620 10:35:24.215065 132745443468416 config_util.py:552] Maybe overwriting train_steps: 37500\nI0620 10:35:24.215260 132745443468416 config_util.py:552] Maybe overwriting use_bfloat16: False\nW0620 10:35:24.383772 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI0620 10:35:24.387630 132745443468416 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 10:35:24.387849 132745443468416 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 10:35:24.387972 132745443468416 dataset_builder.py:80] Number of filenames to read: 1\nW0620 10:35:24.388056 132745443468416 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 10:35:24.390441 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 10:35:24.415031 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 10:35:30.903665 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 10:35:33.564390 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nW0620 10:35:35.984560 132745443468416 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 10:35:44.863525 132738212410944 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:35:54.295400 132738220803648 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:35:59.536656 132738220803648 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:03.365855 132738212410944 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 10:36:16.138075 132738933835328 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\nI0620 10:36:17.068297 132738933835328 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:22.259482 132738682189376 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:26.325325 132745443468416 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 10:36:29.581716 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:29.584062 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:29.585633 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:29.587149 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:32.392732 132738682189376 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:37.412771 132738933835328 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:41.863147 132745443468416 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 10:36:44.527132 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:44.529598 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:44.531299 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:44.533089 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:46.834284 132738933835328 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:51.878984 132738682189376 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:36:56.491942 132745443468416 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 10:36:59.547073 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:36:59.549429 132745443468416 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 10:37:02.451415 132738682189376 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:37:07.536736 132738933835328 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 10:37:12.162473 132745443468416 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 10:38:23.571738 132745443468416 model_lib_v2.py:705] Step 25100 per-step time 1.278s\nI0620 10:38:23.572164 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.726526,\n 'Loss/localization_loss': 1.1251848,\n 'Loss/regularization_loss': 0.14752643,\n 'Loss/total_loss': 1.9992373,\n 'learning_rate': 1.5748425e-05}\nI0620 10:39:07.994647 132745443468416 model_lib_v2.py:705] Step 25200 per-step time 0.444s\nI0620 10:39:07.995039 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7033316,\n 'Loss/localization_loss': 1.1860998,\n 'Loss/regularization_loss': 0.14751454,\n 'Loss/total_loss': 2.0369458,\n 'learning_rate': 1.571584e-05}\nI0620 10:39:52.385989 132745443468416 model_lib_v2.py:705] Step 25300 per-step time 0.444s\nI0620 10:39:52.386413 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.76856196,\n 'Loss/localization_loss': 1.1075845,\n 'Loss/regularization_loss': 0.14750274,\n 'Loss/total_loss': 2.0236492,\n 'learning_rate': 1.5683165e-05}\nI0620 10:40:36.505001 132745443468416 model_lib_v2.py:705] Step 25400 per-step time 0.441s\nI0620 10:40:36.505408 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6714157,\n 'Loss/localization_loss': 1.2027966,\n 'Loss/regularization_loss': 0.14749122,\n 'Loss/total_loss': 2.0217035,\n 'learning_rate': 1.5650397e-05}\nI0620 10:41:20.780036 132745443468416 model_lib_v2.py:705] Step 25500 per-step time 0.443s\nI0620 10:41:20.780522 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7136521,\n 'Loss/localization_loss': 1.0484568,\n 'Loss/regularization_loss': 0.1474797,\n 'Loss/total_loss': 1.9095886,\n 'learning_rate': 1.5617545e-05}\nI0620 10:42:05.386478 132745443468416 model_lib_v2.py:705] Step 25600 per-step time 0.446s\nI0620 10:42:05.386881 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.79584855,\n 'Loss/localization_loss': 1.2500358,\n 'Loss/regularization_loss': 0.14746784,\n 'Loss/total_loss': 2.1933522,\n 'learning_rate': 1.55846e-05}\nI0620 10:42:49.702558 132745443468416 model_lib_v2.py:705] Step 25700 per-step time 0.443s\nI0620 10:42:49.702954 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7462877,\n 'Loss/localization_loss': 1.2632155,\n 'Loss/regularization_loss': 0.14745615,\n 'Loss/total_loss': 2.1569595,\n 'learning_rate': 1.5551566e-05}\nI0620 10:43:34.045428 132745443468416 model_lib_v2.py:705] Step 25800 per-step time 0.443s\nI0620 10:43:34.045854 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.68528295,\n 'Loss/localization_loss': 1.0937304,\n 'Loss/regularization_loss': 0.14744458,\n 'Loss/total_loss': 1.926458,\n 'learning_rate': 1.5518448e-05}\nI0620 10:44:18.306839 132745443468416 model_lib_v2.py:705] Step 25900 per-step time 0.443s\nI0620 10:44:18.307245 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.8123262,\n 'Loss/localization_loss': 1.2230754,\n 'Loss/regularization_loss': 0.147433,\n 'Loss/total_loss': 2.1828346,\n 'learning_rate': 1.548524e-05}\nI0620 10:45:02.441577 132745443468416 model_lib_v2.py:705] Step 26000 per-step time 0.441s\nI0620 10:45:02.442015 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7529808,\n 'Loss/localization_loss': 1.2193699,\n 'Loss/regularization_loss': 0.14742164,\n 'Loss/total_loss': 2.1197724,\n 'learning_rate': 1.5451946e-05}\nI0620 10:45:47.379259 132745443468416 model_lib_v2.py:705] Step 26100 per-step time 0.449s\nI0620 10:45:47.379866 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.804865,\n 'Loss/localization_loss': 1.1335899,\n 'Loss/regularization_loss': 0.14741036,\n 'Loss/total_loss': 2.0858653,\n 'learning_rate': 1.5418567e-05}\nI0620 10:46:31.826179 132745443468416 model_lib_v2.py:705] Step 26200 per-step time 0.444s\nI0620 10:46:31.826554 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.74892914,\n 'Loss/localization_loss': 1.2302692,\n 'Loss/regularization_loss': 0.14739914,\n 'Loss/total_loss': 2.1265976,\n 'learning_rate': 1.53851e-05}\nI0620 10:47:16.087469 132745443468416 model_lib_v2.py:705] Step 26300 per-step time 0.443s\nI0620 10:47:16.087865 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.737252,\n 'Loss/localization_loss': 1.1357365,\n 'Loss/regularization_loss': 0.14738782,\n 'Loss/total_loss': 2.0203762,\n 'learning_rate': 1.535155e-05}\nI0620 10:48:00.268073 132745443468416 model_lib_v2.py:705] Step 26400 per-step time 0.442s\nI0620 10:48:00.268528 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66372025,\n 'Loss/localization_loss': 1.0415059,\n 'Loss/regularization_loss': 0.14737661,\n 'Loss/total_loss': 1.852603,\n 'learning_rate': 1.5317915e-05}\nI0620 10:48:44.366136 132745443468416 model_lib_v2.py:705] Step 26500 per-step time 0.441s\nI0620 10:48:44.366549 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.8034569,\n 'Loss/localization_loss': 1.1563671,\n 'Loss/regularization_loss': 0.14736524,\n 'Loss/total_loss': 2.1071892,\n 'learning_rate': 1.5284195e-05}\nI0620 10:49:28.653490 132745443468416 model_lib_v2.py:705] Step 26600 per-step time 0.443s\nI0620 10:49:28.653854 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6536236,\n 'Loss/localization_loss': 1.0586846,\n 'Loss/regularization_loss': 0.14735395,\n 'Loss/total_loss': 1.859662,\n 'learning_rate': 1.5250392e-05}\nI0620 10:50:12.995220 132745443468416 model_lib_v2.py:705] Step 26700 per-step time 0.443s\nI0620 10:50:12.995661 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.72584724,\n 'Loss/localization_loss': 1.1181977,\n 'Loss/regularization_loss': 0.14734262,\n 'Loss/total_loss': 1.9913876,\n 'learning_rate': 1.5216507e-05}\nI0620 10:50:57.236848 132745443468416 model_lib_v2.py:705] Step 26800 per-step time 0.442s\nI0620 10:50:57.237221 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7426851,\n 'Loss/localization_loss': 1.1890557,\n 'Loss/regularization_loss': 0.14733158,\n 'Loss/total_loss': 2.079072,\n 'learning_rate': 1.5182536e-05}\nI0620 10:51:41.379374 132745443468416 model_lib_v2.py:705] Step 26900 per-step time 0.441s\nI0620 10:51:41.379814 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.70990527,\n 'Loss/localization_loss': 1.1209104,\n 'Loss/regularization_loss': 0.14732072,\n 'Loss/total_loss': 1.9781364,\n 'learning_rate': 1.5148486e-05}\nI0620 10:52:25.567004 132745443468416 model_lib_v2.py:705] Step 27000 per-step time 0.442s\nI0620 10:52:25.567482 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.73441166,\n 'Loss/localization_loss': 1.0566039,\n 'Loss/regularization_loss': 0.14730972,\n 'Loss/total_loss': 1.9383253,\n 'learning_rate': 1.5114353e-05}\nI0620 10:53:10.294283 132745443468416 model_lib_v2.py:705] Step 27100 per-step time 0.447s\nI0620 10:53:10.294702 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69950557,\n 'Loss/localization_loss': 1.0300839,\n 'Loss/regularization_loss': 0.14729865,\n 'Loss/total_loss': 1.8768883,\n 'learning_rate': 1.5080142e-05}\nI0620 10:53:54.499696 132745443468416 model_lib_v2.py:705] Step 27200 per-step time 0.442s\nI0620 10:53:54.500039 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7823125,\n 'Loss/localization_loss': 1.1409713,\n 'Loss/regularization_loss': 0.1472877,\n 'Loss/total_loss': 2.0705714,\n 'learning_rate': 1.5045847e-05}\nI0620 10:54:38.619218 132745443468416 model_lib_v2.py:705] Step 27300 per-step time 0.441s\nI0620 10:54:38.619607 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.68945134,\n 'Loss/localization_loss': 1.0918722,\n 'Loss/regularization_loss': 0.14727706,\n 'Loss/total_loss': 1.9286007,\n 'learning_rate': 1.5011475e-05}\nI0620 10:55:22.818671 132745443468416 model_lib_v2.py:705] Step 27400 per-step time 0.442s\nI0620 10:55:22.819088 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6909642,\n 'Loss/localization_loss': 1.086134,\n 'Loss/regularization_loss': 0.14726616,\n 'Loss/total_loss': 1.9243644,\n 'learning_rate': 1.4977023e-05}\nI0620 10:56:07.094542 132745443468416 model_lib_v2.py:705] Step 27500 per-step time 0.443s\nI0620 10:56:07.094945 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.75172144,\n 'Loss/localization_loss': 1.2010627,\n 'Loss/regularization_loss': 0.14725566,\n 'Loss/total_loss': 2.1000397,\n 'learning_rate': 1.494249e-05}\nI0620 10:56:51.366970 132745443468416 model_lib_v2.py:705] Step 27600 per-step time 0.443s\nI0620 10:56:51.367389 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66788316,\n 'Loss/localization_loss': 1.1125578,\n 'Loss/regularization_loss': 0.14724484,\n 'Loss/total_loss': 1.9276857,\n 'learning_rate': 1.4907881e-05}\nI0620 10:57:35.560328 132745443468416 model_lib_v2.py:705] Step 27700 per-step time 0.442s\nI0620 10:57:35.560800 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7043505,\n 'Loss/localization_loss': 1.0769393,\n 'Loss/regularization_loss': 0.14723437,\n 'Loss/total_loss': 1.928524,\n 'learning_rate': 1.4873195e-05}\nI0620 10:58:20.035519 132745443468416 model_lib_v2.py:705] Step 27800 per-step time 0.445s\nI0620 10:58:20.035889 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6850034,\n 'Loss/localization_loss': 1.0380602,\n 'Loss/regularization_loss': 0.14722386,\n 'Loss/total_loss': 1.8702874,\n 'learning_rate': 1.48384315e-05}\nI0620 10:59:04.165027 132745443468416 model_lib_v2.py:705] Step 27900 per-step time 0.441s\nI0620 10:59:04.165410 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6582279,\n 'Loss/localization_loss': 1.0797659,\n 'Loss/regularization_loss': 0.14721349,\n 'Loss/total_loss': 1.8852073,\n 'learning_rate': 1.4803591e-05}\nI0620 10:59:48.405924 132745443468416 model_lib_v2.py:705] Step 28000 per-step time 0.442s\nI0620 10:59:48.406319 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6192082,\n 'Loss/localization_loss': 0.9842273,\n 'Loss/regularization_loss': 0.14720294,\n 'Loss/total_loss': 1.7506385,\n 'learning_rate': 1.4768674e-05}\nI0620 11:00:33.278840 132745443468416 model_lib_v2.py:705] Step 28100 per-step time 0.449s\nI0620 11:00:33.279223 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.75863564,\n 'Loss/localization_loss': 1.139921,\n 'Loss/regularization_loss': 0.14719254,\n 'Loss/total_loss': 2.0457492,\n 'learning_rate': 1.4733682e-05}\nI0620 11:01:17.669401 132745443468416 model_lib_v2.py:705] Step 28200 per-step time 0.444s\nI0620 11:01:17.669818 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.73653555,\n 'Loss/localization_loss': 1.0582948,\n 'Loss/regularization_loss': 0.14718194,\n 'Loss/total_loss': 1.9420123,\n 'learning_rate': 1.4698616e-05}\nI0620 11:02:01.779298 132745443468416 model_lib_v2.py:705] Step 28300 per-step time 0.441s\nI0620 11:02:01.779682 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.74683166,\n 'Loss/localization_loss': 1.0955164,\n 'Loss/regularization_loss': 0.14717169,\n 'Loss/total_loss': 1.98952,\n 'learning_rate': 1.4663476e-05}\nI0620 11:02:46.205319 132745443468416 model_lib_v2.py:705] Step 28400 per-step time 0.444s\nI0620 11:02:46.205686 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7170827,\n 'Loss/localization_loss': 1.0757835,\n 'Loss/regularization_loss': 0.1471613,\n 'Loss/total_loss': 1.9400274,\n 'learning_rate': 1.462826e-05}\nI0620 11:03:30.456514 132745443468416 model_lib_v2.py:705] Step 28500 per-step time 0.443s\nI0620 11:03:30.456939 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6958591,\n 'Loss/localization_loss': 1.0885437,\n 'Loss/regularization_loss': 0.14715123,\n 'Loss/total_loss': 1.9315541,\n 'learning_rate': 1.4592973e-05}\nI0620 11:04:14.637762 132745443468416 model_lib_v2.py:705] Step 28600 per-step time 0.442s\nI0620 11:04:14.638141 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.651129,\n 'Loss/localization_loss': 1.1138983,\n 'Loss/regularization_loss': 0.14714123,\n 'Loss/total_loss': 1.9121686,\n 'learning_rate': 1.4557611e-05}\nI0620 11:04:58.804808 132745443468416 model_lib_v2.py:705] Step 28700 per-step time 0.442s\nI0620 11:04:58.805283 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6906894,\n 'Loss/localization_loss': 1.1747608,\n 'Loss/regularization_loss': 0.14713119,\n 'Loss/total_loss': 2.0125813,\n 'learning_rate': 1.4522179e-05}\nI0620 11:05:42.874184 132745443468416 model_lib_v2.py:705] Step 28800 per-step time 0.441s\nI0620 11:05:42.874578 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.8103394,\n 'Loss/localization_loss': 1.1830068,\n 'Loss/regularization_loss': 0.14712106,\n 'Loss/total_loss': 2.1404672,\n 'learning_rate': 1.4486674e-05}\nI0620 11:06:27.099683 132745443468416 model_lib_v2.py:705] Step 28900 per-step time 0.442s\nI0620 11:06:27.100060 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7011488,\n 'Loss/localization_loss': 1.1097188,\n 'Loss/regularization_loss': 0.14711119,\n 'Loss/total_loss': 1.9579788,\n 'learning_rate': 1.44511005e-05}\nI0620 11:07:11.165730 132745443468416 model_lib_v2.py:705] Step 29000 per-step time 0.441s\nI0620 11:07:11.166101 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7298473,\n 'Loss/localization_loss': 1.1538249,\n 'Loss/regularization_loss': 0.14710121,\n 'Loss/total_loss': 2.0307734,\n 'learning_rate': 1.4415455e-05}\nI0620 11:07:56.016937 132745443468416 model_lib_v2.py:705] Step 29100 per-step time 0.449s\nI0620 11:07:56.017369 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7127545,\n 'Loss/localization_loss': 1.1548686,\n 'Loss/regularization_loss': 0.14709127,\n 'Loss/total_loss': 2.0147145,\n 'learning_rate': 1.437974e-05}\nI0620 11:08:40.176872 132745443468416 model_lib_v2.py:705] Step 29200 per-step time 0.442s\nI0620 11:08:40.177258 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.74383724,\n 'Loss/localization_loss': 1.0206313,\n 'Loss/regularization_loss': 0.14708151,\n 'Loss/total_loss': 1.91155,\n 'learning_rate': 1.4343955e-05}\nI0620 11:09:24.318544 132745443468416 model_lib_v2.py:705] Step 29300 per-step time 0.441s\nI0620 11:09:24.318897 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.68544894,\n 'Loss/localization_loss': 1.1489618,\n 'Loss/regularization_loss': 0.1470715,\n 'Loss/total_loss': 1.9814823,\n 'learning_rate': 1.43081015e-05}\nI0620 11:10:08.565182 132745443468416 model_lib_v2.py:705] Step 29400 per-step time 0.442s\nI0620 11:10:08.565598 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7278579,\n 'Loss/localization_loss': 1.067403,\n 'Loss/regularization_loss': 0.14706172,\n 'Loss/total_loss': 1.9423225,\n 'learning_rate': 1.4272179e-05}\nI0620 11:10:52.788807 132745443468416 model_lib_v2.py:705] Step 29500 per-step time 0.442s\nI0620 11:10:52.789262 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69294095,\n 'Loss/localization_loss': 1.1353753,\n 'Loss/regularization_loss': 0.14705217,\n 'Loss/total_loss': 1.9753683,\n 'learning_rate': 1.423619e-05}\nI0620 11:11:36.946388 132745443468416 model_lib_v2.py:705] Step 29600 per-step time 0.442s\nI0620 11:11:36.946773 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.635921,\n 'Loss/localization_loss': 1.0066187,\n 'Loss/regularization_loss': 0.14704227,\n 'Loss/total_loss': 1.7895821,\n 'learning_rate': 1.4200135e-05}\nI0620 11:12:21.100144 132745443468416 model_lib_v2.py:705] Step 29700 per-step time 0.442s\nI0620 11:12:21.100560 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6749549,\n 'Loss/localization_loss': 1.1043935,\n 'Loss/regularization_loss': 0.14703253,\n 'Loss/total_loss': 1.9263809,\n 'learning_rate': 1.4164012e-05}\nI0620 11:13:05.225586 132745443468416 model_lib_v2.py:705] Step 29800 per-step time 0.441s\nI0620 11:13:05.225968 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66817826,\n 'Loss/localization_loss': 1.1460586,\n 'Loss/regularization_loss': 0.14702304,\n 'Loss/total_loss': 1.9612598,\n 'learning_rate': 1.4127825e-05}\nI0620 11:13:49.416666 132745443468416 model_lib_v2.py:705] Step 29900 per-step time 0.442s\nI0620 11:13:49.417048 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6661379,\n 'Loss/localization_loss': 0.9410071,\n 'Loss/regularization_loss': 0.14701337,\n 'Loss/total_loss': 1.7541583,\n 'learning_rate': 1.409157e-05}\nI0620 11:14:33.578399 132745443468416 model_lib_v2.py:705] Step 30000 per-step time 0.442s\nI0620 11:14:33.578792 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.704882,\n 'Loss/localization_loss': 0.98778033,\n 'Loss/regularization_loss': 0.14700398,\n 'Loss/total_loss': 1.8396665,\n 'learning_rate': 1.4055254e-05}\nI0620 11:15:18.440165 132745443468416 model_lib_v2.py:705] Step 30100 per-step time 0.449s\nI0620 11:15:18.440648 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.71042395,\n 'Loss/localization_loss': 1.072515,\n 'Loss/regularization_loss': 0.14699437,\n 'Loss/total_loss': 1.9299333,\n 'learning_rate': 1.401887e-05}\nI0620 11:16:02.549277 132745443468416 model_lib_v2.py:705] Step 30200 per-step time 0.441s\nI0620 11:16:02.549702 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6978817,\n 'Loss/localization_loss': 1.1123781,\n 'Loss/regularization_loss': 0.14698498,\n 'Loss/total_loss': 1.9572449,\n 'learning_rate': 1.3982424e-05}\nI0620 11:16:46.753278 132745443468416 model_lib_v2.py:705] Step 30300 per-step time 0.442s\nI0620 11:16:46.753666 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7667736,\n 'Loss/localization_loss': 1.0894504,\n 'Loss/regularization_loss': 0.14697538,\n 'Loss/total_loss': 2.0031993,\n 'learning_rate': 1.3945916e-05}\nI0620 11:17:30.987033 132745443468416 model_lib_v2.py:705] Step 30400 per-step time 0.442s\nI0620 11:17:30.987408 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7760582,\n 'Loss/localization_loss': 1.2756569,\n 'Loss/regularization_loss': 0.14696607,\n 'Loss/total_loss': 2.198681,\n 'learning_rate': 1.39093445e-05}\nI0620 11:18:15.071569 132745443468416 model_lib_v2.py:705] Step 30500 per-step time 0.441s\nI0620 11:18:15.071958 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6812999,\n 'Loss/localization_loss': 1.011278,\n 'Loss/regularization_loss': 0.1469566,\n 'Loss/total_loss': 1.8395345,\n 'learning_rate': 1.3872711e-05}\nI0620 11:18:59.343471 132745443468416 model_lib_v2.py:705] Step 30600 per-step time 0.443s\nI0620 11:18:59.343816 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6859522,\n 'Loss/localization_loss': 1.042005,\n 'Loss/regularization_loss': 0.14694732,\n 'Loss/total_loss': 1.8749044,\n 'learning_rate': 1.38360165e-05}\nI0620 11:19:43.430988 132745443468416 model_lib_v2.py:705] Step 30700 per-step time 0.441s\nI0620 11:19:43.431388 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.77414787,\n 'Loss/localization_loss': 1.0632987,\n 'Loss/regularization_loss': 0.14693819,\n 'Loss/total_loss': 1.9843847,\n 'learning_rate': 1.3799262e-05}\nI0620 11:20:27.793548 132745443468416 model_lib_v2.py:705] Step 30800 per-step time 0.444s\nI0620 11:20:27.793931 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.67462313,\n 'Loss/localization_loss': 1.046439,\n 'Loss/regularization_loss': 0.1469289,\n 'Loss/total_loss': 1.8679912,\n 'learning_rate': 1.3762447e-05}\nI0620 11:21:11.798911 132745443468416 model_lib_v2.py:705] Step 30900 per-step time 0.440s\nI0620 11:21:11.799295 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7390495,\n 'Loss/localization_loss': 1.1009344,\n 'Loss/regularization_loss': 0.14691953,\n 'Loss/total_loss': 1.9869034,\n 'learning_rate': 1.3725571e-05}\nI0620 11:21:56.023669 132745443468416 model_lib_v2.py:705] Step 31000 per-step time 0.442s\nI0620 11:21:56.024021 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69454694,\n 'Loss/localization_loss': 1.0880967,\n 'Loss/regularization_loss': 0.14691034,\n 'Loss/total_loss': 1.929554,\n 'learning_rate': 1.3688639e-05}\nI0620 11:22:40.723541 132745443468416 model_lib_v2.py:705] Step 31100 per-step time 0.447s\nI0620 11:22:40.723928 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.73039114,\n 'Loss/localization_loss': 1.2071686,\n 'Loss/regularization_loss': 0.14690122,\n 'Loss/total_loss': 2.084461,\n 'learning_rate': 1.3651646e-05}\nI0620 11:23:24.964993 132745443468416 model_lib_v2.py:705] Step 31200 per-step time 0.442s\nI0620 11:23:24.965347 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.63543284,\n 'Loss/localization_loss': 1.1095018,\n 'Loss/regularization_loss': 0.14689219,\n 'Loss/total_loss': 1.8918269,\n 'learning_rate': 1.3614597e-05}\nI0620 11:24:09.090665 132745443468416 model_lib_v2.py:705] Step 31300 per-step time 0.441s\nI0620 11:24:09.091027 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7695875,\n 'Loss/localization_loss': 1.1521933,\n 'Loss/regularization_loss': 0.14688338,\n 'Loss/total_loss': 2.068664,\n 'learning_rate': 1.3577491e-05}\nI0620 11:24:53.325165 132745443468416 model_lib_v2.py:705] Step 31400 per-step time 0.442s\nI0620 11:24:53.325536 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.77594197,\n 'Loss/localization_loss': 1.1851472,\n 'Loss/regularization_loss': 0.14687441,\n 'Loss/total_loss': 2.1079636,\n 'learning_rate': 1.3540327e-05}\nI0620 11:25:37.389651 132745443468416 model_lib_v2.py:705] Step 31500 per-step time 0.441s\nI0620 11:25:37.390017 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7235981,\n 'Loss/localization_loss': 1.1593437,\n 'Loss/regularization_loss': 0.14686558,\n 'Loss/total_loss': 2.0298076,\n 'learning_rate': 1.3503108e-05}\nI0620 11:26:21.794778 132745443468416 model_lib_v2.py:705] Step 31600 per-step time 0.444s\nI0620 11:26:21.795138 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7340878,\n 'Loss/localization_loss': 1.1048875,\n 'Loss/regularization_loss': 0.1468567,\n 'Loss/total_loss': 1.9858322,\n 'learning_rate': 1.3465833e-05}\nI0620 11:27:06.043561 132745443468416 model_lib_v2.py:705] Step 31700 per-step time 0.442s\nI0620 11:27:06.043931 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.58434796,\n 'Loss/localization_loss': 0.9720332,\n 'Loss/regularization_loss': 0.14684793,\n 'Loss/total_loss': 1.7032292,\n 'learning_rate': 1.3428504e-05}\nI0620 11:27:50.227763 132745443468416 model_lib_v2.py:705] Step 31800 per-step time 0.442s\nI0620 11:27:50.228137 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69779617,\n 'Loss/localization_loss': 1.0027412,\n 'Loss/regularization_loss': 0.1468391,\n 'Loss/total_loss': 1.8473765,\n 'learning_rate': 1.339112e-05}\nI0620 11:28:34.378058 132745443468416 model_lib_v2.py:705] Step 31900 per-step time 0.442s\nI0620 11:28:34.378492 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7397534,\n 'Loss/localization_loss': 1.1207128,\n 'Loss/regularization_loss': 0.14683041,\n 'Loss/total_loss': 2.0072966,\n 'learning_rate': 1.3353681e-05}\nI0620 11:29:18.620167 132745443468416 model_lib_v2.py:705] Step 32000 per-step time 0.442s\nI0620 11:29:18.620556 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6768452,\n 'Loss/localization_loss': 1.019033,\n 'Loss/regularization_loss': 0.1468214,\n 'Loss/total_loss': 1.8426995,\n 'learning_rate': 1.3316192e-05}\nI0620 11:30:03.428993 132745443468416 model_lib_v2.py:705] Step 32100 per-step time 0.448s\nI0620 11:30:03.429433 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7019901,\n 'Loss/localization_loss': 1.0563352,\n 'Loss/regularization_loss': 0.14681266,\n 'Loss/total_loss': 1.905138,\n 'learning_rate': 1.327865e-05}\nI0620 11:30:47.396725 132745443468416 model_lib_v2.py:705] Step 32200 per-step time 0.440s\nI0620 11:30:47.397101 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6863817,\n 'Loss/localization_loss': 1.0593439,\n 'Loss/regularization_loss': 0.14680406,\n 'Loss/total_loss': 1.8925297,\n 'learning_rate': 1.3241055e-05}\nI0620 11:31:31.685460 132745443468416 model_lib_v2.py:705] Step 32300 per-step time 0.443s\nI0620 11:31:31.685867 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.61957794,\n 'Loss/localization_loss': 1.0058286,\n 'Loss/regularization_loss': 0.14679559,\n 'Loss/total_loss': 1.7722021,\n 'learning_rate': 1.3203408e-05}\nI0620 11:32:15.655304 132745443468416 model_lib_v2.py:705] Step 32400 per-step time 0.440s\nI0620 11:32:15.655679 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66076446,\n 'Loss/localization_loss': 1.0552557,\n 'Loss/regularization_loss': 0.146787,\n 'Loss/total_loss': 1.8628072,\n 'learning_rate': 1.3165712e-05}\nI0620 11:32:59.772346 132745443468416 model_lib_v2.py:705] Step 32500 per-step time 0.441s\nI0620 11:32:59.772699 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7199124,\n 'Loss/localization_loss': 1.1103611,\n 'Loss/regularization_loss': 0.14677861,\n 'Loss/total_loss': 1.977052,\n 'learning_rate': 1.3127966e-05}\nI0620 11:33:43.893976 132745443468416 model_lib_v2.py:705] Step 32600 per-step time 0.441s\nI0620 11:33:43.894360 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7785778,\n 'Loss/localization_loss': 1.1339552,\n 'Loss/regularization_loss': 0.1467702,\n 'Loss/total_loss': 2.0593033,\n 'learning_rate': 1.3090169e-05}\nI0620 11:34:27.979954 132745443468416 model_lib_v2.py:705] Step 32700 per-step time 0.441s\nI0620 11:34:27.980340 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6978464,\n 'Loss/localization_loss': 0.9468579,\n 'Loss/regularization_loss': 0.14676175,\n 'Loss/total_loss': 1.7914662,\n 'learning_rate': 1.3052325e-05}\nI0620 11:35:12.057059 132745443468416 model_lib_v2.py:705] Step 32800 per-step time 0.441s\nI0620 11:35:12.057500 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6996145,\n 'Loss/localization_loss': 0.99893427,\n 'Loss/regularization_loss': 0.14675319,\n 'Loss/total_loss': 1.845302,\n 'learning_rate': 1.3014431e-05}\nI0620 11:35:56.137499 132745443468416 model_lib_v2.py:705] Step 32900 per-step time 0.441s\nI0620 11:35:56.137840 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.732051,\n 'Loss/localization_loss': 1.085108,\n 'Loss/regularization_loss': 0.14674494,\n 'Loss/total_loss': 1.9639041,\n 'learning_rate': 1.297649e-05}\nI0620 11:36:40.250923 132745443468416 model_lib_v2.py:705] Step 33000 per-step time 0.441s\nI0620 11:36:40.251346 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6929153,\n 'Loss/localization_loss': 1.0622611,\n 'Loss/regularization_loss': 0.14673658,\n 'Loss/total_loss': 1.9019129,\n 'learning_rate': 1.2938502e-05}\nI0620 11:37:25.118584 132745443468416 model_lib_v2.py:705] Step 33100 per-step time 0.449s\nI0620 11:37:25.118950 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.73697555,\n 'Loss/localization_loss': 1.0939225,\n 'Loss/regularization_loss': 0.14672822,\n 'Loss/total_loss': 1.9776262,\n 'learning_rate': 1.29004675e-05}\nI0620 11:38:09.305182 132745443468416 model_lib_v2.py:705] Step 33200 per-step time 0.442s\nI0620 11:38:09.305611 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.575748,\n 'Loss/localization_loss': 0.9433846,\n 'Loss/regularization_loss': 0.14671966,\n 'Loss/total_loss': 1.6658523,\n 'learning_rate': 1.2862388e-05}\nI0620 11:38:53.549996 132745443468416 model_lib_v2.py:705] Step 33300 per-step time 0.442s\nI0620 11:38:53.550433 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.75345385,\n 'Loss/localization_loss': 1.1132989,\n 'Loss/regularization_loss': 0.14671142,\n 'Loss/total_loss': 2.0134642,\n 'learning_rate': 1.2824261e-05}\nI0620 11:39:38.001920 132745443468416 model_lib_v2.py:705] Step 33400 per-step time 0.444s\nI0620 11:39:38.002324 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6830054,\n 'Loss/localization_loss': 0.9841888,\n 'Loss/regularization_loss': 0.14670332,\n 'Loss/total_loss': 1.8138976,\n 'learning_rate': 1.2786092e-05}\nI0620 11:40:22.200419 132745443468416 model_lib_v2.py:705] Step 33500 per-step time 0.442s\nI0620 11:40:22.200760 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.707054,\n 'Loss/localization_loss': 1.129272,\n 'Loss/regularization_loss': 0.146695,\n 'Loss/total_loss': 1.983021,\n 'learning_rate': 1.2747876e-05}\nI0620 11:41:06.333473 132745443468416 model_lib_v2.py:705] Step 33600 per-step time 0.441s\nI0620 11:41:06.333890 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.68747073,\n 'Loss/localization_loss': 1.0003716,\n 'Loss/regularization_loss': 0.14668699,\n 'Loss/total_loss': 1.8345294,\n 'learning_rate': 1.270962e-05}\nI0620 11:41:50.323085 132745443468416 model_lib_v2.py:705] Step 33700 per-step time 0.440s\nI0620 11:41:50.323510 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.70577145,\n 'Loss/localization_loss': 1.0983663,\n 'Loss/regularization_loss': 0.14667888,\n 'Loss/total_loss': 1.9508166,\n 'learning_rate': 1.2671318e-05}\nI0620 11:42:34.644378 132745443468416 model_lib_v2.py:705] Step 33800 per-step time 0.443s\nI0620 11:42:34.644754 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7116908,\n 'Loss/localization_loss': 1.0651066,\n 'Loss/regularization_loss': 0.14667077,\n 'Loss/total_loss': 1.9234682,\n 'learning_rate': 1.2632975e-05}\nI0620 11:43:18.735107 132745443468416 model_lib_v2.py:705] Step 33900 per-step time 0.441s\nI0620 11:43:18.735502 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.775164,\n 'Loss/localization_loss': 1.1424665,\n 'Loss/regularization_loss': 0.14666279,\n 'Loss/total_loss': 2.0642934,\n 'learning_rate': 1.2594593e-05}\nI0620 11:44:02.721467 132745443468416 model_lib_v2.py:705] Step 34000 per-step time 0.440s\nI0620 11:44:02.721873 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69281566,\n 'Loss/localization_loss': 0.8894112,\n 'Loss/regularization_loss': 0.14665475,\n 'Loss/total_loss': 1.7288816,\n 'learning_rate': 1.25561655e-05}\nI0620 11:44:47.672040 132745443468416 model_lib_v2.py:705] Step 34100 per-step time 0.450s\nI0620 11:44:47.672445 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.62668145,\n 'Loss/localization_loss': 0.94315654,\n 'Loss/regularization_loss': 0.14664696,\n 'Loss/total_loss': 1.7164849,\n 'learning_rate': 1.25177e-05}\nI0620 11:45:31.789839 132745443468416 model_lib_v2.py:705] Step 34200 per-step time 0.441s\nI0620 11:45:31.790256 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7637654,\n 'Loss/localization_loss': 1.1080003,\n 'Loss/regularization_loss': 0.14663908,\n 'Loss/total_loss': 2.018405,\n 'learning_rate': 1.2479193e-05}\nI0620 11:46:16.037268 132745443468416 model_lib_v2.py:705] Step 34300 per-step time 0.442s\nI0620 11:46:16.037658 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6905495,\n 'Loss/localization_loss': 0.9600456,\n 'Loss/regularization_loss': 0.14663121,\n 'Loss/total_loss': 1.7972264,\n 'learning_rate': 1.2440648e-05}\nI0620 11:47:00.328931 132745443468416 model_lib_v2.py:705] Step 34400 per-step time 0.443s\nI0620 11:47:00.329381 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.65707654,\n 'Loss/localization_loss': 0.9690251,\n 'Loss/regularization_loss': 0.14662333,\n 'Loss/total_loss': 1.772725,\n 'learning_rate': 1.2402065e-05}\nI0620 11:47:44.628577 132745443468416 model_lib_v2.py:705] Step 34500 per-step time 0.443s\nI0620 11:47:44.628970 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.5929303,\n 'Loss/localization_loss': 0.90114087,\n 'Loss/regularization_loss': 0.14661536,\n 'Loss/total_loss': 1.6406866,\n 'learning_rate': 1.2363443e-05}\nI0620 11:48:28.561002 132745443468416 model_lib_v2.py:705] Step 34600 per-step time 0.439s\nI0620 11:48:28.561398 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6321428,\n 'Loss/localization_loss': 0.98796564,\n 'Loss/regularization_loss': 0.14660741,\n 'Loss/total_loss': 1.7667159,\n 'learning_rate': 1.23247855e-05}\nI0620 11:49:12.583963 132745443468416 model_lib_v2.py:705] Step 34700 per-step time 0.440s\nI0620 11:49:12.584385 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66767466,\n 'Loss/localization_loss': 1.0271752,\n 'Loss/regularization_loss': 0.14659981,\n 'Loss/total_loss': 1.8414495,\n 'learning_rate': 1.2286089e-05}\nI0620 11:49:56.658510 132745443468416 model_lib_v2.py:705] Step 34800 per-step time 0.441s\nI0620 11:49:56.658920 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.642846,\n 'Loss/localization_loss': 0.9613235,\n 'Loss/regularization_loss': 0.1465921,\n 'Loss/total_loss': 1.7507615,\n 'learning_rate': 1.2247357e-05}\nI0620 11:50:40.838971 132745443468416 model_lib_v2.py:705] Step 34900 per-step time 0.442s\nI0620 11:50:40.839367 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7090332,\n 'Loss/localization_loss': 1.0325356,\n 'Loss/regularization_loss': 0.14658432,\n 'Loss/total_loss': 1.8881531,\n 'learning_rate': 1.220859e-05}\nI0620 11:51:25.054870 132745443468416 model_lib_v2.py:705] Step 35000 per-step time 0.442s\nI0620 11:51:25.055248 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.71135485,\n 'Loss/localization_loss': 0.95991987,\n 'Loss/regularization_loss': 0.1465768,\n 'Loss/total_loss': 1.8178515,\n 'learning_rate': 1.2169787e-05}\nI0620 11:52:09.720278 132745443468416 model_lib_v2.py:705] Step 35100 per-step time 0.447s\nI0620 11:52:09.720678 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6067176,\n 'Loss/localization_loss': 0.95066476,\n 'Loss/regularization_loss': 0.14656931,\n 'Loss/total_loss': 1.7039516,\n 'learning_rate': 1.2130951e-05}\nI0620 11:52:53.951181 132745443468416 model_lib_v2.py:705] Step 35200 per-step time 0.442s\nI0620 11:52:53.951669 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.69676316,\n 'Loss/localization_loss': 0.9509478,\n 'Loss/regularization_loss': 0.14656168,\n 'Loss/total_loss': 1.7942727,\n 'learning_rate': 1.2092081e-05}\nI0620 11:53:37.940772 132745443468416 model_lib_v2.py:705] Step 35300 per-step time 0.440s\nI0620 11:53:37.941094 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6769446,\n 'Loss/localization_loss': 0.90915406,\n 'Loss/regularization_loss': 0.1465543,\n 'Loss/total_loss': 1.732653,\n 'learning_rate': 1.2053176e-05}\nI0620 11:54:22.055310 132745443468416 model_lib_v2.py:705] Step 35400 per-step time 0.441s\nI0620 11:54:22.055729 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6283939,\n 'Loss/localization_loss': 1.0287557,\n 'Loss/regularization_loss': 0.14654666,\n 'Loss/total_loss': 1.8036962,\n 'learning_rate': 1.2014241e-05}\nI0620 11:55:06.198987 132745443468416 model_lib_v2.py:705] Step 35500 per-step time 0.441s\nI0620 11:55:06.199370 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6523018,\n 'Loss/localization_loss': 0.8788619,\n 'Loss/regularization_loss': 0.14653926,\n 'Loss/total_loss': 1.6777029,\n 'learning_rate': 1.1975272e-05}\nI0620 11:55:50.324626 132745443468416 model_lib_v2.py:705] Step 35600 per-step time 0.441s\nI0620 11:55:50.325024 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6531919,\n 'Loss/localization_loss': 0.9816926,\n 'Loss/regularization_loss': 0.1465318,\n 'Loss/total_loss': 1.7814164,\n 'learning_rate': 1.1936275e-05}\nI0620 11:56:34.641661 132745443468416 model_lib_v2.py:705] Step 35700 per-step time 0.443s\nI0620 11:56:34.642105 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.5921644,\n 'Loss/localization_loss': 0.91665494,\n 'Loss/regularization_loss': 0.1465243,\n 'Loss/total_loss': 1.6553438,\n 'learning_rate': 1.1897246e-05}\nI0620 11:57:18.804247 132745443468416 model_lib_v2.py:705] Step 35800 per-step time 0.442s\nI0620 11:57:18.804644 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.72228706,\n 'Loss/localization_loss': 1.1059673,\n 'Loss/regularization_loss': 0.14651684,\n 'Loss/total_loss': 1.9747711,\n 'learning_rate': 1.1858186e-05}\nI0620 11:58:02.937175 132745443468416 model_lib_v2.py:705] Step 35900 per-step time 0.441s\nI0620 11:58:02.937556 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6451323,\n 'Loss/localization_loss': 1.0270658,\n 'Loss/regularization_loss': 0.14650936,\n 'Loss/total_loss': 1.8187075,\n 'learning_rate': 1.18190965e-05}\nI0620 11:58:47.079697 132745443468416 model_lib_v2.py:705] Step 36000 per-step time 0.441s\nI0620 11:58:47.080062 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.72301036,\n 'Loss/localization_loss': 1.144998,\n 'Loss/regularization_loss': 0.14650203,\n 'Loss/total_loss': 2.0145104,\n 'learning_rate': 1.1779978e-05}\nI0620 11:59:31.807683 132745443468416 model_lib_v2.py:705] Step 36100 per-step time 0.447s\nI0620 11:59:31.808104 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.7279979,\n 'Loss/localization_loss': 0.9661578,\n 'Loss/regularization_loss': 0.14649479,\n 'Loss/total_loss': 1.8406503,\n 'learning_rate': 1.1740832e-05}\nI0620 12:00:15.845499 132745443468416 model_lib_v2.py:705] Step 36200 per-step time 0.440s\nI0620 12:00:15.845862 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.673867,\n 'Loss/localization_loss': 0.99695694,\n 'Loss/regularization_loss': 0.14648761,\n 'Loss/total_loss': 1.8173115,\n 'learning_rate': 1.1701659e-05}\nI0620 12:01:00.159396 132745443468416 model_lib_v2.py:705] Step 36300 per-step time 0.443s\nI0620 12:01:00.159867 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.66819686,\n 'Loss/localization_loss': 1.0448952,\n 'Loss/regularization_loss': 0.1464805,\n 'Loss/total_loss': 1.8595725,\n 'learning_rate': 1.1662459e-05}\nI0620 12:01:44.229269 132745443468416 model_lib_v2.py:705] Step 36400 per-step time 0.441s\nI0620 12:01:44.229690 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6260896,\n 'Loss/localization_loss': 1.0514123,\n 'Loss/regularization_loss': 0.14647332,\n 'Loss/total_loss': 1.8239752,\n 'learning_rate': 1.1623232e-05}\nI0620 12:02:28.284256 132745443468416 model_lib_v2.py:705] Step 36500 per-step time 0.441s\nI0620 12:02:28.284622 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.640903,\n 'Loss/localization_loss': 0.98469603,\n 'Loss/regularization_loss': 0.14646599,\n 'Loss/total_loss': 1.772065,\n 'learning_rate': 1.158398e-05}\nI0620 12:03:12.261904 132745443468416 model_lib_v2.py:705] Step 36600 per-step time 0.440s\nI0620 12:03:12.262302 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6054424,\n 'Loss/localization_loss': 0.90466017,\n 'Loss/regularization_loss': 0.14645872,\n 'Loss/total_loss': 1.6565614,\n 'learning_rate': 1.1544702e-05}\nI0620 12:03:56.562271 132745443468416 model_lib_v2.py:705] Step 36700 per-step time 0.443s\nI0620 12:03:56.562700 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.72432387,\n 'Loss/localization_loss': 0.94465697,\n 'Loss/regularization_loss': 0.14645183,\n 'Loss/total_loss': 1.8154327,\n 'learning_rate': 1.1505401e-05}\nI0620 12:04:40.676563 132745443468416 model_lib_v2.py:705] Step 36800 per-step time 0.441s\nI0620 12:04:40.676918 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.70797724,\n 'Loss/localization_loss': 1.0895388,\n 'Loss/regularization_loss': 0.14644486,\n 'Loss/total_loss': 1.9439609,\n 'learning_rate': 1.1466075e-05}\nI0620 12:05:24.756758 132745443468416 model_lib_v2.py:705] Step 36900 per-step time 0.441s\nI0620 12:05:24.757171 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.67782366,\n 'Loss/localization_loss': 1.0258553,\n 'Loss/regularization_loss': 0.1464379,\n 'Loss/total_loss': 1.8501167,\n 'learning_rate': 1.1426726e-05}\nI0620 12:06:08.751275 132745443468416 model_lib_v2.py:705] Step 37000 per-step time 0.440s\nI0620 12:06:08.751625 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6253948,\n 'Loss/localization_loss': 1.010149,\n 'Loss/regularization_loss': 0.14643082,\n 'Loss/total_loss': 1.7819746,\n 'learning_rate': 1.1387355e-05}\nI0620 12:06:53.463180 132745443468416 model_lib_v2.py:705] Step 37100 per-step time 0.447s\nI0620 12:06:53.463627 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6299876,\n 'Loss/localization_loss': 0.8834423,\n 'Loss/regularization_loss': 0.1464239,\n 'Loss/total_loss': 1.6598538,\n 'learning_rate': 1.1347961e-05}\nI0620 12:07:37.440242 132745443468416 model_lib_v2.py:705] Step 37200 per-step time 0.440s\nI0620 12:07:37.440640 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.68443537,\n 'Loss/localization_loss': 1.008928,\n 'Loss/regularization_loss': 0.14641722,\n 'Loss/total_loss': 1.8397806,\n 'learning_rate': 1.1308547e-05}\nI0620 12:08:21.440763 132745443468416 model_lib_v2.py:705] Step 37300 per-step time 0.440s\nI0620 12:08:21.441172 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6676614,\n 'Loss/localization_loss': 0.94588363,\n 'Loss/regularization_loss': 0.14641036,\n 'Loss/total_loss': 1.7599554,\n 'learning_rate': 1.1269111e-05}\nI0620 12:09:05.749567 132745443468416 model_lib_v2.py:705] Step 37400 per-step time 0.443s\nI0620 12:09:05.749953 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.6321498,\n 'Loss/localization_loss': 1.006277,\n 'Loss/regularization_loss': 0.14640349,\n 'Loss/total_loss': 1.7848302,\n 'learning_rate': 1.1229656e-05}\nI0620 12:09:49.632234 132745443468416 model_lib_v2.py:705] Step 37500 per-step time 0.439s\nI0620 12:09:49.632666 132745443468416 model_lib_v2.py:708] {'Loss/classification_loss': 0.72783214,\n 'Loss/localization_loss': 0.97443736,\n 'Loss/regularization_loss': 0.14639674,\n 'Loss/total_loss': 1.8486662,\n 'learning_rate': 1.1190181e-05}\n\n🔵 Evaluasi setelah iterasi ke-3\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nW0620 12:09:58.547625 133098547676288 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\nI0620 12:09:58.547891 133098547676288 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\nI0620 12:09:58.548026 133098547676288 config_util.py:552] Maybe overwriting use_bfloat16: False\nI0620 12:09:58.548129 133098547676288 config_util.py:552] Maybe overwriting eval_num_epochs: 1\nW0620 12:09:58.548289 133098547676288 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\nI0620 12:10:00.170086 133098547676288 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 12:10:00.170391 133098547676288 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 12:10:00.170523 133098547676288 dataset_builder.py:80] Number of filenames to read: 1\nW0620 12:10:00.170637 133098547676288 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 12:10:00.172694 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 12:10:00.199226 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 12:10:03.900653 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 12:10:04.786720 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 12:10:07.231576 133098547676288 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\nI0620 12:10:07.232568 133098547676288 checkpoint_utils.py:145] Found new checkpoint at /kaggle/working/training/ckpt-38\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 12:10:12.723697 133098547676288 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:10:25.855349 133098547676288 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 12:10:31.522429 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 12:10:31.532373 133098547676288 model_lib_v2.py:966] Finished eval step 0\nW0620 12:10:31.648048 133098547676288 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nI0620 12:10:35.194134 133098547676288 coco_evaluation.py:293] Performing evaluation on 39 images.\ncreating index...\nindex created!\nI0620 12:10:35.197318 133098547676288 coco_tools.py:116] Loading and preparing annotation results...\nI0620 12:10:35.200975 133098547676288 coco_tools.py:138] DONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.81s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.109\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.076\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.104\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\nI0620 12:10:36.074273 133098547676288 model_lib_v2.py:1015] Eval metrics at step 37000\nI0620 12:10:36.083073 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.030017\nI0620 12:10:36.084839 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.109173\nI0620 12:10:36.086643 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.007604\nI0620 12:10:36.088181 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\nI0620 12:10:36.089779 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.022218\nI0620 12:10:36.091107 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.046833\nI0620 12:10:36.092636 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.006881\nI0620 12:10:36.094163 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.075982\nI0620 12:10:36.095530 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.137322\nI0620 12:10:36.096970 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\nI0620 12:10:36.098394 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.103675\nI0620 12:10:36.099700 133098547676288 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.204189\nI0620 12:10:36.100679 133098547676288 model_lib_v2.py:1018] \t+ Loss/localization_loss: 1.090390\nI0620 12:10:36.101780 133098547676288 model_lib_v2.py:1018] \t+ Loss/classification_loss: 1.005914\nI0620 12:10:36.102962 133098547676288 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.146431\nI0620 12:10:36.104086 133098547676288 model_lib_v2.py:1018] \t+ Loss/total_loss: 2.242735\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n    tf.compat.v1.app.run()\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 81, in main\n    model_lib_v2.eval_continuously(\n  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n    for latest_checkpoint in tf.train.checkpoints_iterator(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 212, in checkpoints_iterator\n    time.sleep(time_to_next_eval)\nKeyboardInterrupt\n\n🟢 Training iterasi ke-4 (37500 -> 50000 steps)\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nI0620 12:12:13.502350 137593212425344 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nI0620 12:12:13.506402 137593212425344 config_util.py:552] Maybe overwriting train_steps: 50000\nI0620 12:12:13.506579 137593212425344 config_util.py:552] Maybe overwriting use_bfloat16: False\nW0620 12:12:13.680385 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\nInstructions for updating:\nrename to distribute_datasets_from_function\nI0620 12:12:13.684460 137593212425344 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 12:12:13.684700 137593212425344 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/train/1-QDa5-FSKD.tfrecord']\nI0620 12:12:13.684794 137593212425344 dataset_builder.py:80] Number of filenames to read: 1\nW0620 12:12:13.684882 137593212425344 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 12:12:13.687371 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 12:12:13.713004 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 12:12:20.220087 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 12:12:22.938093 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\nW0620 12:12:25.383160 137593212425344 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 12:12:34.398857 137585896703552 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:12:44.171169 137585905096256 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:12:49.809717 137585905096256 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:12:53.441395 137585896703552 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 12:13:06.681989 137586684184128 deprecation.py:541] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\nI0620 12:13:07.634194 137586684184128 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:13.005783 137586675791424 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:17.466267 137593212425344 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 12:13:19.516975 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:19.518766 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:19.520369 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:19.521978 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:22.594618 137586675791424 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:27.560126 137586684184128 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:31.721487 137593212425344 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 12:13:34.754918 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:34.757253 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:34.758987 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:34.760572 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:37.051085 137586684184128 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:42.183693 137586675791424 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:46.485959 137593212425344 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 12:13:49.041625 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:49.043471 137593212425344 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nI0620 12:13:51.972883 137586684184128 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:13:57.052772 137586675791424 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 12:14:01.243776 137593212425344 cross_device_ops.py:897] batch_all_reduce: 232 all-reduces with algorithm = nccl, num_packs = 1\nI0620 12:15:12.996804 137593212425344 model_lib_v2.py:705] Step 37100 per-step time 1.267s\nI0620 12:15:12.997274 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.65522563,\n 'Loss/localization_loss': 0.9052056,\n 'Loss/regularization_loss': 0.14642388,\n 'Loss/total_loss': 1.706855,\n 'learning_rate': 1.1347961e-05}\nI0620 12:15:57.056535 137593212425344 model_lib_v2.py:705] Step 37200 per-step time 0.441s\nI0620 12:15:57.056952 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.623844,\n 'Loss/localization_loss': 0.8736268,\n 'Loss/regularization_loss': 0.14641681,\n 'Loss/total_loss': 1.6438876,\n 'learning_rate': 1.1308547e-05}\nI0620 12:16:41.646119 137593212425344 model_lib_v2.py:705] Step 37300 per-step time 0.446s\nI0620 12:16:41.646579 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7424581,\n 'Loss/localization_loss': 1.0782912,\n 'Loss/regularization_loss': 0.14640985,\n 'Loss/total_loss': 1.967159,\n 'learning_rate': 1.1269111e-05}\nI0620 12:17:26.011938 137593212425344 model_lib_v2.py:705] Step 37400 per-step time 0.444s\nI0620 12:17:26.012383 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.64700556,\n 'Loss/localization_loss': 0.9746051,\n 'Loss/regularization_loss': 0.14640279,\n 'Loss/total_loss': 1.7680135,\n 'learning_rate': 1.1229656e-05}\nI0620 12:18:10.317334 137593212425344 model_lib_v2.py:705] Step 37500 per-step time 0.443s\nI0620 12:18:10.317772 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.641986,\n 'Loss/localization_loss': 0.90934193,\n 'Loss/regularization_loss': 0.14639594,\n 'Loss/total_loss': 1.6977239,\n 'learning_rate': 1.1190181e-05}\nI0620 12:18:54.595148 137593212425344 model_lib_v2.py:705] Step 37600 per-step time 0.443s\nI0620 12:18:54.595518 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6779057,\n 'Loss/localization_loss': 1.0121596,\n 'Loss/regularization_loss': 0.14638935,\n 'Loss/total_loss': 1.8364546,\n 'learning_rate': 1.1150688e-05}\nI0620 12:19:39.247557 137593212425344 model_lib_v2.py:705] Step 37700 per-step time 0.446s\nI0620 12:19:39.247922 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.67493385,\n 'Loss/localization_loss': 1.048835,\n 'Loss/regularization_loss': 0.14638254,\n 'Loss/total_loss': 1.8701515,\n 'learning_rate': 1.1111176e-05}\nI0620 12:20:23.407819 137593212425344 model_lib_v2.py:705] Step 37800 per-step time 0.442s\nI0620 12:20:23.408272 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7208889,\n 'Loss/localization_loss': 0.99147725,\n 'Loss/regularization_loss': 0.1463756,\n 'Loss/total_loss': 1.8587418,\n 'learning_rate': 1.1071647e-05}\nI0620 12:21:07.944331 137593212425344 model_lib_v2.py:705] Step 37900 per-step time 0.445s\nI0620 12:21:07.944715 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.74296415,\n 'Loss/localization_loss': 0.9249203,\n 'Loss/regularization_loss': 0.14636873,\n 'Loss/total_loss': 1.8142531,\n 'learning_rate': 1.10321e-05}\nI0620 12:21:52.209300 137593212425344 model_lib_v2.py:705] Step 38000 per-step time 0.443s\nI0620 12:21:52.209731 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66374475,\n 'Loss/localization_loss': 1.0492406,\n 'Loss/regularization_loss': 0.14636211,\n 'Loss/total_loss': 1.8593473,\n 'learning_rate': 1.0992539e-05}\nI0620 12:22:37.219994 137593212425344 model_lib_v2.py:705] Step 38100 per-step time 0.450s\nI0620 12:22:37.220450 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6893213,\n 'Loss/localization_loss': 0.9850626,\n 'Loss/regularization_loss': 0.14635555,\n 'Loss/total_loss': 1.8207394,\n 'learning_rate': 1.0952959e-05}\nI0620 12:23:21.580783 137593212425344 model_lib_v2.py:705] Step 38200 per-step time 0.444s\nI0620 12:23:21.581215 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63581145,\n 'Loss/localization_loss': 0.9374981,\n 'Loss/regularization_loss': 0.14634901,\n 'Loss/total_loss': 1.7196586,\n 'learning_rate': 1.0913364e-05}\nI0620 12:24:05.882535 137593212425344 model_lib_v2.py:705] Step 38300 per-step time 0.443s\nI0620 12:24:05.882933 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7139497,\n 'Loss/localization_loss': 1.2892051,\n 'Loss/regularization_loss': 0.14634275,\n 'Loss/total_loss': 2.1494975,\n 'learning_rate': 1.0873759e-05}\nI0620 12:24:50.198961 137593212425344 model_lib_v2.py:705] Step 38400 per-step time 0.443s\nI0620 12:24:50.199430 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.640466,\n 'Loss/localization_loss': 1.0198761,\n 'Loss/regularization_loss': 0.14633617,\n 'Loss/total_loss': 1.8066783,\n 'learning_rate': 1.08341355e-05}\nI0620 12:25:34.542109 137593212425344 model_lib_v2.py:705] Step 38500 per-step time 0.443s\nI0620 12:25:34.542639 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6484077,\n 'Loss/localization_loss': 0.96033216,\n 'Loss/regularization_loss': 0.14632966,\n 'Loss/total_loss': 1.7550695,\n 'learning_rate': 1.0794501e-05}\nI0620 12:26:18.934416 137593212425344 model_lib_v2.py:705] Step 38600 per-step time 0.444s\nI0620 12:26:18.934926 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7938522,\n 'Loss/localization_loss': 1.0328459,\n 'Loss/regularization_loss': 0.14632307,\n 'Loss/total_loss': 1.9730211,\n 'learning_rate': 1.0754853e-05}\nI0620 12:27:03.160978 137593212425344 model_lib_v2.py:705] Step 38700 per-step time 0.442s\nI0620 12:27:03.161434 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.72141117,\n 'Loss/localization_loss': 1.0349169,\n 'Loss/regularization_loss': 0.14631659,\n 'Loss/total_loss': 1.9026445,\n 'learning_rate': 1.0715194e-05}\nI0620 12:27:47.400927 137593212425344 model_lib_v2.py:705] Step 38800 per-step time 0.442s\nI0620 12:27:47.401327 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.654786,\n 'Loss/localization_loss': 1.0306611,\n 'Loss/regularization_loss': 0.14631005,\n 'Loss/total_loss': 1.8317571,\n 'learning_rate': 1.0675524e-05}\nI0620 12:28:31.615386 137593212425344 model_lib_v2.py:705] Step 38900 per-step time 0.442s\nI0620 12:28:31.615767 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7298305,\n 'Loss/localization_loss': 1.0496927,\n 'Loss/regularization_loss': 0.1463037,\n 'Loss/total_loss': 1.9258268,\n 'learning_rate': 1.0635842e-05}\nI0620 12:29:15.823723 137593212425344 model_lib_v2.py:705] Step 39000 per-step time 0.442s\nI0620 12:29:15.824113 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7142123,\n 'Loss/localization_loss': 1.0260867,\n 'Loss/regularization_loss': 0.14629725,\n 'Loss/total_loss': 1.8865962,\n 'learning_rate': 1.0596151e-05}\nI0620 12:30:01.497254 137593212425344 model_lib_v2.py:705] Step 39100 per-step time 0.457s\nI0620 12:30:01.497684 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.64439964,\n 'Loss/localization_loss': 0.97788787,\n 'Loss/regularization_loss': 0.14629103,\n 'Loss/total_loss': 1.7685785,\n 'learning_rate': 1.05564495e-05}\nI0620 12:30:45.645349 137593212425344 model_lib_v2.py:705] Step 39200 per-step time 0.441s\nI0620 12:30:45.645784 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.67204547,\n 'Loss/localization_loss': 1.0472169,\n 'Loss/regularization_loss': 0.14628467,\n 'Loss/total_loss': 1.8655471,\n 'learning_rate': 1.051674e-05}\nI0620 12:31:29.741777 137593212425344 model_lib_v2.py:705] Step 39300 per-step time 0.441s\nI0620 12:31:29.742327 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.72391105,\n 'Loss/localization_loss': 0.9250492,\n 'Loss/regularization_loss': 0.14627846,\n 'Loss/total_loss': 1.7952387,\n 'learning_rate': 1.0477022e-05}\nI0620 12:32:14.271465 137593212425344 model_lib_v2.py:705] Step 39400 per-step time 0.445s\nI0620 12:32:14.271860 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5941528,\n 'Loss/localization_loss': 0.8625977,\n 'Loss/regularization_loss': 0.14627224,\n 'Loss/total_loss': 1.6030227,\n 'learning_rate': 1.0437297e-05}\nI0620 12:32:58.685441 137593212425344 model_lib_v2.py:705] Step 39500 per-step time 0.444s\nI0620 12:32:58.685812 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.69833636,\n 'Loss/localization_loss': 0.9672415,\n 'Loss/regularization_loss': 0.14626586,\n 'Loss/total_loss': 1.8118438,\n 'learning_rate': 1.0397565e-05}\nI0620 12:33:43.151947 137593212425344 model_lib_v2.py:705] Step 39600 per-step time 0.445s\nI0620 12:33:43.152332 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.62711936,\n 'Loss/localization_loss': 0.9708655,\n 'Loss/regularization_loss': 0.14625965,\n 'Loss/total_loss': 1.7442446,\n 'learning_rate': 1.0357827e-05}\nI0620 12:34:27.342734 137593212425344 model_lib_v2.py:705] Step 39700 per-step time 0.442s\nI0620 12:34:27.343166 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6788498,\n 'Loss/localization_loss': 0.9249258,\n 'Loss/regularization_loss': 0.1462535,\n 'Loss/total_loss': 1.7500292,\n 'learning_rate': 1.0318082e-05}\nI0620 12:35:11.647570 137593212425344 model_lib_v2.py:705] Step 39800 per-step time 0.443s\nI0620 12:35:11.647971 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.65122426,\n 'Loss/localization_loss': 0.94283295,\n 'Loss/regularization_loss': 0.14624748,\n 'Loss/total_loss': 1.7403047,\n 'learning_rate': 1.0278332e-05}\nI0620 12:35:55.930634 137593212425344 model_lib_v2.py:705] Step 39900 per-step time 0.443s\nI0620 12:35:55.931035 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6641635,\n 'Loss/localization_loss': 0.94467485,\n 'Loss/regularization_loss': 0.14624138,\n 'Loss/total_loss': 1.7550797,\n 'learning_rate': 1.0238578e-05}\nI0620 12:36:40.415085 137593212425344 model_lib_v2.py:705] Step 40000 per-step time 0.445s\nI0620 12:36:40.415536 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7424297,\n 'Loss/localization_loss': 0.8188567,\n 'Loss/regularization_loss': 0.1462354,\n 'Loss/total_loss': 1.7075218,\n 'learning_rate': 1.0198822e-05}\nI0620 12:37:24.987522 137593212425344 model_lib_v2.py:705] Step 40100 per-step time 0.446s\nI0620 12:37:24.987944 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6371918,\n 'Loss/localization_loss': 0.9029244,\n 'Loss/regularization_loss': 0.14622927,\n 'Loss/total_loss': 1.6863455,\n 'learning_rate': 1.015906e-05}\nI0620 12:38:09.180126 137593212425344 model_lib_v2.py:705] Step 40200 per-step time 0.442s\nI0620 12:38:09.180559 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6254057,\n 'Loss/localization_loss': 1.0383043,\n 'Loss/regularization_loss': 0.14622317,\n 'Loss/total_loss': 1.8099332,\n 'learning_rate': 1.0119297e-05}\nI0620 12:38:53.379443 137593212425344 model_lib_v2.py:705] Step 40300 per-step time 0.442s\nI0620 12:38:53.379951 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7127867,\n 'Loss/localization_loss': 1.0412745,\n 'Loss/regularization_loss': 0.14621729,\n 'Loss/total_loss': 1.9002786,\n 'learning_rate': 1.0079532e-05}\nI0620 12:39:37.768797 137593212425344 model_lib_v2.py:705] Step 40400 per-step time 0.444s\nI0620 12:39:37.769209 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.70003027,\n 'Loss/localization_loss': 1.0355318,\n 'Loss/regularization_loss': 0.14621142,\n 'Loss/total_loss': 1.8817735,\n 'learning_rate': 1.00397665e-05}\nI0620 12:40:22.066732 137593212425344 model_lib_v2.py:705] Step 40500 per-step time 0.443s\nI0620 12:40:22.067119 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6343683,\n 'Loss/localization_loss': 0.8627541,\n 'Loss/regularization_loss': 0.14620557,\n 'Loss/total_loss': 1.643328,\n 'learning_rate': 9.999999e-06}\nI0620 12:41:06.382805 137593212425344 model_lib_v2.py:705] Step 40600 per-step time 0.443s\nI0620 12:41:06.383176 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.61675227,\n 'Loss/localization_loss': 0.928054,\n 'Loss/regularization_loss': 0.14619975,\n 'Loss/total_loss': 1.691006,\n 'learning_rate': 9.960232e-06}\nI0620 12:41:50.702032 137593212425344 model_lib_v2.py:705] Step 40700 per-step time 0.443s\nI0620 12:41:50.702423 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7038597,\n 'Loss/localization_loss': 0.9235157,\n 'Loss/regularization_loss': 0.14619388,\n 'Loss/total_loss': 1.7735692,\n 'learning_rate': 9.920466e-06}\nI0620 12:42:34.876177 137593212425344 model_lib_v2.py:705] Step 40800 per-step time 0.442s\nI0620 12:42:34.876614 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5831483,\n 'Loss/localization_loss': 0.8740868,\n 'Loss/regularization_loss': 0.14618802,\n 'Loss/total_loss': 1.6034231,\n 'learning_rate': 9.880701e-06}\nI0620 12:43:18.957849 137593212425344 model_lib_v2.py:705] Step 40900 per-step time 0.441s\nI0620 12:43:18.958316 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6362097,\n 'Loss/localization_loss': 0.91793305,\n 'Loss/regularization_loss': 0.14618221,\n 'Loss/total_loss': 1.700325,\n 'learning_rate': 9.840938e-06}\nI0620 12:44:03.474276 137593212425344 model_lib_v2.py:705] Step 41000 per-step time 0.445s\nI0620 12:44:03.474663 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.67236483,\n 'Loss/localization_loss': 0.9479134,\n 'Loss/regularization_loss': 0.14617655,\n 'Loss/total_loss': 1.7664548,\n 'learning_rate': 9.801177e-06}\nI0620 12:44:48.376369 137593212425344 model_lib_v2.py:705] Step 41100 per-step time 0.449s\nI0620 12:44:48.376781 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6527715,\n 'Loss/localization_loss': 0.90288997,\n 'Loss/regularization_loss': 0.14617066,\n 'Loss/total_loss': 1.701832,\n 'learning_rate': 9.761419e-06}\nI0620 12:45:32.508315 137593212425344 model_lib_v2.py:705] Step 41200 per-step time 0.441s\nI0620 12:45:32.508761 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6441377,\n 'Loss/localization_loss': 0.97073245,\n 'Loss/regularization_loss': 0.14616504,\n 'Loss/total_loss': 1.7610352,\n 'learning_rate': 9.721666e-06}\nI0620 12:46:16.949350 137593212425344 model_lib_v2.py:705] Step 41300 per-step time 0.444s\nI0620 12:46:16.949803 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.68633723,\n 'Loss/localization_loss': 0.958157,\n 'Loss/regularization_loss': 0.14615932,\n 'Loss/total_loss': 1.7906536,\n 'learning_rate': 9.681917e-06}\nI0620 12:47:01.168520 137593212425344 model_lib_v2.py:705] Step 41400 per-step time 0.442s\nI0620 12:47:01.168923 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.71349347,\n 'Loss/localization_loss': 0.9982352,\n 'Loss/regularization_loss': 0.14615352,\n 'Loss/total_loss': 1.8578823,\n 'learning_rate': 9.642174e-06}\nI0620 12:47:45.536904 137593212425344 model_lib_v2.py:705] Step 41500 per-step time 0.444s\nI0620 12:47:45.537329 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6491337,\n 'Loss/localization_loss': 0.9886087,\n 'Loss/regularization_loss': 0.14614776,\n 'Loss/total_loss': 1.7838902,\n 'learning_rate': 9.602434e-06}\nI0620 12:48:29.915716 137593212425344 model_lib_v2.py:705] Step 41600 per-step time 0.444s\nI0620 12:48:29.916158 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6173906,\n 'Loss/localization_loss': 1.0065982,\n 'Loss/regularization_loss': 0.14614218,\n 'Loss/total_loss': 1.770131,\n 'learning_rate': 9.562701e-06}\nI0620 12:49:14.129079 137593212425344 model_lib_v2.py:705] Step 41700 per-step time 0.442s\nI0620 12:49:14.129693 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.60476476,\n 'Loss/localization_loss': 0.84753853,\n 'Loss/regularization_loss': 0.1461367,\n 'Loss/total_loss': 1.59844,\n 'learning_rate': 9.522976e-06}\nI0620 12:49:58.422601 137593212425344 model_lib_v2.py:705] Step 41800 per-step time 0.443s\nI0620 12:49:58.422990 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.74606645,\n 'Loss/localization_loss': 0.94878453,\n 'Loss/regularization_loss': 0.14613117,\n 'Loss/total_loss': 1.8409822,\n 'learning_rate': 9.4832585e-06}\nI0620 12:50:42.849041 137593212425344 model_lib_v2.py:705] Step 41900 per-step time 0.444s\nI0620 12:50:42.849496 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.65861416,\n 'Loss/localization_loss': 0.8842876,\n 'Loss/regularization_loss': 0.14612558,\n 'Loss/total_loss': 1.6890273,\n 'learning_rate': 9.44355e-06}\nI0620 12:51:27.147263 137593212425344 model_lib_v2.py:705] Step 42000 per-step time 0.443s\nI0620 12:51:27.147680 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6389123,\n 'Loss/localization_loss': 0.99023294,\n 'Loss/regularization_loss': 0.14612001,\n 'Loss/total_loss': 1.7752653,\n 'learning_rate': 9.403848e-06}\nI0620 12:52:11.842972 137593212425344 model_lib_v2.py:705] Step 42100 per-step time 0.447s\nI0620 12:52:11.843390 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63910604,\n 'Loss/localization_loss': 1.0045859,\n 'Loss/regularization_loss': 0.14611448,\n 'Loss/total_loss': 1.7898064,\n 'learning_rate': 9.364156e-06}\nI0620 12:52:56.042560 137593212425344 model_lib_v2.py:705] Step 42200 per-step time 0.442s\nI0620 12:52:56.042965 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.61969745,\n 'Loss/localization_loss': 0.9122621,\n 'Loss/regularization_loss': 0.14610897,\n 'Loss/total_loss': 1.6780685,\n 'learning_rate': 9.324476e-06}\nI0620 12:53:40.246629 137593212425344 model_lib_v2.py:705] Step 42300 per-step time 0.442s\nI0620 12:53:40.247118 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6831707,\n 'Loss/localization_loss': 1.0356464,\n 'Loss/regularization_loss': 0.14610352,\n 'Loss/total_loss': 1.8649206,\n 'learning_rate': 9.284804e-06}\nI0620 12:54:24.293117 137593212425344 model_lib_v2.py:705] Step 42400 per-step time 0.440s\nI0620 12:54:24.293519 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.69619083,\n 'Loss/localization_loss': 0.96950537,\n 'Loss/regularization_loss': 0.14609797,\n 'Loss/total_loss': 1.8117942,\n 'learning_rate': 9.2451455e-06}\nI0620 12:55:08.581940 137593212425344 model_lib_v2.py:705] Step 42500 per-step time 0.443s\nI0620 12:55:08.582341 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6361437,\n 'Loss/localization_loss': 0.94826424,\n 'Loss/regularization_loss': 0.14609253,\n 'Loss/total_loss': 1.7305005,\n 'learning_rate': 9.205497e-06}\nI0620 12:55:52.973104 137593212425344 model_lib_v2.py:705] Step 42600 per-step time 0.444s\nI0620 12:55:52.973501 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.67607033,\n 'Loss/localization_loss': 1.0160332,\n 'Loss/regularization_loss': 0.14608729,\n 'Loss/total_loss': 1.8381908,\n 'learning_rate': 9.165863e-06}\nI0620 12:56:37.413432 137593212425344 model_lib_v2.py:705] Step 42700 per-step time 0.444s\nI0620 12:56:37.413830 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6393341,\n 'Loss/localization_loss': 0.93060756,\n 'Loss/regularization_loss': 0.14608194,\n 'Loss/total_loss': 1.7160237,\n 'learning_rate': 9.126242e-06}\nI0620 12:57:21.892671 137593212425344 model_lib_v2.py:705] Step 42800 per-step time 0.445s\nI0620 12:57:21.893039 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.62445325,\n 'Loss/localization_loss': 0.98228073,\n 'Loss/regularization_loss': 0.14607662,\n 'Loss/total_loss': 1.7528106,\n 'learning_rate': 9.086632e-06}\nI0620 12:58:06.174969 137593212425344 model_lib_v2.py:705] Step 42900 per-step time 0.443s\nI0620 12:58:06.175360 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.64480495,\n 'Loss/localization_loss': 0.9302008,\n 'Loss/regularization_loss': 0.14607121,\n 'Loss/total_loss': 1.721077,\n 'learning_rate': 9.04704e-06}\nI0620 12:58:50.455915 137593212425344 model_lib_v2.py:705] Step 43000 per-step time 0.443s\nI0620 12:58:50.456351 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7010486,\n 'Loss/localization_loss': 0.97731256,\n 'Loss/regularization_loss': 0.14606608,\n 'Loss/total_loss': 1.8244272,\n 'learning_rate': 9.007462e-06}\nI0620 12:59:35.486441 137593212425344 model_lib_v2.py:705] Step 43100 per-step time 0.450s\nI0620 12:59:35.486825 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6405928,\n 'Loss/localization_loss': 0.81822693,\n 'Loss/regularization_loss': 0.14606096,\n 'Loss/total_loss': 1.6048807,\n 'learning_rate': 8.967899e-06}\nI0620 13:00:19.828358 137593212425344 model_lib_v2.py:705] Step 43200 per-step time 0.443s\nI0620 13:00:19.828759 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6013546,\n 'Loss/localization_loss': 1.03701,\n 'Loss/regularization_loss': 0.14605574,\n 'Loss/total_loss': 1.7844203,\n 'learning_rate': 8.928351e-06}\nI0620 13:01:04.226360 137593212425344 model_lib_v2.py:705] Step 43300 per-step time 0.444s\nI0620 13:01:04.226786 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6836446,\n 'Loss/localization_loss': 0.9156176,\n 'Loss/regularization_loss': 0.14605062,\n 'Loss/total_loss': 1.7453128,\n 'learning_rate': 8.888822e-06}\nI0620 13:01:48.472062 137593212425344 model_lib_v2.py:705] Step 43400 per-step time 0.442s\nI0620 13:01:48.472486 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66480947,\n 'Loss/localization_loss': 0.9712949,\n 'Loss/regularization_loss': 0.14604558,\n 'Loss/total_loss': 1.7821498,\n 'learning_rate': 8.849312e-06}\nI0620 13:02:32.852547 137593212425344 model_lib_v2.py:705] Step 43500 per-step time 0.444s\nI0620 13:02:32.852953 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.726089,\n 'Loss/localization_loss': 1.0167499,\n 'Loss/regularization_loss': 0.14604048,\n 'Loss/total_loss': 1.8888792,\n 'learning_rate': 8.809818e-06}\nI0620 13:03:17.342267 137593212425344 model_lib_v2.py:705] Step 43600 per-step time 0.445s\nI0620 13:03:17.342678 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6714195,\n 'Loss/localization_loss': 0.9935998,\n 'Loss/regularization_loss': 0.14603536,\n 'Loss/total_loss': 1.8110546,\n 'learning_rate': 8.770344e-06}\nI0620 13:04:01.589864 137593212425344 model_lib_v2.py:705] Step 43700 per-step time 0.442s\nI0620 13:04:01.590512 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66556764,\n 'Loss/localization_loss': 0.97957623,\n 'Loss/regularization_loss': 0.14603014,\n 'Loss/total_loss': 1.791174,\n 'learning_rate': 8.730886e-06}\nI0620 13:04:45.841631 137593212425344 model_lib_v2.py:705] Step 43800 per-step time 0.443s\nI0620 13:04:45.842037 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6430627,\n 'Loss/localization_loss': 0.8531111,\n 'Loss/regularization_loss': 0.14602509,\n 'Loss/total_loss': 1.6421988,\n 'learning_rate': 8.6914515e-06}\nI0620 13:05:30.123021 137593212425344 model_lib_v2.py:705] Step 43900 per-step time 0.443s\nI0620 13:05:30.123450 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6304321,\n 'Loss/localization_loss': 0.93203616,\n 'Loss/regularization_loss': 0.14602001,\n 'Loss/total_loss': 1.7084885,\n 'learning_rate': 8.652037e-06}\nI0620 13:06:14.440765 137593212425344 model_lib_v2.py:705] Step 44000 per-step time 0.443s\nI0620 13:06:14.441104 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6338818,\n 'Loss/localization_loss': 0.86131954,\n 'Loss/regularization_loss': 0.14601496,\n 'Loss/total_loss': 1.6412163,\n 'learning_rate': 8.612645e-06}\nI0620 13:06:59.459280 137593212425344 model_lib_v2.py:705] Step 44100 per-step time 0.450s\nI0620 13:06:59.459630 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5669906,\n 'Loss/localization_loss': 0.81486875,\n 'Loss/regularization_loss': 0.14600997,\n 'Loss/total_loss': 1.5278693,\n 'learning_rate': 8.573274e-06}\nI0620 13:07:43.817325 137593212425344 model_lib_v2.py:705] Step 44200 per-step time 0.444s\nI0620 13:07:43.817652 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.77775955,\n 'Loss/localization_loss': 1.0852218,\n 'Loss/regularization_loss': 0.14600493,\n 'Loss/total_loss': 2.0089862,\n 'learning_rate': 8.5339225e-06}\nI0620 13:08:28.106856 137593212425344 model_lib_v2.py:705] Step 44300 per-step time 0.443s\nI0620 13:08:28.107316 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.64148325,\n 'Loss/localization_loss': 1.0379593,\n 'Loss/regularization_loss': 0.14599997,\n 'Loss/total_loss': 1.8254426,\n 'learning_rate': 8.494598e-06}\nI0620 13:09:12.100599 137593212425344 model_lib_v2.py:705] Step 44400 per-step time 0.440s\nI0620 13:09:12.101019 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6041212,\n 'Loss/localization_loss': 0.9756228,\n 'Loss/regularization_loss': 0.145995,\n 'Loss/total_loss': 1.725739,\n 'learning_rate': 8.455297e-06}\nI0620 13:09:56.226694 137593212425344 model_lib_v2.py:705] Step 44500 per-step time 0.441s\nI0620 13:09:56.227107 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5895605,\n 'Loss/localization_loss': 0.8801142,\n 'Loss/regularization_loss': 0.14599006,\n 'Loss/total_loss': 1.6156647,\n 'learning_rate': 8.416019e-06}\nI0620 13:10:40.442071 137593212425344 model_lib_v2.py:705] Step 44600 per-step time 0.442s\nI0620 13:10:40.442490 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6139665,\n 'Loss/localization_loss': 0.94018936,\n 'Loss/regularization_loss': 0.14598522,\n 'Loss/total_loss': 1.7001412,\n 'learning_rate': 8.376768e-06}\nI0620 13:11:24.962417 137593212425344 model_lib_v2.py:705] Step 44700 per-step time 0.445s\nI0620 13:11:24.962840 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6860466,\n 'Loss/localization_loss': 1.149521,\n 'Loss/regularization_loss': 0.14598034,\n 'Loss/total_loss': 1.9815478,\n 'learning_rate': 8.337539e-06}\nI0620 13:12:09.399112 137593212425344 model_lib_v2.py:705] Step 44800 per-step time 0.444s\nI0620 13:12:09.399524 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.69750196,\n 'Loss/localization_loss': 0.9684675,\n 'Loss/regularization_loss': 0.14597547,\n 'Loss/total_loss': 1.811945,\n 'learning_rate': 8.29834e-06}\nI0620 13:12:53.699912 137593212425344 model_lib_v2.py:705] Step 44900 per-step time 0.443s\nI0620 13:12:53.700294 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.69101113,\n 'Loss/localization_loss': 0.912527,\n 'Loss/regularization_loss': 0.14597087,\n 'Loss/total_loss': 1.749509,\n 'learning_rate': 8.259166e-06}\nI0620 13:13:38.021100 137593212425344 model_lib_v2.py:705] Step 45000 per-step time 0.443s\nI0620 13:13:38.021517 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.58976793,\n 'Loss/localization_loss': 0.9060383,\n 'Loss/regularization_loss': 0.14596617,\n 'Loss/total_loss': 1.6417724,\n 'learning_rate': 8.22002e-06}\nI0620 13:14:22.885270 137593212425344 model_lib_v2.py:705] Step 45100 per-step time 0.449s\nI0620 13:14:22.885695 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5945865,\n 'Loss/localization_loss': 0.83227134,\n 'Loss/regularization_loss': 0.14596133,\n 'Loss/total_loss': 1.5728191,\n 'learning_rate': 8.180904e-06}\nI0620 13:15:07.242215 137593212425344 model_lib_v2.py:705] Step 45200 per-step time 0.444s\nI0620 13:15:07.242619 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.62183595,\n 'Loss/localization_loss': 0.9159367,\n 'Loss/regularization_loss': 0.14595658,\n 'Loss/total_loss': 1.6837292,\n 'learning_rate': 8.141812e-06}\nI0620 13:15:51.359161 137593212425344 model_lib_v2.py:705] Step 45300 per-step time 0.441s\nI0620 13:15:51.359584 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.72814274,\n 'Loss/localization_loss': 1.0449836,\n 'Loss/regularization_loss': 0.1459518,\n 'Loss/total_loss': 1.9190782,\n 'learning_rate': 8.102754e-06}\nI0620 13:16:35.573496 137593212425344 model_lib_v2.py:705] Step 45400 per-step time 0.442s\nI0620 13:16:35.573899 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.656281,\n 'Loss/localization_loss': 0.8840201,\n 'Loss/regularization_loss': 0.14594714,\n 'Loss/total_loss': 1.6862482,\n 'learning_rate': 8.063724e-06}\nI0620 13:17:19.868676 137593212425344 model_lib_v2.py:705] Step 45500 per-step time 0.443s\nI0620 13:17:19.869073 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5628325,\n 'Loss/localization_loss': 0.7343924,\n 'Loss/regularization_loss': 0.14594245,\n 'Loss/total_loss': 1.4431672,\n 'learning_rate': 8.0247255e-06}\nI0620 13:18:03.957457 137593212425344 model_lib_v2.py:705] Step 45600 per-step time 0.441s\nI0620 13:18:03.957862 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.69163436,\n 'Loss/localization_loss': 0.84340155,\n 'Loss/regularization_loss': 0.14593776,\n 'Loss/total_loss': 1.6809738,\n 'learning_rate': 7.985758e-06}\nI0620 13:18:48.098848 137593212425344 model_lib_v2.py:705] Step 45700 per-step time 0.441s\nI0620 13:18:48.099239 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6537634,\n 'Loss/localization_loss': 0.867473,\n 'Loss/regularization_loss': 0.14593305,\n 'Loss/total_loss': 1.6671696,\n 'learning_rate': 7.946821e-06}\nI0620 13:19:32.425877 137593212425344 model_lib_v2.py:705] Step 45800 per-step time 0.443s\nI0620 13:19:32.426263 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63814163,\n 'Loss/localization_loss': 0.9632634,\n 'Loss/regularization_loss': 0.14592855,\n 'Loss/total_loss': 1.7473335,\n 'learning_rate': 7.907918e-06}\nI0620 13:20:16.781678 137593212425344 model_lib_v2.py:705] Step 45900 per-step time 0.444s\nI0620 13:20:16.782069 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6677055,\n 'Loss/localization_loss': 0.9302152,\n 'Loss/regularization_loss': 0.14592397,\n 'Loss/total_loss': 1.7438446,\n 'learning_rate': 7.869047e-06}\nI0620 13:21:00.934579 137593212425344 model_lib_v2.py:705] Step 46000 per-step time 0.442s\nI0620 13:21:00.934996 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6301044,\n 'Loss/localization_loss': 0.92497164,\n 'Loss/regularization_loss': 0.14591946,\n 'Loss/total_loss': 1.7009954,\n 'learning_rate': 7.830212e-06}\nI0620 13:21:45.754896 137593212425344 model_lib_v2.py:705] Step 46100 per-step time 0.448s\nI0620 13:21:45.755276 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6433826,\n 'Loss/localization_loss': 0.8861796,\n 'Loss/regularization_loss': 0.14591488,\n 'Loss/total_loss': 1.6754771,\n 'learning_rate': 7.791409e-06}\nI0620 13:22:30.046062 137593212425344 model_lib_v2.py:705] Step 46200 per-step time 0.443s\nI0620 13:22:30.046467 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.67497224,\n 'Loss/localization_loss': 1.0012307,\n 'Loss/regularization_loss': 0.14591035,\n 'Loss/total_loss': 1.8221133,\n 'learning_rate': 7.752643e-06}\nI0620 13:23:14.357614 137593212425344 model_lib_v2.py:705] Step 46300 per-step time 0.443s\nI0620 13:23:14.358006 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7426686,\n 'Loss/localization_loss': 1.061939,\n 'Loss/regularization_loss': 0.14590594,\n 'Loss/total_loss': 1.9505135,\n 'learning_rate': 7.713909e-06}\nI0620 13:23:58.606306 137593212425344 model_lib_v2.py:705] Step 46400 per-step time 0.443s\nI0620 13:23:58.606734 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66478455,\n 'Loss/localization_loss': 0.95854735,\n 'Loss/regularization_loss': 0.14590146,\n 'Loss/total_loss': 1.7692335,\n 'learning_rate': 7.675214e-06}\nI0620 13:24:42.948980 137593212425344 model_lib_v2.py:705] Step 46500 per-step time 0.443s\nI0620 13:24:42.949438 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.59917545,\n 'Loss/localization_loss': 0.9157957,\n 'Loss/regularization_loss': 0.14589705,\n 'Loss/total_loss': 1.6608682,\n 'learning_rate': 7.636555e-06}\nI0620 13:25:27.144991 137593212425344 model_lib_v2.py:705] Step 46600 per-step time 0.442s\nI0620 13:25:27.145421 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.61204565,\n 'Loss/localization_loss': 0.9564123,\n 'Loss/regularization_loss': 0.14589258,\n 'Loss/total_loss': 1.7143505,\n 'learning_rate': 7.5979337e-06}\nI0620 13:26:11.339298 137593212425344 model_lib_v2.py:705] Step 46700 per-step time 0.442s\nI0620 13:26:11.339696 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6429609,\n 'Loss/localization_loss': 0.8911375,\n 'Loss/regularization_loss': 0.14588822,\n 'Loss/total_loss': 1.6799866,\n 'learning_rate': 7.5593507e-06}\nI0620 13:26:55.540852 137593212425344 model_lib_v2.py:705] Step 46800 per-step time 0.442s\nI0620 13:26:55.541314 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6674547,\n 'Loss/localization_loss': 1.0064979,\n 'Loss/regularization_loss': 0.1458839,\n 'Loss/total_loss': 1.8198365,\n 'learning_rate': 7.520804e-06}\nI0620 13:27:40.022437 137593212425344 model_lib_v2.py:705] Step 46900 per-step time 0.445s\nI0620 13:27:40.022820 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6710051,\n 'Loss/localization_loss': 0.8519936,\n 'Loss/regularization_loss': 0.14587955,\n 'Loss/total_loss': 1.6688782,\n 'learning_rate': 7.4822983e-06}\nI0620 13:28:24.119561 137593212425344 model_lib_v2.py:705] Step 47000 per-step time 0.441s\nI0620 13:28:24.119953 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6819671,\n 'Loss/localization_loss': 0.9563006,\n 'Loss/regularization_loss': 0.1458753,\n 'Loss/total_loss': 1.784143,\n 'learning_rate': 7.443833e-06}\nI0620 13:29:09.067900 137593212425344 model_lib_v2.py:705] Step 47100 per-step time 0.450s\nI0620 13:29:09.068286 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6706463,\n 'Loss/localization_loss': 0.9601779,\n 'Loss/regularization_loss': 0.14587122,\n 'Loss/total_loss': 1.7766955,\n 'learning_rate': 7.405408e-06}\nI0620 13:29:53.333314 137593212425344 model_lib_v2.py:705] Step 47200 per-step time 0.443s\nI0620 13:29:53.333721 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.72618794,\n 'Loss/localization_loss': 1.0583317,\n 'Loss/regularization_loss': 0.14586695,\n 'Loss/total_loss': 1.9303868,\n 'learning_rate': 7.367023e-06}\nI0620 13:30:37.489509 137593212425344 model_lib_v2.py:705] Step 47300 per-step time 0.442s\nI0620 13:30:37.489920 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6344334,\n 'Loss/localization_loss': 0.9511862,\n 'Loss/regularization_loss': 0.14586267,\n 'Loss/total_loss': 1.7314823,\n 'learning_rate': 7.328679e-06}\nI0620 13:31:21.811513 137593212425344 model_lib_v2.py:705] Step 47400 per-step time 0.443s\nI0620 13:31:21.811875 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5824006,\n 'Loss/localization_loss': 0.7589736,\n 'Loss/regularization_loss': 0.1458585,\n 'Loss/total_loss': 1.4872327,\n 'learning_rate': 7.2903786e-06}\nI0620 13:32:06.060572 137593212425344 model_lib_v2.py:705] Step 47500 per-step time 0.442s\nI0620 13:32:06.060936 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7553218,\n 'Loss/localization_loss': 1.1301463,\n 'Loss/regularization_loss': 0.14585432,\n 'Loss/total_loss': 2.0313225,\n 'learning_rate': 7.252122e-06}\nI0620 13:32:50.185742 137593212425344 model_lib_v2.py:705] Step 47600 per-step time 0.441s\nI0620 13:32:50.186093 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.75846016,\n 'Loss/localization_loss': 0.97472525,\n 'Loss/regularization_loss': 0.14585015,\n 'Loss/total_loss': 1.8790357,\n 'learning_rate': 7.213908e-06}\nI0620 13:33:34.413294 137593212425344 model_lib_v2.py:705] Step 47700 per-step time 0.442s\nI0620 13:33:34.413702 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63908845,\n 'Loss/localization_loss': 0.8025938,\n 'Loss/regularization_loss': 0.14584614,\n 'Loss/total_loss': 1.5875285,\n 'learning_rate': 7.1757377e-06}\nI0620 13:34:18.672700 137593212425344 model_lib_v2.py:705] Step 47800 per-step time 0.443s\nI0620 13:34:18.673110 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.61082506,\n 'Loss/localization_loss': 0.90620255,\n 'Loss/regularization_loss': 0.145842,\n 'Loss/total_loss': 1.6628696,\n 'learning_rate': 7.1376107e-06}\nI0620 13:35:02.848415 137593212425344 model_lib_v2.py:705] Step 47900 per-step time 0.442s\nI0620 13:35:02.848859 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5874529,\n 'Loss/localization_loss': 0.82333875,\n 'Loss/regularization_loss': 0.14583799,\n 'Loss/total_loss': 1.5566297,\n 'learning_rate': 7.0995306e-06}\nI0620 13:35:46.905984 137593212425344 model_lib_v2.py:705] Step 48000 per-step time 0.441s\nI0620 13:35:46.906376 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.7042718,\n 'Loss/localization_loss': 0.95369667,\n 'Loss/regularization_loss': 0.14583388,\n 'Loss/total_loss': 1.8038024,\n 'learning_rate': 7.061497e-06}\nI0620 13:36:31.690997 137593212425344 model_lib_v2.py:705] Step 48100 per-step time 0.448s\nI0620 13:36:31.691401 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.64586926,\n 'Loss/localization_loss': 0.9698161,\n 'Loss/regularization_loss': 0.14582995,\n 'Loss/total_loss': 1.7615153,\n 'learning_rate': 7.0235083e-06}\nI0620 13:37:16.128724 137593212425344 model_lib_v2.py:705] Step 48200 per-step time 0.444s\nI0620 13:37:16.129318 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6474948,\n 'Loss/localization_loss': 0.8445897,\n 'Loss/regularization_loss': 0.14582591,\n 'Loss/total_loss': 1.6379104,\n 'learning_rate': 6.9855687e-06}\nI0620 13:38:00.360654 137593212425344 model_lib_v2.py:705] Step 48300 per-step time 0.442s\nI0620 13:38:00.360993 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.56625795,\n 'Loss/localization_loss': 0.76596576,\n 'Loss/regularization_loss': 0.14582193,\n 'Loss/total_loss': 1.4780457,\n 'learning_rate': 6.9476732e-06}\nI0620 13:38:44.601502 137593212425344 model_lib_v2.py:705] Step 48400 per-step time 0.442s\nI0620 13:38:44.601920 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.58326495,\n 'Loss/localization_loss': 0.83968526,\n 'Loss/regularization_loss': 0.14581801,\n 'Loss/total_loss': 1.5687683,\n 'learning_rate': 6.909829e-06}\nI0620 13:39:28.937169 137593212425344 model_lib_v2.py:705] Step 48500 per-step time 0.443s\nI0620 13:39:28.937568 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6757865,\n 'Loss/localization_loss': 0.9366001,\n 'Loss/regularization_loss': 0.14581403,\n 'Loss/total_loss': 1.7582006,\n 'learning_rate': 6.8720333e-06}\nI0620 13:40:13.436362 137593212425344 model_lib_v2.py:705] Step 48600 per-step time 0.445s\nI0620 13:40:13.436756 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.61480737,\n 'Loss/localization_loss': 0.85544896,\n 'Loss/regularization_loss': 0.14581004,\n 'Loss/total_loss': 1.6160663,\n 'learning_rate': 6.834286e-06}\nI0620 13:40:57.763397 137593212425344 model_lib_v2.py:705] Step 48700 per-step time 0.443s\nI0620 13:40:57.763897 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6460475,\n 'Loss/localization_loss': 0.96203077,\n 'Loss/regularization_loss': 0.14580618,\n 'Loss/total_loss': 1.7538844,\n 'learning_rate': 6.796591e-06}\nI0620 13:41:41.823160 137593212425344 model_lib_v2.py:705] Step 48800 per-step time 0.441s\nI0620 13:41:41.823504 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6586275,\n 'Loss/localization_loss': 0.9715413,\n 'Loss/regularization_loss': 0.14580227,\n 'Loss/total_loss': 1.7759709,\n 'learning_rate': 6.758943e-06}\nI0620 13:42:25.763857 137593212425344 model_lib_v2.py:705] Step 48900 per-step time 0.439s\nI0620 13:42:25.764233 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.62594783,\n 'Loss/localization_loss': 0.88361937,\n 'Loss/regularization_loss': 0.14579836,\n 'Loss/total_loss': 1.6553655,\n 'learning_rate': 6.7213496e-06}\nI0620 13:43:09.943072 137593212425344 model_lib_v2.py:705] Step 49000 per-step time 0.442s\nI0620 13:43:09.943570 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66812265,\n 'Loss/localization_loss': 0.9273375,\n 'Loss/regularization_loss': 0.14579457,\n 'Loss/total_loss': 1.7412548,\n 'learning_rate': 6.6838065e-06}\nI0620 13:43:54.707391 137593212425344 model_lib_v2.py:705] Step 49100 per-step time 0.448s\nI0620 13:43:54.707841 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63976824,\n 'Loss/localization_loss': 0.9831799,\n 'Loss/regularization_loss': 0.14579077,\n 'Loss/total_loss': 1.768739,\n 'learning_rate': 6.646316e-06}\nI0620 13:44:38.781599 137593212425344 model_lib_v2.py:705] Step 49200 per-step time 0.441s\nI0620 13:44:38.782058 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6347617,\n 'Loss/localization_loss': 0.8826747,\n 'Loss/regularization_loss': 0.14578706,\n 'Loss/total_loss': 1.6632234,\n 'learning_rate': 6.608879e-06}\nI0620 13:45:22.962277 137593212425344 model_lib_v2.py:705] Step 49300 per-step time 0.442s\nI0620 13:45:22.962676 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.6426354,\n 'Loss/localization_loss': 1.0349216,\n 'Loss/regularization_loss': 0.14578341,\n 'Loss/total_loss': 1.8233405,\n 'learning_rate': 6.5714958e-06}\nI0620 13:46:07.038716 137593212425344 model_lib_v2.py:705] Step 49400 per-step time 0.441s\nI0620 13:46:07.039127 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.55731446,\n 'Loss/localization_loss': 0.7522146,\n 'Loss/regularization_loss': 0.14577976,\n 'Loss/total_loss': 1.4553088,\n 'learning_rate': 6.534165e-06}\nI0620 13:46:51.428589 137593212425344 model_lib_v2.py:705] Step 49500 per-step time 0.444s\nI0620 13:46:51.428974 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5989783,\n 'Loss/localization_loss': 0.8188764,\n 'Loss/regularization_loss': 0.14577618,\n 'Loss/total_loss': 1.5636308,\n 'learning_rate': 6.496891e-06}\nI0620 13:47:35.707638 137593212425344 model_lib_v2.py:705] Step 49600 per-step time 0.443s\nI0620 13:47:35.707998 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.63295,\n 'Loss/localization_loss': 0.9116784,\n 'Loss/regularization_loss': 0.1457725,\n 'Loss/total_loss': 1.6904008,\n 'learning_rate': 6.459671e-06}\nI0620 13:48:20.026136 137593212425344 model_lib_v2.py:705] Step 49700 per-step time 0.443s\nI0620 13:48:20.026562 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.5223634,\n 'Loss/localization_loss': 0.888685,\n 'Loss/regularization_loss': 0.1457689,\n 'Loss/total_loss': 1.5568173,\n 'learning_rate': 6.4225087e-06}\nI0620 13:49:04.216483 137593212425344 model_lib_v2.py:705] Step 49800 per-step time 0.442s\nI0620 13:49:04.216922 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.71363485,\n 'Loss/localization_loss': 1.009666,\n 'Loss/regularization_loss': 0.14576533,\n 'Loss/total_loss': 1.8690662,\n 'learning_rate': 6.3854027e-06}\nI0620 13:49:48.438709 137593212425344 model_lib_v2.py:705] Step 49900 per-step time 0.442s\nI0620 13:49:48.439059 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.66725135,\n 'Loss/localization_loss': 0.99596345,\n 'Loss/regularization_loss': 0.14576167,\n 'Loss/total_loss': 1.8089765,\n 'learning_rate': 6.3483517e-06}\nI0620 13:50:32.674262 137593212425344 model_lib_v2.py:705] Step 50000 per-step time 0.442s\nI0620 13:50:32.674706 137593212425344 model_lib_v2.py:708] {'Loss/classification_loss': 0.68842536,\n 'Loss/localization_loss': 0.7723646,\n 'Loss/regularization_loss': 0.1457581,\n 'Loss/total_loss': 1.6065481,\n 'learning_rate': 6.31136e-06}\n\n🔵 Evaluasi setelah iterasi ke-4\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nW0620 13:50:42.345046 136637267162240 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\nI0620 13:50:42.345310 136637267162240 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\nI0620 13:50:42.345469 136637267162240 config_util.py:552] Maybe overwriting use_bfloat16: False\nI0620 13:50:42.345591 136637267162240 config_util.py:552] Maybe overwriting eval_num_epochs: 1\nW0620 13:50:42.345728 136637267162240 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\nI0620 13:50:43.986216 136637267162240 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 13:50:43.986505 136637267162240 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/@25M(3class)-4/valid/1-QDa5-FSKD.tfrecord']\nI0620 13:50:43.986631 136637267162240 dataset_builder.py:80] Number of filenames to read: 1\nW0620 13:50:43.986728 136637267162240 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\nW0620 13:50:43.988811 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\nW0620 13:50:44.015408 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.data.Dataset.map()\nW0620 13:50:47.803574 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\nW0620 13:50:48.704489 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 13:50:51.073067 136637267162240 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\nI0620 13:50:51.074110 136637267162240 checkpoint_utils.py:145] Found new checkpoint at /kaggle/working/training/ckpt-51\n/usr/local/lib/python3.10/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\nI0620 13:50:56.598596 136637267162240 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nI0620 13:51:09.775071 136637267162240 api.py:441] feature_map_spatial_dims: [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4)]\nW0620 13:51:15.326618 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nI0620 13:51:15.338019 136637267162240 model_lib_v2.py:966] Finished eval step 0\nW0620 13:51:15.474286 136637267162240 deprecation.py:337] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\ntf.py_func is deprecated in TF V2. Instead, there are two\n    options available in V2.\n    - tf.py_function takes a python function which manipulates tf eager\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\n    means `tf.py_function`s can use accelerators such as GPUs as well as\n    being differentiable using a gradient tape.\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n    (it is not differentiable, and manipulates numpy arrays). It drops the\n    stateful argument making all functions stateful.\n    \nI0620 13:51:19.095262 136637267162240 coco_evaluation.py:293] Performing evaluation on 39 images.\ncreating index...\nindex created!\nI0620 13:51:19.098073 136637267162240 coco_tools.py:116] Loading and preparing annotation results...\nI0620 13:51:19.102090 136637267162240 coco_tools.py:138] DONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.71s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.113\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.073\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\nI0620 13:51:19.869790 136637267162240 model_lib_v2.py:1015] Eval metrics at step 50000\nI0620 13:51:19.878363 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.031138\nI0620 13:51:19.880022 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.113278\nI0620 13:51:19.881372 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.008094\nI0620 13:51:19.882783 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\nI0620 13:51:19.884344 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.022470\nI0620 13:51:19.885727 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.052138\nI0620 13:51:19.887064 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.009492\nI0620 13:51:19.888531 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.073214\nI0620 13:51:19.890024 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.145616\nI0620 13:51:19.891231 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\nI0620 13:51:19.892595 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.111219\nI0620 13:51:19.894255 136637267162240 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.216499\nI0620 13:51:19.895438 136637267162240 model_lib_v2.py:1018] \t+ Loss/localization_loss: 1.067336\nI0620 13:51:19.896558 136637267162240 model_lib_v2.py:1018] \t+ Loss/classification_loss: 1.028413\nI0620 13:51:19.897617 136637267162240 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.145758\nI0620 13:51:19.898862 136637267162240 model_lib_v2.py:1018] \t+ Loss/total_loss: 2.241507\nI0620 13:55:51.150871 136637267162240 checkpoint_utils.py:136] Waiting for new checkpoint at /kaggle/working/training\n^C\nTraceback (most recent call last):\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n    tf.compat.v1.app.run()\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n    sys.exit(main(argv))\n  File \"/kaggle/working/models/research/object_detection/model_main_tf2.py\", line 81, in main\n    model_lib_v2.eval_continuously(\n  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\n    for latest_checkpoint in tf.train.checkpoints_iterator(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 194, in checkpoints_iterator\n    new_checkpoint_path = wait_for_new_checkpoint(\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 143, in wait_for_new_checkpoint\n    time.sleep(seconds_to_sleep)\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# # Make a directory to store the trained TFLite model\n# !mkdir /kaggle/working/custom_model_lite\n# output_directory = '/kaggle/working/custom_model_lite'\n\n# # Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n# last_model_path = '/kaggle/working/training'\n\n# !python /kaggle/working/models/research/object_detection/export_tflite_graph_tf2.py \\\n#     --trained_checkpoint_dir {last_model_path} \\\n#     --output_directory {output_directory} \\\n#     --pipeline_config_path {pipeline_file}\n\n\nimport os\nimport subprocess\n\n# Path ke file pipeline config (hasil modifikasi mu)\npipeline_config_path = '/kaggle/working/models/mymodel/pipeline_file.config'\n\n# Folder checkpoint hasil training\ntrained_checkpoint_dir = '/kaggle/working/training/'\n\n# Folder output untuk saved_model\noutput_directory = '/kaggle/working/training/saved_model'\n\n# Pastikan folder output sudah ada\nos.makedirs(output_directory, exist_ok=True)\n\n# Jalankan exporter_main_v2.py dari TensorFlow Object Detection API\ncmd = [\n    'python',\n    '/kaggle/working/models/research/object_detection/exporter_main_v2.py',\n    '--input_type', 'image_tensor',\n    '--pipeline_config_path', pipeline_config_path,\n    '--trained_checkpoint_dir', trained_checkpoint_dir,\n    '--output_directory', output_directory\n]\n\nprint(\"Menjalankan export saved_model ...\")\nsubprocess.run(cmd, check=True)\nprint(f\"Saved_model berhasil diekspor ke: {output_directory}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:28:53.462210Z","iopub.execute_input":"2025-06-20T14:28:53.462564Z","iopub.status.idle":"2025-06-20T14:29:42.680648Z","shell.execute_reply.started":"2025-06-20T14:28:53.462542Z","shell.execute_reply":"2025-06-20T14:29:42.679835Z"}},"outputs":[{"name":"stdout","text":"Menjalankan export saved_model ...\nSaved_model berhasil diekspor ke: /kaggle/working/training/saved_model\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!zip -r /kaggle/working/training.zip /kaggle/working/training/saved_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:20.356943Z","iopub.execute_input":"2025-06-20T14:08:20.357352Z","iopub.status.idle":"2025-06-20T14:08:21.731871Z","shell.execute_reply.started":"2025-06-20T14:08:20.357317Z","shell.execute_reply":"2025-06-20T14:08:21.730888Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/training/saved_model/ (stored 0%)\n  adding: kaggle/working/training/saved_model/pipeline.config (deflated 70%)\n  adding: kaggle/working/training/saved_model/checkpoint/ (stored 0%)\n  adding: kaggle/working/training/saved_model/checkpoint/ckpt-0.data-00000-of-00001 (deflated 8%)\n  adding: kaggle/working/training/saved_model/checkpoint/ckpt-0.index (deflated 80%)\n  adding: kaggle/working/training/saved_model/checkpoint/checkpoint (deflated 41%)\n  adding: kaggle/working/training/saved_model/saved_model/ (stored 0%)\n  adding: kaggle/working/training/saved_model/saved_model/assets/ (stored 0%)\n  adding: kaggle/working/training/saved_model/saved_model/saved_model.pb (deflated 92%)\n  adding: kaggle/working/training/saved_model/saved_model/variables/ (stored 0%)\n  adding: kaggle/working/training/saved_model/saved_model/variables/variables.data-00000-of-00001 (deflated 8%)\n  adding: kaggle/working/training/saved_model/saved_model/variables/variables.index (deflated 78%)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!zip -r /kaggle/working/training.zip /kaggle/working/training","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:33:48.210810Z","iopub.execute_input":"2025-06-20T14:33:48.211151Z","iopub.status.idle":"2025-06-20T14:34:17.310963Z","shell.execute_reply.started":"2025-06-20T14:33:48.211126Z","shell.execute_reply":"2025-06-20T14:34:17.309893Z"}},"outputs":[{"name":"stdout","text":"updating: kaggle/working/training/saved_model/ (stored 0%)\nupdating: kaggle/working/training/saved_model/pipeline.config (deflated 70%)\nupdating: kaggle/working/training/saved_model/checkpoint/ (stored 0%)\nupdating: kaggle/working/training/saved_model/checkpoint/ckpt-0.data-00000-of-00001 (deflated 8%)\nupdating: kaggle/working/training/saved_model/checkpoint/ckpt-0.index (deflated 80%)\nupdating: kaggle/working/training/saved_model/checkpoint/checkpoint (deflated 40%)\nupdating: kaggle/working/training/saved_model/saved_model/ (stored 0%)\nupdating: kaggle/working/training/saved_model/saved_model/assets/ (stored 0%)\nupdating: kaggle/working/training/saved_model/saved_model/saved_model.pb (deflated 92%)\nupdating: kaggle/working/training/saved_model/saved_model/variables/ (stored 0%)\nupdating: kaggle/working/training/saved_model/saved_model/variables/variables.data-00000-of-00001 (deflated 8%)\nupdating: kaggle/working/training/saved_model/saved_model/variables/variables.index (deflated 78%)\nupdating: kaggle/working/training/ (stored 0%)\nupdating: kaggle/working/training/ckpt-49.index (deflated 81%)\nupdating: kaggle/working/training/ckpt-48.index (deflated 81%)\nupdating: kaggle/working/training/ckpt-51.index (deflated 81%)\nupdating: kaggle/working/training/ckpt-47.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/ckpt-46.index (deflated 81%)\nupdating: kaggle/working/training/checkpoint (deflated 75%)\nupdating: kaggle/working/training/ckpt-45.index (deflated 82%)\nupdating: kaggle/working/training/ckpt-48.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/ckpt-47.index (deflated 81%)\nupdating: kaggle/working/training/eval/ (stored 0%)\nupdating: kaggle/working/training/eval/events.out.tfevents.1750427451.5ac6fefba83c.3203.0.v2 (deflated 1%)\nupdating: kaggle/working/training/eval/events.out.tfevents.1750408899.5ac6fefba83c.2597.0.v2 (deflated 1%)\nupdating: kaggle/working/training/eval/events.out.tfevents.1750415492.5ac6fefba83c.2802.0.v2 (deflated 1%)\nupdating: kaggle/working/training/eval/events.out.tfevents.1750421407.5ac6fefba83c.3000.0.v2 (deflated 1%)\nupdating: kaggle/working/training/ckpt-46.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/ckpt-51.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/train/ (stored 0%)\nupdating: kaggle/working/training/train/events.out.tfevents.1750409602.5ac6fefba83c.2641.0.v2 (deflated 0%)\nupdating: kaggle/working/training/train/events.out.tfevents.1750403201.5ac6fefba83c.2469.0.v2 (deflated 0%)\nupdating: kaggle/working/training/train/events.out.tfevents.1750421547.5ac6fefba83c.3042.0.v2 (deflated 0%)\nupdating: kaggle/working/training/train/events.out.tfevents.1750415737.5ac6fefba83c.2844.0.v2 (deflated 0%)\nupdating: kaggle/working/training/ckpt-50.index (deflated 81%)\nupdating: kaggle/working/training/ckpt-49.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/ckpt-45.data-00000-of-00001 (deflated 9%)\nupdating: kaggle/working/training/ckpt-50.data-00000-of-00001 (deflated 9%)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import shutil\nimport os\nfrom zipfile import ZipFile\nfrom IPython.display import FileLink\n\n# Nama file output zip\nzip_file = \"/kaggle/working/backup.zip\"\n\n# Daftar folder yang ingin dikompres\nfolders_to_zip = [\"training\"]\n\n\n# Buat file ZIP dan tambahkan folder yang dipilih\nwith ZipFile(zip_file, 'w') as zipf:\n    for folder in folders_to_zip:\n        folder_path = os.path.join(\"/kaggle/working\", folder)\n        if os.path.exists(folder_path):\n            for root, _, files in os.walk(folder_path):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Tampilkan link untuk mengunduh file zip\nif os.path.exists(zip_file):\n    display(FileLink(zip_file))\nelse:\n    print(\"File ZIP tidak ditemukan.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:50.541648Z","iopub.execute_input":"2025-06-20T14:08:50.542024Z","iopub.status.idle":"2025-06-20T14:08:52.260976Z","shell.execute_reply.started":"2025-06-20T14:08:50.541986Z","shell.execute_reply":"2025-06-20T14:08:52.260188Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/backup.zip","text/html":"<a href='/kaggle/working/backup.zip' target='_blank'>/kaggle/working/backup.zip</a><br>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# import shutil\n\n# zip_path = '/kaggle/working/saved_model.zip'\n# saved_model_dir = '/kaggle/working/training/saved_model'\n\n# # Kompres ke zip\n# shutil.make_archive(base_name=zip_path.replace('.zip', ''), format='zip', root_dir=saved_model_dir)\n# shutil.make_archive('/kaggle/working/training_full_backup', 'zip', '/kaggle/working/training')\n\n# print(f\"✅ Model berhasil dikompres menjadi: {zip_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:52.261955Z","iopub.execute_input":"2025-06-20T14:08:52.262305Z","iopub.status.idle":"2025-06-20T14:08:52.265844Z","shell.execute_reply.started":"2025-06-20T14:08:52.262273Z","shell.execute_reply":"2025-06-20T14:08:52.264944Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# # Convert exported graph file into TFLite model file\n# import tensorflow as tf\n\n# converter = tf.lite.TFLiteConverter.from_saved_model('/kaggle/working/custom_model_lite/saved_model')\n# tflite_model = converter.convert()\n\n# with open('/kaggle/working/custom_model_lite/detect.tflite', 'wb') as f:\n#   f.write(tflite_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:52.269751Z","iopub.execute_input":"2025-06-20T14:08:52.270019Z","iopub.status.idle":"2025-06-20T14:08:52.278049Z","shell.execute_reply.started":"2025-06-20T14:08:52.269998Z","shell.execute_reply":"2025-06-20T14:08:52.277365Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# # Run evaluation!\n# !python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n#     --pipeline_config_path={pipeline_file} \\\n#     --model_dir={model_dir} \\\n#     --checkpoint_dir={model_dir} \\\n#     --alsologtostderr \\\n#     --sample_1_of_n_eval_examples=1\n\n\n# !python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n#     --pipeline_config_path={pipeline_file} \\\n#     --model_dir={model_dir} \\\n#     --checkpoint_dir={model_dir} \\\n#     --alsologtostderr \\\n#     --sample_1_of_n_eval_examples=1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:52.278938Z","iopub.execute_input":"2025-06-20T14:08:52.279235Z","iopub.status.idle":"2025-06-20T14:08:52.288968Z","shell.execute_reply.started":"2025-06-20T14:08:52.279183Z","shell.execute_reply":"2025-06-20T14:08:52.288132Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# # Buat zip dari direktori log\n# !zip -r model_logs.zip /kaggle/working/training\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:52.289894Z","iopub.execute_input":"2025-06-20T14:08:52.290144Z","iopub.status.idle":"2025-06-20T14:08:52.302763Z","shell.execute_reply.started":"2025-06-20T14:08:52.290119Z","shell.execute_reply":"2025-06-20T14:08:52.302071Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# !rm /kaggle/working/custom_model_lite/detect.tflite","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T14:08:52.303669Z","iopub.execute_input":"2025-06-20T14:08:52.303911Z","iopub.status.idle":"2025-06-20T14:08:52.314698Z","shell.execute_reply.started":"2025-06-20T14:08:52.303891Z","shell.execute_reply":"2025-06-20T14:08:52.313859Z"}},"outputs":[],"execution_count":26}]}